{"meta":{"title":"Jeremy's Blog Site","subtitle":"","description":"","author":"JeremyTownes","url":"http://yoursite.com","root":"/"},"pages":[{"title":"关于","date":"2020-12-04T11:24:29.148Z","updated":"2020-12-04T11:24:29.148Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"汤英杰，籍贯湖南，2017 年毕业于河南理工大学，方向 DevOps 证书 红帽认证系统管理员（RHCSA） 红帽认证工程师（RHCE） 大学英语测试四级（CET-4） 技能特长 熟悉多种发行版 Linux（Redhat、Debian）/ 熟练使用 Shell、Python 编写脚本 熟悉 Django 等 Python Web 框架 熟悉常用 SVC 工具（Git、Subversion） 熟悉自动化工具（Ansible、Jenkins） 熟悉常用监控部署和使用（Zabbix、Prometheus） 熟悉容器部署安装和使用（Docker、Kubernetes） 熟悉 MySQL、Redis、Elasticsearch 等数据库 工作经历 2020.05~至今 · 广东小天才技术有限公司（服务器运维工程师） 2018.11～2020.05 · 联畅信息技术有限公司（中信银行信用卡中心项目 · 系统管理员） 2017.08 ~ 2018.11 · 欣旺达电子股份有限公司（运维工程师）"}],"posts":[{"title":"RHEL 7 配置网络绑定","slug":"bond","date":"2020-01-14T16:00:00.000Z","updated":"2020-12-04T12:12:46.090Z","comments":true,"path":"2020/01/15/bond/","link":"","permalink":"http://yoursite.com/2020/01/15/bond/","excerpt":"","text":"1. 常见的网卡绑定驱动模式: active-backup、balance-tlb 和 balance-alb 模式不需要交换机的任何特殊配置。其他绑定模式需要配置交换机以便整合链接。例如：Cisco 交换机需要在模式 0、2 和 3 中使用 EtherChannel，但在模式 4 中需要 LACP 和 EtherChannel。有关交换机附带文档，请查看 https://www.kernel.org/doc/Documentation/networking/bonding.txt。 balance-rr 或者 0 — 为容错及负载平衡设定轮询机制。从第一个可用的绑定从属接口开始按顺序接收和发送传输数据。 active-backup 或者 1 — 为容错设定 active-backup 策略。 通过第一个可用的绑定从属接口接收和发送传输文件。只有在活动的绑定从属接口失败时才使用其他绑定从属接口。 balance-xor 或者 2 — 只根据所选哈希策略传输数据。默认为使用源的 XOR 和目标 MAC 地址与从属接口数的余数相乘生成哈希。在这个模式中，指向具体对等接口的模式流量总是使用同一接口发送。因为目标是由 MAC 地址决定，因此这个方法最适合相同链接或本地网络的对等接口流量。如果流量必须通过单一路由器，那么这个流量平衡模式将是次选模式。 broadcast 或者 3 — 为容错设定广播策略。可在所有从属接口中传输所有数据。 802.3ad 或者 4 — 设定 IEEE 802.3ad 动态链接聚合策略。创建一个共享同一速度和双工设置的聚合组。在所有活跃聚合器中传输和接受数据。需要兼容 802.3ad 的交换机。 balance-tlb 或者 5 — 为容错及负载平衡设定传输负载平衡（TLB）策略。传出流量会根据每个从属接口的当前负载分布。传入流量由当前从属接口接收。如果接收数据从属接口失败，另一个从属接口会接管失败从属接口的 MAC 地址。这个模式只适用于内核绑定模式了解的本地地址，因此无法在桥接后的虚拟机中使用。 balance-alb 或者 6 — 为容错及负载平衡设定自适应负载平衡（ALB）策略，包括用于 IPv4 流量的传输及接收负载平衡。使用 ARP 协商获得接收负载平衡。这个模式只适用于内核 binding 模块了解的本地地址，因此无法在桥接后的虚拟机中使用。 2. 主接口及从属接口的默认行为使用 NetworkManager 守护进程控制绑定的从属接口时，特别是在查找出现问题时，请记住以下几点： 启动主接口不会自动启动从属接口。 启动从属接口总是启动主接口。 停止主接口也可以停止从属接口。 没有从属接口的主接口可启动静态 IP 连接。 没有从属接口的主接口会在启动 DHCP 连接时等待从属接口。 有 DHCP 连接的主接口会在添加有载波的从属接口时等待从属接口完成。 有 DHCP 连接的主接口会在添加没有载波的从属接口时等待从属接口完成。 3. 使用 (NetworkManager) nmcli 工具配置网卡绑定123nmcli con add type bond con-name bond0 ifname bond0 mode active-backupnmcli con add type bond-slave ifname enp0s9 master bond0nmcli con add type bond-slave ifname enp0s10 master bond0 要启动绑定，则必须首先启动从属接口： 123nmcli c up bond-slave-enp0s9nmcli c up bond-slave-enp0s10 启动绑定： 1nmcli c up bond0 1234nmcli c modify bond0 ipv4.addresses 192.168.33.32/24nmcli c modify bond0 ipv4.gateway 192.168.33.1nmcli c modify bond0 ipv4.dns 192.168.33.1nmcli c modify bond0 ipv4.method manual 1systemctl restart network 3. 使用命令行界面配置网卡绑定检查是否已安装 Bonding 内核模块 在 Red Hat Enterprise Linux 7 中默认载入 bonding 模块。 显示 boding 模块信息 1modinfo bonding Bonding 模块指令查看所有现有绑定（包括未启动的绑定），请运行： 1cat /sys/class/net/bonding_masters 绑定接口参数 ad_select=value - 指定要使用的 802.3ad 聚合选择逻辑。 arp_interval=time_in_milliseconds - 以毫秒为单位指定 ARP 监控的频繁度。默认将这个数值设定为 0，即禁用该功能。 arp_ip_target=ip_address[,ip_address_2,…ip_address_16] - 启用 arp_interval 参数后，指定 ARP 请求的目标 IP 地址。在使用逗号分开的列表中最多可指定 16 个 IP 地址。 arp_validate=value - 验证 ARP 探测的源/分配，默认为 none。其他值为 active、backup 和 all。 downdelay=time_in_milliseconds - 以毫秒为单位指定从链接失败到禁用该链接前要等待的时间。该值必须是 miimon 参数中的多个数值。默认将其设定为 0，即禁用该功能。 fail_over_mac=value - 指定 active-backup 模式是否应该将所有从属连接设定为使用同一 MAC 地址作为 enslavement（传统行为），或在启用时根据所选策略执行绑定 MAC 地址的特殊处理。 lacp_rate=value - 指定链接伙伴应使用 802.3ad 模式传输 LACPDU 的速率 miimon=time_in_milliseconds - 以毫秒为单位指定 MII 链接监控的频率。 mode=value - 允许您指定绑定的策略。 primary=interface_name - 指定主设备的接口名称，比如 eth0。 primary_reselect=value - 为主从属接口指定重新选择策略。 resend_igmp=range - 指定故障转移事件后要进行的 IGMP 成员报告数。故障转移后会立即提交一个报告，之后会每隔 200 毫秒发送数据包。 updelay=time_in_milliseconds - 以毫秒为单位指定启用某个链接前要等待的时间。该数值必须是在 miimon 参数值指定值的倍数。默认设定为 0，即禁用该参数。 use_carrier=number - 指定 miimon 是否应该使用 MII/ETHTOOL ioctls 或者 netif_carrier_ok() 来决定该链接状态。 xmit_hash_policy=value - 选择 balance-xor 和 802.3ad 模式中用来选择从属接口的传输哈希策略。 创建频道绑定接口 必须在 ifcfg-bondN 接口文件的 BONDING_OPTS=&quot;bonding parameters separated by spaces&quot; 指令中，使用以空格分开的列表指定 bonding 内核模块。请不要在 /etc/modprobe.d/bonding.conf 文件或弃用的 /etc/modprobe.conf 文件中为绑定设备指定选项。max_bonds 参数不是具体接口的参数，且不应在使用 BONDING_OPTS 指令的 ifcfg-bondN 文件中设定，因为这个指令会让网络脚本根据需要创建绑定接口。 在 /etc/sysconfig/network-scripts/ 目录中创建名为 ifcfg-bondN 的文件，使用接口号码替换 N，比如 0。 12345678910111213cat &lt;&lt; EOF &gt; /etc/sysconfig/network-scripts/ifcfg-bond0DEVICE=bond0NAME=bond0TYPE=BondBONDING_MASTER=yesIPADDR=192.168.33.32PREFIX=24GATEWAY=192.168.33.1DNS1=192.168.33.1ONBOOT=yesBOOTPROTO=noneBONDING_OPTS=\"miimon=1000 mode=1 primary=enp0s9\"EOF 创建从属接口在 /etc/sysconfig/network-scripts/ 目录中创建名为 ifcfg-ethN 的文件，使用接口号码替换 N，比如 0。 123456789cat &lt;&lt; EOF &gt; /etc/sysconfig/network-scripts/ifcfg-enp0s9DEVICE=enp0s9NAME=bond0-slave-enp0s9TYPE=EthernetBOOTPROTO=noneONBOOT=yesMASTER=bond0SLAVE=yesEOF 123456789cat &lt;&lt; EOF &gt; /etc/sysconfig/network-scripts/ifcfg-enp0s10DEVICE=enp0s10NAME=bond0-slave-enp0s10TYPE=EthernetBOOTPROTO=noneONBOOT=yesMASTER=bond0SLAVE=yesEOF 激活频道绑定123456789ifup bond0ifup ifcfg-enp0s9ifup ifcfg-enp0s10# 生效更改nmcli con load /etc/sysconfig/network-script/ifcfg-devicenmcli con reload# 查看网卡绑定接口状态ip link show","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"nmcli","slug":"nmcli","permalink":"http://yoursite.com/tags/nmcli/"}]},{"title":"RHEL 7 配置网络成组","slug":"team","date":"2020-01-14T16:00:00.000Z","updated":"2020-12-04T11:57:26.676Z","comments":true,"path":"2020/01/15/team/","link":"","permalink":"http://yoursite.com/2020/01/15/team/","excerpt":"","text":"网络成组和绑定对比 安装 teamd默认不会安装网络成组守护进程 teamd。要安装 teamd 1yum -y install teamd 将绑定转换为成组1bond2team --examples 12345678910111213141516171819202122232425262728293031323334The following commands will deliver the ifcfg files into a temporarydirectory. You can review the files and copy to the right location.Add the following argument to the commands below to print the outputto the screen instead of writing to files. --stdoutAdd the following arguments to the commands below to set thedestination directory for the output files. --outputdir &lt;&#x2F;path&#x2F;to&#x2F;dir&gt;Add the following argument to the commands below to output thefiles in teamd format (JSON) instead of the default ifcfg format. --jsonTo convert the current &quot;bond0&quot; ifcfg configuration to team ifcfg:# &#x2F;usr&#x2F;bin&#x2F;bond2team --master bond0To convert the current &quot;bond0&quot; ifcfg configuration out of thestandard ifcfg-:# &#x2F;usr&#x2F;bin&#x2F;bond2team --master bond0 --configdir &lt;&#x2F;path&#x2F;to&#x2F;ifcfg&gt;To convert the current &quot;bond0&quot; ifcfg configuration to team ifcfgrenaming the interface name to &quot;team0&quot;. (carefull: firewall rules,aliases interfaces, etc., will break after the renaming because thetool will only change the ifcfg file, nothing else)# &#x2F;usr&#x2F;bin&#x2F;bond2team --master bond0 --rename team0To convert given bonding parameters without any ifcfg:# &#x2F;usr&#x2F;bin&#x2F;bond2team --bonding_opts &quot;mode&#x3D;1 miimon&#x3D;500&quot;To convert given bonding parameters without any ifcfg with ports:# &#x2F;usr&#x2F;bin&#x2F;bond2team --bonding_opts &quot;mode&#x3D;1 miimon&#x3D;500 primary&#x3D;eth1 primary_reselect-0&quot; \\ --port eth1 --port eth2 --port eth3 --port eth4 1234567# 保留名称/usr/bin/bond2team --master bond0Resulted files: /tmp/bond2team.j8PiKA/ifcfg-bond0 /tmp/bond2team.j8PiKA/ifcfg-enp0s10 /tmp/bond2team.j8PiKA/ifcfg-enp0s9 12345678# 使用新名称保存该配置# 添加 --json 选项输出 JSON 格式文件/usr/bin/bond2team --master bond0 --rename team0Resulted files: /tmp/bond2team.vwCjgt/ifcfg-team0 /tmp/bond2team.vwCjgt/ifcfg-enp0s10 /tmp/bond2team.vwCjgt/ifcfg-enp0s9 123# 将绑定转换为成组并指定文件路径# 添加 --json 选项输出 JSON 格式文件/usr/bin/bond2team --master bond0 --configdir /etc/sysconfig/network-scripts/","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"nmcli","slug":"nmcli","permalink":"http://yoursite.com/tags/nmcli/"}]},{"title":"Journald 指南","slug":"journald","date":"2019-12-30T16:00:00.000Z","updated":"2020-12-04T12:18:40.780Z","comments":true,"path":"2019/12/31/journald/","link":"","permalink":"http://yoursite.com/2019/12/31/journald/","excerpt":"","text":"1. journald 服务 systemd-journald 是一项收集和存储日志记录数据的系统服务。它基于从各种来源接收到的日志记录信息来创建和维护结构化, 已索引的日志： 通过 kmsg 的内核日志消息 通过 libc syslog 调用的简单系统日志消息 通过本机的结构化系统日志消息日志API 系统服务的标准输出和标准错误 通过审核子系统的审核记录守护程序将以安全且可靠的方式隐式收集每个日志消息的大量元数据段 12345678910111213141516[root@nginx ~]# systemctl status systemd-journald.service● systemd-journald.service - Journal Service Loaded: loaded (/usr/lib/systemd/system/systemd-journald.service; static; vendor preset: disabled) Active: active (running) since 三 2020-01-01 06:31:55 CST; 47min ago Docs: man:systemd-journald.service(8) man:journald.conf(5) Main PID: 515 (systemd-journal) Status: \"Processing requests...\" CGroup: /system.slice/systemd-journald.service └─515 /usr/lib/systemd/systemd-journald1月 01 06:31:55 ldap.example.com systemd-journal[515]: Runtime journal is using 6.1M (max …M).1月 01 06:31:55 ldap.example.com systemd-journal[515]: Journal started1月 01 06:31:55 ldap.example.com systemd-journal[515]: Permanent journal is using 16.0M (m…G).1月 01 06:31:55 ldap.example.com systemd-journal[515]: Time spent on flushing to /var is 7....Hint: Some lines were ellipsized, use -l to show in full. systemd-journald.service 文件 1234567891011121314151617181920212223242526272829303132[root@nginx ~]# cat /usr/lib/systemd/system/systemd-journald.service# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Journal ServiceDocumentation=man:systemd-journald.service(8) man:journald.conf(5)DefaultDependencies=noRequires=systemd-journald.socketAfter=systemd-journald.socket syslog.socketBefore=sysinit.target[Service]Type=notifySockets=systemd-journald.socketExecStart=/usr/lib/systemd/systemd-journaldRestart=alwaysRestartSec=0StandardOutput=nullFileDescriptorStoreMax=4224CapabilityBoundingSet=CAP_SYS_ADMIN CAP_DAC_OVERRIDE CAP_SYS_PTRACE CAP_SYSLOG CAP_AUDIT_CONTROL CAP_AUDIT_READ CAP_CHOWN CAP_DAC_READ_SEARCH CAP_FOWNER CAP_SETUID CAP_SETGID CAP_MAC_OVERRIDEWatchdogSec=3min# Increase the default a bit in order to allow many simultaneous# services being run since we keep one fd open per service. Also, when# flushing journal files to disk, we might need a lot of fds when many# journal files are combined.LimitNOFILE=16384 默认 journald 配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041[root@nginx ~]# cat /etc/systemd/journald.conf# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.## Entries in this file show the compile time defaults.# You can change settings by editing this file.# Defaults can be restored by simply deleting this file.## See journald.conf(5) for details.[Journal]#Storage=auto#Compress=yes#Seal=yes#SplitMode=uid#SyncIntervalSec=5m#RateLimitInterval=30s#RateLimitBurst=1000#SystemMaxUse=#SystemKeepFree=#SystemMaxFileSize=#RuntimeMaxUse=#RuntimeKeepFree=#RuntimeMaxFileSize=#MaxRetentionSec=#MaxFileSec=1month#ForwardToSyslog=yes#ForwardToKMsg=no#ForwardToConsole=no#ForwardToWall=yes#TTYPath=/dev/console#MaxLevelStore=debug#MaxLevelSyslog=debug#MaxLevelKMsg=notice#MaxLevelConsole=info#MaxLevelWall=emerg#LineMax=48K 2. journald 日志持久化默认情况下，日志将日志数据存储在 /run/log/journal/. 中。由于 /run/ 是易失性的，因此日志数据在重新引导时会丢失。要使数据持久化，只需创建 /var/log/journal/，然后systemd-journald将在其中存储数据： 12[root@nginx ~]# mkdir -p /var/log/journal [root@nginx ~]# systemd-tmpfiles --create --prefix /var/log/journal 123456789101112131415161718192021222324252627[root@nginx ~]# mkdir /etc/systemd/journald.conf.d[root@nginx ~]# cat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF[Journal]# 持久化保存到磁盘Storage=persistent# 压缩历史日志Compress=yesSyncIntervalSec=5mRateLimitInterval=30sRateLimitBurst=1000# 最大占用空间 10GSystemMaxUse=10G# 单日志文件最大 200MSystemMaxFileSize=200M# 日志保存时间 2 周MaxRetentionSec=2week# 不将日志转发到 syslogForwardToSyslog=noEOF[root@nginx ~]# systemctl restart systemd-journald 3. journalctl 管理工具 journalctl 是用来查询由 systemd-journald 服务收集的 systemd 日志，当它不接收任何参数则会最早的收集入口展示日志 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[root@nginx ~]# journalctl --helpjournalctl [OPTIONS...] [MATCHES...]Query the journal.Flags: --system 展示系统日志 --user 展示当前用户的用户日志 -M --machine=CONTAINER Operate on local container -S --since=DATE 展示从指定日期 [%Y-%m-%d %H:%M:%S] 开始的日志 -U --until=DATE 展示到指定日期 [%Y-%m-%d %H:%M:%S] 为止的日志 -c --cursor=CURSOR Show entries starting at the specified cursor --after-cursor=CURSOR Show entries after the specified cursor --show-cursor Print the cursor after all the entries -b --boot[=ID] Show current boot or the specified boot --list-boots Show terse information about recorded boots -k --dmesg 展示当前启动的内核日志 -u --unit=UNIT 展示指定 unit [nginx, httpd ...] 的日志 -t --identifier=STRING Show entries with the specified syslog identifier -p --priority=RANGE Show entries with the specified priority -e --pager-end Immediately jump to the end in the pager -f --follow Follow the journal -n --lines[=INTEGER] Number of journal entries to show --no-tail Show all lines, even in follow mode -r --reverse Show the newest entries first -o --output=STRING Change journal output mode (short, short-iso, short-precise, short-monotonic, verbose, export, json, json-pretty, json-sse, cat) --utc Express time in Coordinated Universal Time (UTC) -x --catalog Add message explanations where available --no-full Ellipsize fields -a --all Show all fields, including long and unprintable -q --quiet Do not show privilege warning --no-pager Do not pipe output into a pager -m --merge Show entries from all available journals -D --directory=PATH 展示指定目录下的日志文件的日志 --file=PATH 展示指定日志文件中的日志 --root=ROOT Operate on catalog files underneath the root ROOT --interval=TIME Time interval for changing the FSS sealing key --verify-key=KEY Specify FSS verification key --force Override of the FSS key pair with --setup-keysCommands: -h --help Show this help text --version Show package version -F --field=FIELD List all values that a specified field takes --new-id128 Generate a new 128-bit ID --disk-usage Show total disk usage of all journal files --vacuum-size=BYTES Reduce disk usage below specified size --vacuum-time=TIME Remove journal files older than specified date --flush Flush all journal data from /run into /var --header Show journal header information --list-catalog Show all message IDs in the catalog --dump-catalog Show entries in the message catalog --update-catalog Update the message catalog database --setup-keys Generate a new FSS key pair --verify Verify journal file consistency","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"systemd","slug":"systemd","permalink":"http://yoursite.com/tags/systemd/"}]},{"title":"Nginx 安装与配置","slug":"nginx","date":"2019-12-30T16:00:00.000Z","updated":"2020-12-04T12:21:29.167Z","comments":true,"path":"2019/12/31/nginx/","link":"","permalink":"http://yoursite.com/2019/12/31/nginx/","excerpt":"","text":"Nginx 安装1. yum 源安装 epel 源 12345yum -y install epel-releaseyum makecacheyum -y install nginxsystemctl enable nginx &amp;&amp; systemctl start nginx nginx 官方源http://nginx.org/en/linux_packages.html#RHEL-CentOS 123456789101112131415161718192021222324252627yum install yum-utilscat &lt; EOF &gt; /etc/yum.repos.d/nginx.repo[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=trueEOFyum-config-manager --enable nginx-stableyum-config-manager --enable nginx-mainlineyum makecacheyum install nginxsystemctl enable nginx &amp;&amp; systemctl start nginx 2. 源码编译安装1[root@nginx nginx-1.16.1]# yum -y install gcc pcre-devel zlib-devel 下载 nginx 源码http://nginx.org/en/download.html 123[root@nginx ~]# wget http://nginx.org/download/nginx-1.16.1.tar.gz[root@nginx ~]# tar -zxvf nginx-1.16.1.tar.gz[root@nginx ~]# cd nginx-1.16.1 configure 参数 根据需求设置编译参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174[root@nginx nginx-1.16.1]# ./configure --help --help print this message --prefix=PATH set installation prefix --sbin-path=PATH set nginx binary pathname --modules-path=PATH set modules path --conf-path=PATH set nginx.conf pathname --error-log-path=PATH set error log pathname --pid-path=PATH set nginx.pid pathname --lock-path=PATH set nginx.lock pathname --user=USER set non-privileged user for worker processes --group=GROUP set non-privileged group for worker processes --build=NAME set build name --builddir=DIR set build directory --with-select_module enable select module --without-select_module disable select module --with-poll_module enable poll module --without-poll_module disable poll module --with-threads enable thread pool support --with-file-aio enable file AIO support --with-http_ssl_module enable ngx_http_ssl_module --with-http_v2_module enable ngx_http_v2_module --with-http_realip_module enable ngx_http_realip_module --with-http_addition_module enable ngx_http_addition_module --with-http_xslt_module enable ngx_http_xslt_module --with-http_xslt_module=dynamic enable dynamic ngx_http_xslt_module --with-http_image_filter_module enable ngx_http_image_filter_module --with-http_image_filter_module=dynamic enable dynamic ngx_http_image_filter_module --with-http_geoip_module enable ngx_http_geoip_module --with-http_geoip_module=dynamic enable dynamic ngx_http_geoip_module --with-http_sub_module enable ngx_http_sub_module --with-http_dav_module enable ngx_http_dav_module --with-http_flv_module enable ngx_http_flv_module --with-http_mp4_module enable ngx_http_mp4_module --with-http_gunzip_module enable ngx_http_gunzip_module --with-http_gzip_static_module enable ngx_http_gzip_static_module --with-http_auth_request_module enable ngx_http_auth_request_module --with-http_random_index_module enable ngx_http_random_index_module --with-http_secure_link_module enable ngx_http_secure_link_module --with-http_degradation_module enable ngx_http_degradation_module --with-http_slice_module enable ngx_http_slice_module --with-http_stub_status_module enable ngx_http_stub_status_module --without-http_charset_module disable ngx_http_charset_module --without-http_gzip_module disable ngx_http_gzip_module --without-http_ssi_module disable ngx_http_ssi_module --without-http_userid_module disable ngx_http_userid_module --without-http_access_module disable ngx_http_access_module --without-http_auth_basic_module disable ngx_http_auth_basic_module --without-http_mirror_module disable ngx_http_mirror_module --without-http_autoindex_module disable ngx_http_autoindex_module --without-http_geo_module disable ngx_http_geo_module --without-http_map_module disable ngx_http_map_module --without-http_split_clients_module disable ngx_http_split_clients_module --without-http_referer_module disable ngx_http_referer_module --without-http_rewrite_module disable ngx_http_rewrite_module --without-http_proxy_module disable ngx_http_proxy_module --without-http_fastcgi_module disable ngx_http_fastcgi_module --without-http_uwsgi_module disable ngx_http_uwsgi_module --without-http_scgi_module disable ngx_http_scgi_module --without-http_grpc_module disable ngx_http_grpc_module --without-http_memcached_module disable ngx_http_memcached_module --without-http_limit_conn_module disable ngx_http_limit_conn_module --without-http_limit_req_module disable ngx_http_limit_req_module --without-http_empty_gif_module disable ngx_http_empty_gif_module --without-http_browser_module disable ngx_http_browser_module --without-http_upstream_hash_module disable ngx_http_upstream_hash_module --without-http_upstream_ip_hash_module disable ngx_http_upstream_ip_hash_module --without-http_upstream_least_conn_module disable ngx_http_upstream_least_conn_module --without-http_upstream_random_module disable ngx_http_upstream_random_module --without-http_upstream_keepalive_module disable ngx_http_upstream_keepalive_module --without-http_upstream_zone_module disable ngx_http_upstream_zone_module --with-http_perl_module enable ngx_http_perl_module --with-http_perl_module=dynamic enable dynamic ngx_http_perl_module --with-perl_modules_path=PATH set Perl modules path --with-perl=PATH set perl binary pathname --http-log-path=PATH set http access log pathname --http-client-body-temp-path=PATH set path to store http client request body temporary files --http-proxy-temp-path=PATH set path to store http proxy temporary files --http-fastcgi-temp-path=PATH set path to store http fastcgi temporary files --http-uwsgi-temp-path=PATH set path to store http uwsgi temporary files --http-scgi-temp-path=PATH set path to store http scgi temporary files --without-http disable HTTP server --without-http-cache disable HTTP cache --with-mail enable POP3/IMAP4/SMTP proxy module --with-mail=dynamic enable dynamic POP3/IMAP4/SMTP proxy module --with-mail_ssl_module enable ngx_mail_ssl_module --without-mail_pop3_module disable ngx_mail_pop3_module --without-mail_imap_module disable ngx_mail_imap_module --without-mail_smtp_module disable ngx_mail_smtp_module --with-stream enable TCP/UDP proxy module --with-stream=dynamic enable dynamic TCP/UDP proxy module --with-stream_ssl_module enable ngx_stream_ssl_module --with-stream_realip_module enable ngx_stream_realip_module --with-stream_geoip_module enable ngx_stream_geoip_module --with-stream_geoip_module=dynamic enable dynamic ngx_stream_geoip_module --with-stream_ssl_preread_module enable ngx_stream_ssl_preread_module --without-stream_limit_conn_module disable ngx_stream_limit_conn_module --without-stream_access_module disable ngx_stream_access_module --without-stream_geo_module disable ngx_stream_geo_module --without-stream_map_module disable ngx_stream_map_module --without-stream_split_clients_module disable ngx_stream_split_clients_module --without-stream_return_module disable ngx_stream_return_module --without-stream_upstream_hash_module disable ngx_stream_upstream_hash_module --without-stream_upstream_least_conn_module disable ngx_stream_upstream_least_conn_module --without-stream_upstream_random_module disable ngx_stream_upstream_random_module --without-stream_upstream_zone_module disable ngx_stream_upstream_zone_module --with-google_perftools_module enable ngx_google_perftools_module --with-cpp_test_module enable ngx_cpp_test_module --add-module=PATH enable external module --add-dynamic-module=PATH enable dynamic external module --with-compat dynamic modules compatibility --with-cc=PATH set C compiler pathname --with-cpp=PATH set C preprocessor pathname --with-cc-opt=OPTIONS set additional C compiler options --with-ld-opt=OPTIONS set additional linker options --with-cpu-opt=CPU build for the specified CPU, valid values: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --without-pcre disable PCRE library usage --with-pcre force PCRE library usage --with-pcre=DIR set path to PCRE library sources --with-pcre-opt=OPTIONS set additional build options for PCRE --with-pcre-jit build PCRE with JIT compilation support --with-zlib=DIR set path to zlib library sources --with-zlib-opt=OPTIONS set additional build options for zlib --with-zlib-asm=CPU use zlib assembler sources optimized for the specified CPU, valid values: pentium, pentiumpro --with-libatomic force libatomic_ops library usage --with-libatomic=DIR set path to libatomic_ops library sources --with-openssl=DIR set path to OpenSSL library sources --with-openssl-opt=OPTIONS set additional build options for OpenSSL --with-debug enable debug logging 123456789101112131415161718192021222324[root@nginx nginx-1.16.1]# mkdir nginx-src[root@nginx nginx-1.16.1]# ./configure --prefix=$PWD/nginx-src[root@nginx nginx-1.16.1]# make &amp;&amp; make install[root@nginx nginx-1.16.1]# ./nginx-src/sbin/nginx -vnginx version: nginx/1.16.1[root@nginx nginx-1.16.1]# ldd ./nginx-src/sbin/nginx linux-vdso.so.1 =&gt; (0x00007fff44dea000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f9d0b173000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f9d0af57000) libcrypt.so.1 =&gt; /lib64/libcrypt.so.1 (0x00007f9d0ad20000) libpcre.so.1 =&gt; /lib64/libpcre.so.1 (0x00007f9d0aabe000) libz.so.1 =&gt; /lib64/libz.so.1 (0x00007f9d0a8a8000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f9d0a4da000) /lib64/ld-linux-x86-64.so.2 (0x00007f9d0b377000) libfreebl3.so =&gt; /lib64/libfreebl3.so (0x00007f9d0a2d7000)[root@nginx nginx-1.16.1]# mv nginx-src/ /opt/nginx[root@nginx nginx-1.16.1]# ll /opt/nginx/总用量 0drwxr-xr-x 2 root root 333 1月 1 06:50 confdrwxr-xr-x 2 root root 40 1月 1 06:50 htmldrwxr-xr-x 2 root root 6 1月 1 06:50 logsdrwxr-xr-x 2 root root 19 1月 1 06:50 sbin 创建 nginx.service 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@nginx ~]# cat &lt; EOF &gt; nginx.service[Unit]Description=Nginx ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=forkingExecStartPre=/opt/nginx/sbin/nginx -c /opt/nginx/conf/nginx.conf -p /opt/nginx -tExecStart=/opt/nginx/sbin/nginx -c /opt/nginx/conf/nginx.conf -p /opt/nginxExecReload=/opt/nginx/sbin/nginx -c /opt/nginx/conf/nginx.conf -p /opt/nginx -s reloadPrivateTmp=trueRestart=alwaysRestartSec=5StartLimitInterval=0LimitNOFILE=65536[Install]WantedBy=multi-user.targetEOF[root@nginx ~]# cp nginx.service /etc/systemd/system/[root@nginx ~]# systemctl enable nginx &amp;&amp; systemctl start nginx[root@nginx ~]# systemctl status nginx● nginx.service - Nginx Server Loaded: loaded (/etc/systemd/system/nginx.service; disabled; vendor preset: disabled) Active: active (running) since 三 2020-01-01 06:59:14 CST; 5s ago Process: 10052 ExecStart=/opt/nginx/sbin/nginx -c /opt/nginx/conf/nginx.conf -p /opt/nginx (code=exited, status=0/SUCCESS) Process: 10051 ExecStartPre=/opt/nginx/sbin/nginx -c /opt/nginx/conf/nginx.conf -p /opt/nginx -t (code=exited, status=0/SUCCESS) Main PID: 10053 (nginx) CGroup: /system.slice/nginx.service ├─10053 nginx: master process /opt/nginx/sbin/nginx -c /opt/nginx/conf/nginx.conf... └─10054 nginx: worker process1月 01 06:59:14 nginx systemd[1]: Starting Nginx Server...1月 01 06:59:14 nginx nginx[10051]: nginx: the configuration file /opt/nginx/conf/nginx.... ok1月 01 06:59:14 nginx nginx[10051]: nginx: configuration file /opt/nginx/conf/nginx.conf...ful1月 01 06:59:14 nginx systemd[1]: Started Nginx Server.Hint: Some lines were ellipsized, use -l to show in full.[root@nginx ~]# netstat -ntlp | grep nginxtcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 10053/nginx: master Nginx 配置1.1 HTTP Load Balancing 使用 NGINX 的 HTTP 模块使用 upstream 块在 HTTP 服务器上进行负载均衡 123456789upstream backend &#123; server 10.10.12.45:80 weight&#x3D;1; server app.example.com:80 weight&#x3D;2;&#125;server &#123; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;backend; &#125;&#125; 1.2 TCP Load Balancing 使用 NGINX 的 stream 模块使用 upstream 块在 TCP 服务器上进行负载均衡 123456789101112stream &#123; upstream mysql_read &#123; server read1.example.com:3306 weight&#x3D;5; server read2.example.com:3306; server 10.10.12.34:3306 backup; &#125; server &#123; listen 3306; proxy_pass mysql_read; &#125;&#125; 1.3 Load-Balancing 方法 使用 NGINX 的负载平衡方法之一，例如least_conn, least_time, hash, ip_hash 这里将后端 upstream 池的负载平衡算法设置为最少连接。所有负载平衡算法（通用散列除外）都将是独立的指令，如前面的示例。通用散列采用单个参数（可以是变量的串联）来构建散列。 12345upstream backend &#123; least_conn; server backend.example.com; server backend1.example.com;&#125; 并非所有请求或数据包都具有相同的权重。鉴于此，循环，甚至是先前示例中使用的加权循环，将不适合所有应用程序或交通流量的需要。NGINX提供了许多负载平衡算法，可用于适应特定的用例。 这些负载平衡算法或方法不仅可以选择，还可以配置。 以下负载平衡方法可用于 upstream HTTP，TCP 和 UDP 池： Round robin（轮询）：默认负载平衡方法，按 upstream 池中服务器列表的顺序分配请求。对于加权循环，可以考虑权重，如果 upstream 服务器的容量变化，则可以使用加权循环。 权重的整数值越高，服务器在循环中的优势就越大。权重背后的算法只是加权平均的统计概率。循环法是默认的负载平衡算法，如果未指定其他算法，则使用该算法。 Least connections（）：另一种由 NGINX 提供的负载均衡方法。此方法通过将当前请求代理到具有通过 NGINX 代理的最少数量的打开连接的upstream服务器来平衡负载。在决定向哪个服务器发送连接时，最小连接（如循环）也会考虑权重。指令名称为 least_conn。 Least time（）：仅在 NGINX Plus 中可用，类似于最少连接，因为它代理具有最少数量的当前连接的upstream 服务器，但有利于具有最低平均响应时间的服务器。这种方法是最复杂的负载平衡算法之一，可满足高性能 Web 应用程序的需求。此算法是一个增加最少连接的值，因为少量连接并不一定意味着最快的响应。指令名称为 least_time。 Generic hash（）：管理员使用给定文本，请求或运行时的变量或两者来定义散列。NGINX 通过为当前请求生成哈希并将其放在 upstream 服务器上来分配服务器之间的负载。当您需要更多地控制发送请求的位置或确定哪些 upstream 服务器最有可能将数据缓存时，此方法非常有用。请注意，在池中添加或删除服务器时，将重新分配散列请求。该算法具有可选参数，一致，以最小化重新分布的影响。指令名称是 hash。 IP hash（）：仅支持HTTP，是最后一批。IP 哈希使用客户端 IP 地址作为哈希。与在通用散列中使用远程变量略有不同，此算法使用 IPv4 地址的前三个八位字节或整个 IPv6 地址。只要该服务器可用，此方法可确保客户端代理到同一个 upstream 服务器，这在会话状态受到关注且未由应用程序的共享内存处理时非常有用。 在分配散列时，此方法还会考虑权重参数。 指令名称为 ip_hash。 1.4 Connection Limiting 使用 NGINX Plus 的 max_conns 参数限制 upstream 服务器的连接数 1234567upstream backend &#123; zone backends 64k; queue 750 timeout&#x3D;30s; server webserver1.example.com max_conns&#x3D;25; server webserver2.example.com max_conns&#x3D;15;&#125;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"OpenLDAP 安装指南","slug":"openldap","date":"2019-12-26T16:00:00.000Z","updated":"2020-12-04T11:24:29.140Z","comments":true,"path":"2019/12/27/openldap/","link":"","permalink":"http://yoursite.com/2019/12/27/openldap/","excerpt":"CentOS 7 OpenLDAP 安装配置指南","text":"CentOS 7 OpenLDAP 安装配置指南 1. 安装 openldap1[root@ldap ~]# yum -y install openldap compat-openldap openldap-clients openldap-servers openldap-servers-sql openldap-devel migrationtools 查看版本123[root@ldap ~]# slapd -VV@(#) $OpenLDAP: slapd 2.4.44 (Jan 29 2019 17:42:45) $ mockbuild@x86-01.bsys.centos.org:/builddir/build/BUILD/openldap-2.4.44/openldap-2.4.44/servers/slapd 为默认用户设置密码1234[root@ldap ~]# slappasswdNew password:Re-enter new password:&#123;SSHA&#125;P+NaHJ1IQAM/17rDCIK8i2Klm3rStDVo 2. 配置 openldap修改 olcDatabase={2}hdb.ldif 文件1[root@ldap ~]# vim /etc/openldap/slapd.d/cn\\=config/olcDatabase\\=\\&#123;2\\&#125;hdb.ldif 12345678910111213141516171819202122# AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify.# CRC32 2df1c260dn: olcDatabase=&#123;2&#125;hdbobjectClass: olcDatabaseConfigobjectClass: olcHdbConfigolcDatabase: &#123;2&#125;hdbolcDbDirectory: /var/lib/ldap# olcSuffix: dc=my-domain,dc=comolcSuffix: dc=example,dc=com# olcRootDN: cn=Manager,dc=my-domain,dc=comolcRootDN: cn=Manager,dc=example,dc=comolcDbIndex: objectClass eq,presolcDbIndex: ou,cn,mail,surname,givenname eq,pres,substructuralObjectClass: olcHdbConfigentryUUID: 7b00e3c0-bcc6-1039-927c-c144385599c7creatorsName: cn=configcreateTimestamp: 20191227073020ZentryCSN: 20191227073020.070906Z#000000#000#000000modifiersName: cn=configmodifyTimestamp: 20191227073020Z# addolcRootPW: &#123;SSHA&#125;P+NaHJ1IQAM/17rDCIK8i2Klm3rStDVo 修改 olcDatabase={1}monitor.ldif 文件1[root@ldap ~]# vim /etc/openldap/slapd.d/cn\\=config/olcDatabase\\=\\&#123;1\\&#125;monitor.ldif 12345678910111213141516# AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify.# CRC32 cdc0bae3dn: olcDatabase=&#123;1&#125;monitorobjectClass: olcDatabaseConfigolcDatabase: &#123;1&#125;monitor# olcAccess: &#123;0&#125;to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=extern# al,cn=auth\" read by dn.base=\"cn=Manager,dc=my-domain,dc=com\" read by * noneolcAccess: &#123;0&#125;to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=extern al,cn=auth\" read by dn.base=\"cn=Manager,dc=example,dc=com\" read by * nonestructuralObjectClass: olcDatabaseConfigentryUUID: 7b00dc72-bcc6-1039-927b-c144385599c7creatorsName: cn=configcreateTimestamp: 20191227073020ZentryCSN: 20191227073020.070787Z#000000#000#000000modifiersName: cn=configmodifyTimestamp: 20191227073020Z 验证配置文件是否正确1234[root@ldap ~]# slaptest -u5e05b57d ldif_read_file: checksum error on \"/etc/openldap/slapd.d/cn=config/olcDatabase=&#123;1&#125;monitor.ldif\"5e05b57d ldif_read_file: checksum error on \"/etc/openldap/slapd.d/cn=config/olcDatabase=&#123;2&#125;hdb.ldif\"config file testing succeeded 启动服务并设置开机启动12345678910111213141516171819202122232425262728[root@ldap ~]# systemctl start slapd &amp;&amp; systemctl enable slapd[root@ldap ~]# systemctl status slapd● slapd.service - OpenLDAP Server Daemon Loaded: loaded (/usr/lib/systemd/system/slapd.service; enabled; vendor preset: disabled) Active: active (running) since 五 2019-12-27 15:41:35 CST; 4s ago Docs: man:slapd man:slapd-config man:slapd-hdb man:slapd-mdb file:///usr/share/doc/openldap-servers/guide.html Process: 1783 ExecStart=/usr/sbin/slapd -u ldap -h $&#123;SLAPD_URLS&#125; $SLAPD_OPTIONS (code=exited, status=0/SUCCESS) Process: 1768 ExecStartPre=/usr/libexec/openldap/check-config.sh (code=exited, status=0/SUCCESS) Main PID: 1786 (slapd) CGroup: /system.slice/slapd.service └─1786 /usr/sbin/slapd -u ldap -h ldapi:/// ldap:///12月 27 15:41:32 ldap.example.com systemd[1]: Starting OpenLDAP Server Daemon...12月 27 15:41:32 ldap.example.com runuser[1771]: pam_unix(runuser:session): session opened for user ldap by (uid=0)12月 27 15:41:35 ldap.example.com slapd[1783]: @(#) $OpenLDAP: slapd 2.4.44 (Jan 29 2019 17:42:45) $ mockbuild@x86-01.bsys.centos.org:/builddir/build/BUILD/openldap-2.4.44/openldap-2.4.44/servers/slapd12月 27 15:41:35 ldap.example.com slapd[1783]: ldif_read_file: checksum error on \"/etc/openldap/slapd.d/cn=config/olcDatabase=&#123;1&#125;monitor.ldif\"12月 27 15:41:35 ldap.example.com slapd[1783]: ldif_read_file: checksum error on \"/etc/openldap/slapd.d/cn=config/olcDatabase=&#123;2&#125;hdb.ldif\"12月 27 15:41:35 ldap.example.com slapd[1783]: tlsmc_get_pin: INFO: Please note the extracted key file will not be protected with a PIN any more, however it will be still prot...permissions.12月 27 15:41:35 ldap.example.com slapd[1786]: hdb_db_open: warning - no DB_CONFIG file found in directory /var/lib/ldap: (2). Expect poor performance for suffix \"dc=example,dc=com\".12月 27 15:41:35 ldap.example.com slapd[1786]: slapd starting12月 27 15:41:35 ldap.example.com systemd[1]: Started OpenLDAP Server Daemon.Hint: Some lines were ellipsized, use -l to show in full. 查看监听端口123[root@ldap ~]# netstat -ntlp | grep slapdtcp 0 0 0.0.0.0:389 0.0.0.0:* LISTEN 1786/slapdtcp6 0 0 :::389 :::* LISTEN 1786/slapd 配置 openldap 数据库12345678910111213[root@ldap ~]# cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG[root@ldap ~]# chown ldap:ldap -R /var/lib/ldap[root@ldap ~]# chmod 700 -R /var/lib/ldap[root@ldap ~]# ll /var/lib/ldap/总用量 324-rwx------. 1 ldap ldap 2048 12月 27 15:41 alock-rwx------. 1 ldap ldap 262144 12月 27 15:41 __db.001-rwx------. 1 ldap ldap 32768 12月 27 15:41 __db.002-rwx------. 1 ldap ldap 49152 12月 27 15:41 __db.003-rwx------. 1 ldap ldap 845 12月 27 15:44 DB_CONFIG-rwx------. 1 ldap ldap 8192 12月 27 15:41 dn2id.bdb-rwx------. 1 ldap ldap 32768 12月 27 15:41 id2entry.bdb-rwx------. 1 ldap ldap 10485760 12月 27 15:41 log.0000000001 导入基本 schema1234567891011121314151617[root@ldap ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry \"cn=cosine,cn=schema,cn=config\"[root@ldap ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry \"cn=nis,cn=schema,cn=config\"[root@ldap ~]# ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0adding new entry \"cn=inetorgperson,cn=schema,cn=config\" 3. 开启 openldap 日志访问功能 默认情况下 openldap 没有启用日志记录功能，在实际使用过程中，为了定位问题，需要使用到 openldap 日志。 123456[root@ldap ~]# cat &gt; /root/loglevel.ldif &lt;&lt; \"EOF\"dn: cn=configchangetype: modifyreplace: olcLogLevelolcLogLevel: statsEOF 1234567[root@ldap ~]# ldapmodify -Y EXTERNAL -H ldapi:/// -f /root/loglevel.ldifSASL/EXTERNAL authentication startedSASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=authSASL SSF: 0modifying entry \"cn=config\"[root@ldap ~]# systemctl restart slapd 1234[root@ldap ~]# cat &gt;&gt; /etc/rsyslog.conf &lt;&lt; \"EOF\"local4.* /var/log/slapd.logEOF[root@ldap ~]# systemctl restart rsyslog 4. 安装和配置 phpldapadmin1[root@ldap ~]# yum -y install httpd php php-ldap php-gd php-mbstring php-pear php-bcmath php-xml 12[root@ldap ~]# yum -y install epel-release[root@ldap ~]# yum -y install phpldapadmin 修改配置文件 1[root@ldap ~]# vim /etc/phpldapadmin/config.php 12397 $servers-&gt;setValue('login','attr','dn');398 // $servers-&gt;setValue('login','attr','uid'); 1[root@ldap ~]# vim /etc/httpd/conf.d/phpldapadmin.conf 123456789101112131415161718192021## Web-based tool for managing LDAP servers#Alias /phpldapadmin /usr/share/phpldapadmin/htdocsAlias /ldapadmin /usr/share/phpldapadmin/htdocs&lt;Directory /usr/share/phpldapadmin/htdocs&gt; &lt;IfModule mod_authz_core.c&gt; # Apache 2.4 Require local Require ip 192.168.33.1 &lt;/IfModule&gt; &lt;IfModule !mod_authz_core.c&gt; # Apache 2.2 Order Deny,Allow Deny from all Allow from 127.0.0.1 Allow from ::1 &lt;/IfModule&gt;&lt;/Directory&gt; 启动服务并设置开机启动 1[root@ldap ~]# systemctl enable httpd &amp;&amp; systemctl start httpd 浏览器访问 主页 登陆 导航 5. 添加用户修改 /usr/share/migrate_common.ph 文件1[root@ldap ~]# vim /usr/share/migrationtools/migrate_common.ph 123456789101112131415161718192021222324# Default DNS domain# $DEFAULT_MAIL_DOMAIN = \"padl.com\";$DEFAULT_MAIL_DOMAIN = \"example.com\";# Default base# $DEFAULT_BASE = \"dc=padl,dc=com\";$DEFAULT_BASE = \"dc=example,dc=com\";# Turn this on for inetLocalMailReceipient# sendmail support; add the following to# sendmail.mc (thanks to Petr@Kristof.CZ):##### CUT HERE ######define(`confLDAP_DEFAULT_SPEC',`-h \"ldap.padl.com\"')dnl#LDAPROUTE_DOMAIN_FILE(`/etc/mail/ldapdomains')dnl#FEATURE(ldap_routing)dnl##### CUT HERE ###### where /etc/mail/ldapdomains contains names of ldap_routed# domains (similiar to MASQUERADE_DOMAIN_FILE).# $DEFAULT_MAIL_HOST = \"mail.padl.com\";# turn this on to support more general object clases# such as person.# $EXTENDED_SCHEMA = 0;$EXTENDED_SCHEMA = 1; 添加用户及用户组1234[root@ldap ~]# groupadd ldapgroup1[root@ldap ~]# groupadd ldapgroup2[root@ldap ~]# useradd -g ldapgroup1 ldapuser1[root@ldap ~]# useradd -g ldapgroup2 ldapuser2 12[root@ldap ~]# echo \"ldap\" | passwd --stdin ldapuser1[root@ldap ~]# echo \"ldap\" | passwd --stdin ldapuser2 提取用户和组1234567891011[root@ldap ~]# cat /etc/passwd | grep ldapuser &gt; users[root@ldap ~]# cat usersldapuser1:x:1000:1000::/home/ldapuser1:/bin/bashldapuser2:x:1001:1001::/home/ldapuser2:/bin/bash[root@ldap ~]# cat /etc/group | grep ldapgroup &gt; groups[root@ldap ~]# cat groupsldapgroup1:x:1000:ldapgroup2:x:1001: 生成用户和组的 ldif 文件12[root@ldap ~]# /usr/share/migrationtools/migrate_passwd.pl /root/users &gt; /root/users.ldif[root@ldap ~]# /usr/share/migrationtools/migrate_group.pl /root/groups &gt; /root/groups.ldif 123456789101112131415161718192021222324252627282930313233343536373839404142[root@ldap ~]# cat users.ldifdn: uid=ldapuser1,ou=People,dc=example,dc=comuid: ldapuser1cn: ldapuser1sn: ldapuser1mail: ldapuser1@example.comobjectClass: personobjectClass: organizationalPersonobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountuserPassword: &#123;crypt&#125;$6$ab3EWxCv$w/1qc6F3.z4PT0CLHQeqCQdxEUxbKHQBboBFprgz3HdaoJ8flCSmSjQ7yhTzGCoB3wUhJYT6bSVkpJENqPNtq/shadowLastChange: 18257shadowMin: 0shadowMax: 99999shadowWarning: 7loginShell: /bin/bashuidNumber: 1000gidNumber: 1000homeDirectory: /home/ldapuser1dn: uid=ldapuser2,ou=People,dc=example,dc=comuid: ldapuser2cn: ldapuser2sn: ldapuser2mail: ldapuser2@example.comobjectClass: personobjectClass: organizationalPersonobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountuserPassword: &#123;crypt&#125;$6$Lh9DKEZ0$qHpMrkzDYLuGhYmq4OLY2uuxv1Oj8TgiwsYs9CKPTMw0kzwGs0EekygLca27hHozJ04AMxE3cONNovcCrwti2/shadowLastChange: 18257shadowMin: 0shadowMax: 99999shadowWarning: 7loginShell: /bin/bashuidNumber: 1001gidNumber: 1001homeDirectory: /home/ldapuser2 1234567891011121314[root@ldap ~]# cat groups.ldifdn: cn=ldapgroup1,ou=Group,dc=example,dc=comobjectClass: posixGroupobjectClass: topcn: ldapgroup1userPassword: &#123;crypt&#125;xgidNumber: 1000dn: cn=ldapgroup2,ou=Group,dc=example,dc=comobjectClass: posixGroupobjectClass: topcn: ldapgroup2userPassword: &#123;crypt&#125;xgidNumber: 1001 导入用户及用户组到 openldap 数据库 尽管已经把用户和用户组信息导入到 openldap 数据库中。但目前 openldap 用户和组之间是没有任何关联的。要把 openldap 数据库中用户和组关联起来需要做单独配置 导入基础数据库 1234567891011121314151617181920212223[root@ldap ~]# cat &gt; /root/base.ldif &lt;&lt; EOFdn: dc=example,dc=como: example comdc: exampleobjectClass: topobjectClass: dcObjectobjectclass: organizationdn: cn=Manager,dc=example,dc=comcn: ManagerobjectClass: organizationalRoledescription: Directory Managerdn: ou=People,dc=example,dc=comou: PeopleobjectClass: topobjectClass: organizationalUnitdn: ou=Group,dc=example,dc=comou: GroupobjectClass: topobjectClass: organizationalUnitEOF 12345678[root@ldap ~]# ldapadd -x -w \"ldap\" -D \"cn=Manager,dc=example,dc=com\" -f /root/base.ldifadding new entry \"dc=example,dc=com\"adding new entry \"cn=Manager,dc=example,dc=com\"adding new entry \"ou=People,dc=example,dc=com\"adding new entry \"ou=Group,dc=example,dc=com\" 导入用户 1234[root@ldap ~]# ldapadd -x -w \"ldap\" -D \"cn=Manager,dc=example,dc=com\" -f /root/users.ldifadding new entry \"uid=ldapuser1,ou=People,dc=example,dc=com\"adding new entry \"uid=ldapuser2,ou=People,dc=example,dc=com\" 导入组 1234[root@ldap ~]# ldapadd -x -w \"ldap\" -D \"cn=Manager,dc=example,dc=com\" -f /root/groups.ldifadding new entry \"cn=ldapgroup1,ou=Group,dc=example,dc=com\"adding new entry \"cn=ldapgroup2,ou=Group,dc=example,dc=com\" 将用户加入到用户组 1234567891011[root@ldap ~]# cat &gt; add_user_to_groups.ldif &lt;&lt; \"EOF\"dn: cn=ldapgroup1,ou=Group,dc=example,dc=comchangetype: modifyadd: memberuidmemberuid: ldapuser1dn: cn=ldapgroup2,ou=Group,dc=example,dc=comchangetype: modifyadd: memberuidmemberuid: ldapuser2EOF 123[root@ldap ~]# ldapadd -x -w \"ldap\" -D \"cn=Manager,dc=example,dc=com\" -f /root/add_user_to_groups.ldifmodifying entry \"cn=ldapgroup1,ou=Group,dc=example,dc=com\"modifying entry \"cn=ldapgroup2,ou=Group,dc=example,dc=com\" 1234567891011121314151617[root@ldap ~]# ldapsearch -LLL -x -D 'cn=Manager,dc=example,dc=com' -w \"ldap\" -b 'dc=example,dc=com' 'cn=ldapgroup1'dn: cn=ldapgroup1,ou=Group,dc=example,dc=comobjectClass: posixGroupobjectClass: topcn: ldapgroup1userPassword:: e2NyeXB0fXg=gidNumber: 1000memberUid: ldapuser1[root@ldap ~]# ldapsearch -LLL -x -D 'cn=Manager,dc=example,dc=com' -w \"ldap\" -b 'dc=example,dc=com' 'cn=ldapgroup2'dn: cn=ldapgroup2,ou=Group,dc=example,dc=comobjectClass: posixGroupobjectClass: topcn: ldapgroup2userPassword:: e2NyeXB0fXg=gidNumber: 1001memberUid: ldapuser2 phpldapadmin 导航","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"ldap","slug":"ldap","permalink":"http://yoursite.com/tags/ldap/"}]},{"title":"Git Hooks","slug":"git_hooks","date":"2019-12-20T08:51:16.000Z","updated":"2020-12-04T11:24:29.128Z","comments":true,"path":"2019/12/20/git_hooks/","link":"","permalink":"http://yoursite.com/2019/12/20/git_hooks/","excerpt":"Git Hooks - 在特定的重要动作发生时触发自定义脚本。","text":"Git Hooks - 在特定的重要动作发生时触发自定义脚本。 配置一个钩子钩子都被存储在 Git 目录下的 hooks 子目录中。 即项目中的 .git/hooks 。 当你用 git init 初始化一个新版本库时，Git 默认会在这个目录中放置一些示例脚本。这些脚本除了本身可以被调用外，它们还透露了被触发时所传入的参数。 所有的示例都是 shell 脚本，其中一些还混杂了 Perl 代码，不过，任何正确命名的可执行脚本都可以正常使用 —— 你可以用 Ruby 或 Python，或其它语言编写它们。 这些示例的名字都是以 .sample 结尾，如果你想启用它们，得先移除这个后缀。 把一个正确命名且可执行的文件放入 Git 目录下的 hooks 子目录中 .git/hooks，即可激活该钩子脚本。 这样一来，它就能被 Git 调用。 客户端钩子客户端钩子分为很多种。 下面把它们分为：提交工作流钩子、电子邮件工作流钩子和其它钩子。 123456789101112applypatch-msg.samplecommit-msg.samplefsmonitor-watchman.samplepost-update.samplepre-applypatch.samplepre-commit.samplepre-merge-commit.samplepre-push.samplepre-rebase.samplepre-receive.sampleprepare-commit-msg.sampleupdate.sample 提交工作流钩子 pre-commit 钩子在键入提交信息前运行。 它用于检查即将提交的快照，例如，检查是否有所遗漏，确保测试运行，以及核查代码。 如果该钩子以非零值退出，Git 将放弃此次提交，不过你可以用 git commit --no-verify 来绕过这个环节。 你可以利用该钩子，来检查代码风格是否一致（运行类似 lint 的程序）、尾随空白字符是否存在（自带的钩子就是这么做的），或新方法的文档是否适当。 prepare-commit-msg 钩子在启动提交信息编辑器之前，默认信息被创建之后运行。 它允许你编辑提交者所看到的默认信息。 该钩子接收一些选项：存有当前提交信息的文件的路径、提交类型和修补提交的提交的 SHA-1 校验。 它对一般的提交来说并没有什么用；然而对那些会自动产生默认信息的提交，如提交信息模板、合并提交、压缩提交和修订提交等非常实用。 你可以结合提交模板来使用它，动态地插入信息。 commit-msg 钩子接收一个参数，此参数即上文提到的，存有当前提交信息的临时文件的路径。 如果该钩子脚本以非零值退出，Git 将放弃提交，因此，可以用来在提交通过前验证项目状态或提交信息。 在本章的最后一节，我们将展示如何使用该钩子来核对提交信息是否遵循指定的模板。 post-commit钩子在整个提交过程完成后运行。 它不接收任何参数，但你可以很容易地通过运行 git log -1 HEAD 来获得最后一次的提交信息。 该钩子一般用于通知之类的事情。 电子邮件工作流钩子 你可以给电子邮件工作流设置三个客户端钩子。 它们都是由 git am 命令调用的，因此如果你没有在你的工作流中用到这个命令，可以跳到下一节。 如果你需要通过电子邮件接收由 git format-patch 产生的补丁，这些钩子也许用得上。 applypatch-msg 它接收单个参数：包含请求合并信息的临时文件的名字。 如果脚本返回非零值，Git 将放弃该补丁。 你可以用该脚本来确保提交信息符合格式，或直接用脚本修正格式错误。 pre-applypatch 有些难以理解的是，它正好运行于应用补丁 之后，产生提交之前，所以你可以用它在提交前检查快照。 你可以用这个脚本运行测试或检查工作区。 如果有什么遗漏，或测试未能通过，脚本会以非零值退出，中断 git am 的运行，这样补丁就不会被提交。 post-applypatch 运行于提交产生之后，是在 git am 运行期间最后被调用的钩子。 你可以用它把结果通知给一个小组或所拉取的补丁的作者。 但你没办法用它停止打补丁的过程。 其它客户端钩子 pre-rebase 钩子运行于变基之前，以非零值退出可以中止变基的过程。 你可以使用这个钩子来禁止对已经推送的提交变基。 Git 自带的 pre-rebase 钩子示例就是这么做的，不过它所做的一些假设可能与你的工作流程不匹配。 post-rewrite 钩子被那些会替换提交记录的命令调用，比如 git commit –amend 和 git rebase（不过不包括 git filter-branch）。 它唯一的参数是触发重写的命令名，同时从标准输入中接受一系列重写的提交记录。 这个钩子的用途很大程度上跟 post-checkout 和 post-merge 差不多。 post-checkout 在 git checkout 成功运行后，post-checkout 钩子会被调用。你可以根据你的项目环境用它调整你的工作目录。 其中包括放入大的二进制文件、自动生成文档或进行其他类似这样的操作。 post-merge 在 git merge 成功运行后，post-merge 钩子会被调用。 你可以用它恢复 Git 无法跟踪的工作区数据，比如权限数据。 这个钩子也可以用来验证某些在 Git 控制之外的文件是否存在，这样你就能在工作区改变时，把这些文件复制进来。 pre-push pre-push 钩子会在 git push 运行期间， 更新了远程引用但尚未传送对象时被调用。 它接受远程分支的名字和位置作为参数，同时从标准输入中读取一系列待更新的引用。 你可以在推送开始之前，用它验证对引用的更新操作（一个非零的退出码将终止推送过程）。 pre-auto-gc Git 的一些日常操作在运行时，偶尔会调用 git gc --auto 进行垃圾回收。 pre-auto-gc 钩子会在垃圾回收开始之前被调用，可以用它来提醒你现在要回收垃圾了，或者依情形判断是否要中断回收。 服务器端钩子除了客户端钩子，作为系统管理员，你还可以使用若干服务器端的钩子对项目强制执行各种类型的策略。 这些钩子脚本在推送到服务器之前和之后运行。 推送到服务器前运行的钩子可以在任何时候以非零值退出，拒绝推送并给客户端返回错误消息，还可以依你所想设置足够复杂的推送策略。 123456789applypatch-msg.samplecommit-msg.samplepost-update.samplepre-applypatch.samplepre-commit.sampleprepare-commit-msg.samplepre-push.samplepre-rebase.sampleupdate.sample pre-receive 处理来自客户端的推送操作时，最先被调用的脚本是 pre-receive。 它从标准输入获取一系列被推送的引用。如果它以非零值退出，所有的推送内容都不会被接受。 你可以用这个钩子阻止对引用进行非快进（non-fast-forward）的更新，或者对该推送所修改的所有引用和文件进行访问控制。 update update 脚本和 pre-receive 脚本十分类似，不同之处在于它会为每一个准备更新的分支各运行一次。 假如推送者同时向多个分支推送内容，pre-receive 只运行一次，相比之下 update 则会为每一个被推送的分支各运行一次。 它不会从标准输入读取内容，而是接受三个参数：引用的名字（分支），推送前的引用指向的内容的 SHA-1 值，以及用户准备推送的内容的 SHA-1 值。 如果 update 脚本以非零值退出，只有相应的那一个引用会被拒绝；其余的依然会被更新。 post-receive post-receive 挂钩在整个过程完结以后运行，可以用来更新其他系统服务或者通知用户。 它接受与 pre-receive 相同的标准输入数据。 它的用途包括给某个邮件列表发信，通知持续集成（continous integration）的服务器，或者更新问题追踪系统（ticket-tracking system） —— 甚至可以通过分析提交信息来决定某个问题（ticket）是否应该被开启，修改或者关闭。 该脚本无法终止推送进程，不过客户端在它结束运行之前将保持连接状态，所以如果你想做其他操作需谨慎使用它，因为它将耗费你很长的一段时间。","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"在服务器上搭建 Git","slug":"git_in_server","date":"2019-12-19T16:00:00.000Z","updated":"2020-12-04T12:25:14.481Z","comments":true,"path":"2019/12/20/git_in_server/","link":"","permalink":"http://yoursite.com/2019/12/20/git_in_server/","excerpt":"服务器上的 Git - 在服务器上搭建 Git","text":"服务器上的 Git - 在服务器上搭建 Git 在服务器上创建裸仓库假设一个域名为 git.example.com 的服务器已经架设好，并可以通过 SSH 连接，你想把所有的 Git 仓库放在 /opt/git 目录下。 1234567891011121314# 创建 git 用户[root@git ~]# useradd git -m -d /opt/git[root@git ~]# echo \"git\" | passwd --stdin git更改用户 git 的密码 。passwd：所有的身份验证令牌已经成功更新。[root@git ~]# su - git[git@git ~]$ pwd/opt/git[git@git ~]$ git init --bare project.git初始化空的 Git 版本库于 /opt/git/project.git/ 客户端配置连接客户端如果一个用户，通过使用 SSH 连接到一个服务器，并且其对 /opt/git/project.git 目录拥有可写权限，那么他将自动拥有推送权限。（这里我们默认使用 git 用户） 12345678910111213141516171819202122232425ssh-copy-id git@git.example.comgit clone git@git.example.com:/opt/git/project.git正克隆到 'project'...warning: 您似乎克隆了一个空仓库。cd projectecho \"## project\" &gt; README.mdgit add .git commit -m \"initial new project\"[master（根提交） 1304197] initial new project 1 file changed, 1 insertion(+) create mode 100644 README.mdgit push枚举对象: 3, 完成.对象计数中: 100% (3/3), 完成.写入对象中: 100% (3/3), 226 字节 | 226.00 KiB/s, 完成.总共 3 （差异 0），复用 0 （差异 0）To git.example.com:/opt/git/project.git * [new branch] master -&gt; master 服务器端返回服务端查看文件变化 123456789[git@git ~]$ ls -1 project.git/branchesconfigdescriptionHEADhooksinfoobjectsrefs","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"Jenkins 入门指南","slug":"jenkins","date":"2019-12-19T16:00:00.000Z","updated":"2020-12-04T12:18:17.181Z","comments":true,"path":"2019/12/20/jenkins/","link":"","permalink":"http://yoursite.com/2019/12/20/jenkins/","excerpt":"","text":"Jenkins 安装方法1. 使用 yum 安装（Redhat/CentOS/Fedora）12345678910111213141516171819202122[root@jenkins ~]# wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo[root@jenkins ~]# rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key[root@jenkins ~]# yum -y install jenkins[root@jenkins ~]# systemctl start jenkins[root@jenkins ~]# systemctl status jenkins● jenkins.service - LSB: Jenkins Automation Server Loaded: loaded (/etc/rc.d/init.d/jenkins; bad; vendor preset: disabled) Active: active (running) since 五 2019-12-20 10:37:48 CST; 6s ago Docs: man:systemd-sysv-generator(8) Process: 8910 ExecStart=/etc/rc.d/init.d/jenkins start (code=exited, status=0/SUCCESS) Tasks: 48 Memory: 442.5M CGroup: /system.slice/jenkins.service └─8934 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jen...12月 20 10:37:47 jenkins systemd[1]: Starting LSB: Jenkins Automation Server...12月 20 10:37:47 jenkins runuser[8915]: pam_unix(runuser:session): session opened for user jenkins by (uid=0)12月 20 10:37:48 jenkins runuser[8915]: pam_unix(runuser:session): session closed for user jenkins12月 20 10:37:48 jenkins jenkins[8910]: Starting Jenkins [ 确定 ]12月 20 10:37:48 jenkins systemd[1]: Started LSB: Jenkins Automation Server. 通过 &lt;IP&gt;:&lt;PORT&gt; 访问 Jenkins 获取 initialAdminPassword 1[root@jenkins ~]# cat /var/lib/jenkins/secrets/initialAdminPassword 方法2. 使用 Docker 安装123[root@jenkins ~]# docker pull jenkinsci/blueocean[root@jenkins ~]# docker run -u root -p 8080:8080 -v jenkins_home:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock -v \"$HOME\":/home --name jenkins -d jenkinsci/blueocean 通过 &lt;IP&gt;:&lt;PORT&gt; 访问 Jenkins 获取 initialAdminPassword 123456789101112# 通过 docker logs 获取[root@jenkins ~]# docker logs jenkins...Jenkins initial setup is required. An admin user has been created and a password generated.Please use the following password to proceed to installation:95538a82714644d5a4b5d84c6f998a4fThis may also be found at: /var/jenkins_home/secrets/initialAdminPassword... 123# 进入容器内部获取 initialAdminPassword[root@jenkins ~]# docker exec -it jenkins /bin/bashbash-4.4# cat /var/jenkins_home/secrets/initialAdminPassword 安装推荐插件 设置用户 安装完成","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"CI/CD","slug":"CI-CD","permalink":"http://yoursite.com/tags/CI-CD/"}]},{"title":"LeetCode（最长公共前缀）","slug":"leetcode_daily_4","date":"2019-12-18T16:00:00.000Z","updated":"2020-12-04T12:26:56.615Z","comments":true,"path":"2019/12/19/leetcode_daily_4/","link":"","permalink":"http://yoursite.com/2019/12/19/leetcode_daily_4/","excerpt":"LeetCode每日一题（罗马数字转整数）https://leetcode-cn.com/problems/longest-common-prefix/","text":"LeetCode每日一题（罗马数字转整数）https://leetcode-cn.com/problems/longest-common-prefix/ 题目编写一个函数来查找字符串数组中的最长公共前缀。 如果不存在公共前缀，返回空字符串 &quot;&quot;。 示例12345输入: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]输出: &quot;fl&quot;输入: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]输出: &quot;&quot; 题解123456789101112131415161718192021func longestCommonPrefix(strs []string) string &#123; if len(strs) == 0 &#123; return \"\" &#125; // 取strs第一个元素作为前缀 prefix := strs[0] // 遍历数组的长度 for i := 1; i &lt; len(strs); i++ &#123; // 从数组第二个元素开始，判断是否存在前缀prefix for !strings.HasPrefix(strs[i], prefix) &#123; fmt.Println(i, len(prefix), prefix) // 如果不存在则将前缀prefix最后一个字符删除 prefix = prefix[0 : len(prefix)-1] // 当前缀prefix=0时返回空字符串 if len(prefix) == 0 &#123; return \"\" &#125; &#125; &#125; return prefix&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"LeetCode（罗马数字转整数）","slug":"leetcode_daily_3","date":"2019-12-17T16:00:00.000Z","updated":"2020-12-04T12:26:51.641Z","comments":true,"path":"2019/12/18/leetcode_daily_3/","link":"","permalink":"http://yoursite.com/2019/12/18/leetcode_daily_3/","excerpt":"LeetCode每日一题（罗马数字转整数）https://leetcode-cn.com/problems/roman-to-integer/","text":"LeetCode每日一题（罗马数字转整数）https://leetcode-cn.com/problems/roman-to-integer/ 题目罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。 字符 数值 I 1 V 5 X 10 L 50 C 100 D 500 M 1000 I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。 X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。 C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。 示例12345输入: &quot;III&quot;输出: 3输入: &quot;LVIII&quot;输出: 58 题解123456789101112131415161718192021222324252627282930313233343536373839404142434445func romanToInt(s string) int &#123; r1 := map[string]int&#123; \"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000, &#125; r2 := map[string]int&#123; \"IV\": 4, \"IX\": 9, \"XL\": 40, \"XC\": 90, \"CD\": 400, \"CM\": 900, &#125; // ret 用来接收计算结果 ret := 0 // 判断字符串长度是否为0 for len(s) != 0 &#123; if len(s) &gt; 1 &#123; // s长度大于1，先判断前两位是否在r中 chars := s[:2] if v, ok := r2[chars]; ok &#123; ret += v // 删掉前两个字符 s = s[2:] // 判断一个字符是否在r中 &#125; else &#123; ret += r1[string(s[0])] // 删除前一个字符 s = s[1:] &#125; // 长度为1时 &#125; else &#123; ret += r1[string(s[0])] // 将s置空长度为0 s = s[1:] &#125; &#125; return ret&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"LeetCode（整数反转）","slug":"leetcode_daily_2","date":"2019-12-16T16:00:00.000Z","updated":"2020-12-04T12:26:53.421Z","comments":true,"path":"2019/12/17/leetcode_daily_2/","link":"","permalink":"http://yoursite.com/2019/12/17/leetcode_daily_2/","excerpt":"LeetCode每日一题（整数反转）https://leetcode-cn.com/problems/reverse-integer/","text":"LeetCode每日一题（整数反转）https://leetcode-cn.com/problems/reverse-integer/ 题目给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。 假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [−2^31, 2^31 − 1]。请根据这个假设，如果反转后整数溢出那么就返回 0。 示例12345678输入: 123输出: 321输入: -123输出: -321输入: 120输出: 21 题解弹出和推入数字 &amp; 溢出前进行检查1234567&#x2F;&#x2F; 弹出操作:pop &#x3D; x % 10;x &#x2F;&#x3D; 10;&#x2F;&#x2F; 弹出操作:temp &#x3D; rev * 10 + pop;rev &#x3D; temp; 当 temp = rev * 10 + pop 时会导致溢出，所以事先检查这个语句是否会导致溢出。 如果 temp = rev * 10 + pop 导致溢出，那么一定有 rev &gt;= INTMAX/10 如果 rev &gt; INTMAX/10，那么 temp = rev * 10 + pop 一定会溢出 如果 rev == INTMAX/10，那么只要 pop &gt; 7 ，temp = rev * 10 + pop 就会溢出 时间复杂度：O(log(x))，x 中大约有 log10(x) 位数字 空间复杂度：O(1) 123456789101112131415func reverse(x int) int &#123; rev := 0 for x != 0 &#123; pop := x % 10 x /= 10 if rev &gt; math.MaxInt32/10 || (rev == math.MaxInt32/10 &amp;&amp; pop &gt; 7) &#123; return 0 &#125; if rev &lt; math.MinInt32/10 || (rev == math.MinInt32/10 &amp;&amp; pop &lt; -8) &#123; return 0 &#125; rev = rev*10 + pop &#125; return rev&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"Jenkins使用npm构建Node.js应用","slug":"jenkins_npm","date":"2019-12-15T16:00:00.000Z","updated":"2020-12-04T12:17:49.375Z","comments":true,"path":"2019/12/16/jenkins_npm/","link":"","permalink":"http://yoursite.com/2019/12/16/jenkins_npm/","excerpt":"","text":"在Jenkins中创建流水线项目1git clone https://github.com/jenkins-docs/building-a-multibranch-pipeline-project.git 123456789101112131415pipeline &#123; agent &#123; docker &#123; image 'node:6-alpine' args '-p 3000:3000' &#125; &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'npm install' &#125; &#125; &#125;&#125; 12git add .git commit -m \"Add initial Jenkinsfile\" simple-node-js-react-npm-app An entry-level Pipeline demonstrating how to use Jenkins to build a simple Node.js and React application with npm. 向流水线添加Test阶段1234567891011121314151617181920212223pipeline &#123; agent &#123; docker &#123; image 'node:6-alpine' args '-p 3000:3000' &#125; &#125; environment &#123; CI = 'true' &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'npm install' &#125; &#125; stage('Test') &#123; steps &#123; sh './jenkins/scripts/test.sh' &#125; &#125; &#125;&#125; 12git stage .git commit -m \"Add 'Test' stage\" 给流水线添加最终交付阶段123456789101112131415161718192021222324252627282930pipeline &#123; agent &#123; docker &#123; image 'node:6-alpine' args '-p 3000:3000' &#125; &#125; environment &#123; CI = 'true' &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'npm install' &#125; &#125; stage('Test') &#123; steps &#123; sh './jenkins/scripts/test.sh' &#125; &#125; stage('Deliver') &#123; steps &#123; sh './jenkins/scripts/deliver.sh' input message: 'Finished using the web site? (Click \"Proceed\" to continue)' sh './jenkins/scripts/kill.sh' &#125; &#125; &#125;&#125; 12git stage .git commit -m \"Add 'Deliver' stage\"","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://yoursite.com/tags/CI-CD/"}]},{"title":"Jenkins使用PyInstaller构建Python应用","slug":"jenkins_python","date":"2019-12-15T16:00:00.000Z","updated":"2020-12-04T12:17:45.209Z","comments":true,"path":"2019/12/16/jenkins_python/","link":"","permalink":"http://yoursite.com/2019/12/16/jenkins_python/","excerpt":"","text":"在Jenkins中创建流水线项目1git clone https://github.com/jenkins-docs/simple-python-pyinstaller-app.git 123456789101112131415pipeline &#123; agent none stages &#123; stage('Build') &#123; agent &#123; docker &#123; image 'python:2-alpine' &#125; &#125; steps &#123; sh 'python -m py_compile sources/add2vals.py sources/calc.py' &#125; &#125; &#125;&#125; 12git add .git commit -m \"Add initial Jenkinsfile\" 向流水线添加Test阶段123456789101112131415161718192021222324252627282930pipeline &#123; agent none stages &#123; stage('Build') &#123; agent &#123; docker &#123; image 'python:2-alpine' &#125; &#125; steps &#123; sh 'python -m py_compile sources/add2vals.py sources/calc.py' &#125; &#125; stage('Test') &#123; agent &#123; docker &#123; image 'qnib/pytest' &#125; &#125; steps &#123; sh 'py.test --verbose --junit-xml test-reports/results.xml sources/test_calc.py' &#125; post &#123; always &#123; junit 'test-reports/results.xml' &#125; &#125; &#125; &#125;&#125; 12git stage .git commit -m \"Add 'Test' stage\" 给流水线添加最终交付阶段123456789101112131415161718192021222324252627282930313233343536373839404142434445pipeline &#123; agent none stages &#123; stage('Build') &#123; agent &#123; docker &#123; image 'python:2-alpine' &#125; &#125; steps &#123; sh 'python -m py_compile sources/add2vals.py sources/calc.py' &#125; &#125; stage('Test') &#123; agent &#123; docker &#123; image 'qnib/pytest' &#125; &#125; steps &#123; sh 'py.test --verbose --junit-xml test-reports/results.xml sources/test_calc.py' &#125; post &#123; always &#123; junit 'test-reports/results.xml' &#125; &#125; &#125; stage('Deliver') &#123; agent &#123; docker &#123; image 'cdrx/pyinstaller-linux:python2' &#125; &#125; steps &#123; sh 'pyinstaller --onefile sources/add2vals.py' &#125; post &#123; success &#123; archiveArtifacts 'dist/add2vals' &#125; &#125; &#125; &#125;&#125; 12git stage .git commit -m \"Add 'Deliver' stage\"","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://yoursite.com/tags/CI-CD/"}]},{"title":"Jenkins使用Maven构建Java应用程序","slug":"jenkins_maven","date":"2019-12-15T16:00:00.000Z","updated":"2020-12-04T12:17:53.320Z","comments":true,"path":"2019/12/16/jenkins_maven/","link":"","permalink":"http://yoursite.com/2019/12/16/jenkins_maven/","excerpt":"","text":"安装 Jenkins 参考文档 Jenkins 的安装与使用 安装 Docker 参考文档 Docker 的安装与使用 在Jenkins中创建流水线项目 创建目录，克隆项目； 12[root@jenkins ~]# mkdir /home/github[root@jenkins ~]# git clone https://github.com/jenkins-docs/simple-java-maven-app.git /home/github/simple-java-maven-app 为新的流水线项目指定名称（例如 simple-java-maven-app）； 在 Definition 域中，选择 Pipeline script from SCM 选项。此选项指示Jenkins从源代码管理（SCM）仓库获取你的流水线， 这里的仓库就是你clone到本地的Git仓库； 在 SCM 域中，选择 Git ，在 Repository URL 域中，填写你本地仓库的目录路径，这是从你主机上的用户账户home目录映射到Jenkins容器的 /home 目录：/home/github/simple-java-maven-app； 点击 Save 保存你的流水线项目。你现在可以开始创建你的 Jenkinsfile，这些文件会被添加到你的本地仓库 将初始流水线创建为Jenkinsfile 创建一个初始流水线来下载 Maven Docker 镜像，并将其作为 Docker 容器运行（这将构建你的简单Java应用）。同时添加一个“构建”阶段到流水线中，用于协调整个过程。 在你本地的 simple-java-maven-app Git仓库的根目录创建并保存一个名为 Jenkinsfile 的文本文件。 复制以下声明式流水线代码并粘贴到 Jenkinsfile 文件中： 12[root@jenkins ~]# cd /home/github/simple-java-maven-app[root@jenkins simple-java-maven-app]# vim Jenkinsfile 123456789101112131415pipeline &#123; agent &#123; docker &#123; image 'maven:3-alpine' args '-v /root/.m2:/root/.m2' &#125; &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'mvn -B -DskipTests clean package' &#125; &#125; &#125;&#125; 保存对 Jenkinsfile 的修改并且将其提交到你本地的 simple-java-maven-app Git仓库12[root@jenkins simple-java-maven-app]# git stage .[root@jenkins simple-java-maven-app]# git commit -m \"Add initial Jenkinsfile\" 再次回到 Jenkins，点击 Build Now。 为流水线增加test阶段 打开你的 Jenkinsfile 复制以下声明式流水线代码，并粘贴到 Jenkinsfile 中 Build 阶段的下方：12345678910stage('Test') &#123; steps &#123; sh 'mvn test' &#125; post &#123; always &#123; junit 'target/surefire-reports/*.xml' &#125; &#125;&#125; 最终的代码为：12345678910111213141516171819202122232425pipeline &#123; agent &#123; docker &#123; image 'maven:3-alpine' args '-v /root/.m2:/root/.m2' &#125; &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'mvn -B -DskipTests clean package' &#125; &#125; stage('Test') &#123; steps &#123; sh 'mvn test' &#125; post &#123; always &#123; junit 'target/surefire-reports/*.xml' &#125; &#125; &#125; &#125;&#125; 保存对 Jenkinsfile 的修改并将其提交到你的本地 simple-java-maven-app Git仓库。12git stage .git commit -m \"Add 'Test' stage\" 运行构建 为你的流水线增加deliver阶段 打开你的 Jenkinsfile。 复制以下声明式流水线代码，并粘贴到 Jenkinsfile 中 Test 阶段的下方：12345stage('Deliver') &#123; steps &#123; sh './jenkins/scripts/deliver.sh' &#125;&#125; 最终的代码为：123456789101112131415161718192021222324252627282930pipeline &#123; agent &#123; docker &#123; image 'maven:3-alpine' args '-v /root/.m2:/root/.m2' &#125; &#125; stages &#123; stage('Build') &#123; steps &#123; sh 'mvn -B -DskipTests clean package' &#125; &#125; stage('Test') &#123; steps &#123; sh 'mvn test' &#125; post &#123; always &#123; junit 'target/surefire-reports/*.xml' &#125; &#125; &#125; stage('Deliver') &#123; steps &#123; sh './jenkins/scripts/deliver.sh' &#125; &#125; &#125;&#125; 保存对 Jenkinsfile 的修改并将其提交到你的本地 simple-java-maven-app Git仓库。12git stage .git commit -m \"Add 'Deliver' stage\" 运行构建","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://yoursite.com/tags/CI-CD/"}]},{"title":"LeetCode（两数之和）","slug":"leetcode_daily_1","date":"2019-12-15T16:00:00.000Z","updated":"2020-12-04T12:26:39.033Z","comments":true,"path":"2019/12/16/leetcode_daily_1/","link":"","permalink":"http://yoursite.com/2019/12/16/leetcode_daily_1/","excerpt":"LeetCode每日一题（两数之和）https://leetcode-cn.com/problems/two-sum/","text":"LeetCode每日一题（两数之和）https://leetcode-cn.com/problems/two-sum/ 题目给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例123给定 nums &#x3D; [2, 7, 11, 15], target &#x3D; 9因为 nums[0] + nums[1] &#x3D; 2 + 7 &#x3D; 9所以返回 [0, 1] 题解方法一：暴力法遍历每个元素 x，并查找是否存在一个值与 target − x 相等的目标元素。 时间复杂度：O(n^2) 对于每个元素，我们试图通过遍历数组的其余部分来寻找它所对应的目标元素，这将耗费 O(n) 的时间。因此时间复杂度为 O(n^2)。 空间复杂度：O(1) 12345678910111213func twoSum(nums []int, target int) []int &#123; ret := make([]int, 0, 2) for i := 0; i &lt; len(nums); i++ &#123; for j := i + 1; j &lt; len(nums); j++ &#123; if target-nums[i] == nums[j] &#123; ret = append(ret, i, j) break &#125; &#125; &#125; return ret&#125; 方法二：两遍哈希表在第一次迭代中，我们将每个元素的值和它的索引添加到表中。然后，在第二次迭代中，我们将检查每个元素所对应的目标元素（target - nums[i]）是否存在于表中。注意，该目标元素不能是 nums[i] 本身！ 时间复杂度：O(n) 我们把包含有 n 个元素的列表遍历两次。由于哈希表将查找时间缩短到 O(1) ，所以时间复杂度为 O(n)。 空间复杂度：O(n) 所需的额外空间取决于哈希表中存储的元素数量，该表中存储了 n 个元素。 123456789101112131415161718192021222324252627func twoSum(nums []int, target int) []int &#123; numsMap := make(map[int]int) ret := make([]int, 2) // 遍历 nums 并将 nums 的数值和索引映射 // k: nums []int 索引 // v: nums []int 值 for k, v := range nums &#123; numsMap[v] = k &#125; for i, v := range nums &#123; // 取出一个数然后求出剩下一个数的值 x := target - v // 判断剩下的数是否存在于 numsMap 中 // 如果存在则返回两个数的索引 i, numsMap[x] if _, ok := numsMap[x]; ok &#123; // 当 x(target-v) 值所处的索引 (numsMap[x]) 等于当前索引 // 即为同一个数则直接返回空 if i != numsMap[x] &#123; ret = append(ret, i, numsMap[x]) break &#125; &#125; &#125; return ret&#125; 方法三：一遍哈希表在进行迭代并将元素插入到表中的同时，我们还会回过头来检查表中是否已经存在当前元素所对应的目标元素。如果它存在，那我们已经找到了对应解，并立即将其返回。 时间复杂度：O(n) 我们只遍历了包含有 n 个元素的列表一次。在表中进行的每次查找只花费 O(1) 的时间。 空间复杂度：O(n) 所需的额外空间取决于哈希表中存储的元素数量，该表最多需要存储 n 个元素。 12345678910111213141516171819func twoSum(nums []int, target int) []int &#123; numsMap := make(map[int]int) ret := make([]int, 0, 2) for i, v := range nums &#123; x := target - v if _, ok := numsMap[x]; ok &#123; if i != numsMap[x] &#123; ret = append(ret, numsMap[x], i) break &#125; &#125; numsMap[v] = i &#125; return ret&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"Go Tour 练习","slug":"go_tour","date":"2019-12-14T16:00:00.000Z","updated":"2020-12-04T12:16:01.546Z","comments":true,"path":"2019/12/15/go_tour/","link":"","permalink":"http://yoursite.com/2019/12/15/go_tour/","excerpt":"","text":"练习 1：循环与函数为了练习函数与循环，我们来实现一个平方根函数：用牛顿法实现平方根函数。计算机通常使用循环来计算 x 的平方根。从某个猜测的值 z 开始，我们可以根据 z² 与 x 的近似度来调整 z，产生一个更好的猜测：z -= (z*z - x) / (2*z)重复调整的过程，猜测的结果会越来越精确，得到的答案也会尽可能接近实际的平方根。在提供的 func Sqrt 中实现它。无论输入是什么，对 z 的一个恰当的猜测为 1。 要开始，请重复计算 10 次并随之打印每次的 z 值。观察对于不同的值 x（1、2、3 ...）， 你得到的答案是如何逼近结果的，猜测提升的速度有多快。提示：用类型转换或浮点数语法来声明并初始化一个浮点数值：z := 1.0z := float64(1)然后，修改循环条件，使得当值停止改变（或改变非常小）的时候退出循环。观察迭代次数大于还是小于 10。 尝试改变 z 的初始猜测，如 x 或 x/2。你的函数结果与标准库中的 math.Sqrt 接近吗？（注： 如果你对该算法的细节感兴趣，上面的 z² − x 是 z² 到它所要到达的值（即 x）的距离， 除以的 2z 为 z² 的导数，我们通过 z² 的变化速度来改变 z 的调整量。 这种通用方法叫做牛顿法。 它对很多函数，特别是平方根而言非常有效。） 123456789101112package mainimport ( \"fmt\")func Sqrt(x float64) float64 &#123;&#125;func main() &#123; fmt.Println(Sqrt(2))&#125; 实现12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" \"math\")func Sqrt(x float64) float64 &#123; z := 1.0 // 初始化z temp := 0.0 // 初始化temp，用于临时存放结果 for &#123; z = z - (z*z-x)/(2*z) // 定义牛顿法公式求出新的z值 fmt.Println(z) if math.Abs(z-temp) &lt; 0.000000000000001 &#123; // 判断z是否达到精度 break &#125; else &#123; temp = z // 临时存放计算得出的z &#125; &#125; return z&#125;func main() &#123; fmt.Println(\"牛顿法:\") fmt.Println(Sqrt(3)) fmt.Println(\"math.Sqrt:\") fmt.Println(math.Sqrt(3))&#125; 结果12345678910牛顿法:21.751.73214285714285721.73205081001472761.73205080756887721.73205080756887741.7320508075688774math.Sqrt:1.7320508075688772 练习 2：切片实现 Pic。它应当返回一个长度为 dy 的切片，其中每个元素是一个长度为 dx，元素类型为 uint8 的切片。当你运行此程序时，它会将每个整数解释为灰度值（好吧，其实是蓝度值）并显示它所对应的图像。 图像的选择由你来定。几个有趣的函数包括 (x+y)/2, xy, x^y, xlog(y) 和 x%(y+1)。 （提示：需要使用循环来分配 [][]uint8 中的每个 []uint8；请使用 uint8(intValue) 在类型之间转换；你可能会用到 math 包中的函数。） 12345678910package mainimport \"golang.org/x/tour/pic\"func Pic(dx, dy int) [][]uint8 &#123;&#125;func main() &#123; pic.Show(Pic)&#125; 实现12345678910111213141516171819package mainimport \"golang.org/x/tour/pic\"func Pic(dx, dy int) [][]uint8 &#123; a := make([][]uint8, dy) // make 一个长度为 dy 的二维数组切片 for x := range a &#123; // index, value := range a，x 为数组索引 b := make([]uint8, dx) // make 一个长度为 dx 的一维数组切片 for y := range b &#123; // y 为数组索引 b[y] = uint8(x % (y + 1)) // 修改数组 b 对应索引位置的值 &#125; a[x] = b // 修改数组 a 对应索引位置的值 &#125; return a&#125;func main() &#123; pic.Show(Pic)&#125; 练习 3：映射实现 WordCount。它应当返回一个映射，其中包含字符串 s 中每个“单词”的个数。函数 wc.Test 会对此函数执行一系列测试用例，并输出成功还是失败。你会发现 strings.Fields 很有帮助。 12345678910111213package mainimport ( \"golang.org/x/tour/wc\")func WordCount(s string) map[string]int &#123; return map[string]int&#123;\"x\": 1&#125;&#125;func main() &#123; wc.Test(WordCount)&#125; 实现12345678910111213141516171819202122232425package mainimport ( \"strings\" \"golang.org/x/tour/wc\")func WordCount(s string) map[string]int &#123; a := strings.Fields(s) // 使用 strings.Fields 将字符串分割成数组 map_s := make(map[string]int) // 映射单词和出现次数 for _, v := range a &#123; // 遍历 a 的值 _, ok := map_s[v] // 获取状态值 if ok &#123; // 判断map中是否存在当前字符串为下标的值 map_s[v]++ // 有则出现次数+1 &#125; else &#123; map_s[v] = 1 // 无则=1 &#125; &#125; return map_s&#125;func main() &#123; wc.Test(WordCount)&#125; 结果123456789101112PASS f(&quot;I am learning Go!&quot;) &#x3D; map[string]int&#123;&quot;Go!&quot;:1, &quot;I&quot;:1, &quot;am&quot;:1, &quot;learning&quot;:1&#125;PASS f(&quot;The quick brown fox jumped over the lazy dog.&quot;) &#x3D; map[string]int&#123;&quot;The&quot;:1, &quot;brown&quot;:1, &quot;dog.&quot;:1, &quot;fox&quot;:1, &quot;jumped&quot;:1, &quot;lazy&quot;:1, &quot;over&quot;:1, &quot;quick&quot;:1, &quot;the&quot;:1&#125;PASS f(&quot;I ate a donut. Then I ate another donut.&quot;) &#x3D; map[string]int&#123;&quot;I&quot;:2, &quot;Then&quot;:1, &quot;a&quot;:1, &quot;another&quot;:1, &quot;ate&quot;:2, &quot;donut.&quot;:2&#125;PASS f(&quot;A man a plan a canal panama.&quot;) &#x3D; map[string]int&#123;&quot;A&quot;:1, &quot;a&quot;:2, &quot;canal&quot;:1, &quot;man&quot;:1, &quot;panama.&quot;:1, &quot;plan&quot;:1&#125; 练习 4：斐波纳契闭包实现一个 fibonacci 函数，它返回一个函数（闭包），该闭包返回一个斐波纳契数列 (0, 1, 1, 2, 3, 5, ...)。 1234567891011121314package mainimport \"fmt\"// 返回一个“返回int的函数”func fibonacci() func() int &#123;&#125;func main() &#123; f := fibonacci() for i := 0; i &lt; 10; i++ &#123; fmt.Println(f()) &#125;&#125; 实现1234567891011121314151617181920package mainimport \"fmt\"// 返回一个“返回int的函数”func fibonacci() func() int &#123; a, b := 0, 1 return func() int &#123; temp := a a, b = b, a+b return temp &#125;&#125;func main() &#123; f := fibonacci() for i := 0; i &lt; 10; i++ &#123; fmt.Println(f()) &#125;&#125; 结果123456789100112358132134 练习 5： Stringer 通过让 IPAddr 类型实现 fmt.Stringer 来打印点号分隔的地址。 例如，IPAddr{1, 2, 3, 4} 应当打印为 &quot;1.2.3.4&quot;。 1234567891011121314151617package mainimport \"fmt\"type IPAddr [4]byte// TODO: 给 IPAddr 添加一个 \"String() string\" 方法func main() &#123; hosts := map[string]IPAddr&#123; \"loopback\": &#123;127, 0, 0, 1&#125;, \"googleDNS\": &#123;8, 8, 8, 8&#125;, &#125; for name, ip := range hosts &#123; fmt.Printf(\"%v: %v\\n\", name, ip) &#125;&#125; 实现1234567891011121314151617181920package mainimport \"fmt\"type IPAddr [4]byte// TODO: 给 IPAddr 添加一个 \"String() string\" 方法func (ip IPAddr) String() string &#123; return fmt.Sprintf(\"%v.%v.%v.%v\", ip[0], ip[1], ip[2], ip[3])&#125;func main() &#123; hosts := map[string]IPAddr&#123; \"loopback\": &#123;127, 0, 0, 1&#125;, \"googleDNS\": &#123;8, 8, 8, 8&#125;, &#125; for name, ip := range hosts &#123; fmt.Printf(\"%v: %v\\n\", name, ip) &#125;&#125; 结果12loopback: 127.0.0.1googleDNS: 8.8.8.8 练习 6：错误Sqrt 接受到一个负数时，应当返回一个非 nil 的错误值。复数同样也不被支持。 创建一个新的类型type ErrNegativeSqrt float64并为其实现func (e ErrNegativeSqrt) Error() string方法使其拥有 error 值，通过 ErrNegativeSqrt(-2).Error() 调用该方法应返回 &quot;cannot Sqrt negative number: -2&quot;。 注意: 在 Error 方法内调用 fmt.Sprint(e) 会让程序陷入死循环。可以通过先转换 e 来避免这个问题：fmt.Sprint(float64(e))。这是为什么呢？ 修改 Sqrt 函数，使其接受一个负数时，返回 ErrNegativeSqrt 值。 1234567891011121314package mainimport ( \"fmt\")func Sqrt(x float64) (float64, error) &#123; return 0, nil&#125;func main() &#123; fmt.Println(Sqrt(2)) fmt.Println(Sqrt(-2))&#125; 实现123456789101112131415161718192021222324package mainimport ( \"fmt\" \"math\")type ErrNegativeSqrt float64func (e ErrNegativeSqrt) Error() string &#123; // 重写 Error 函数 return fmt.Sprintf(\"cannot Sqrt negative number:%v\", float64(e))&#125;func Sqrt(x float64) (float64, error) &#123; if x &lt; 0 &#123; return 0, ErrNegativeSqrt(x) &#125; return math.Sqrt(x), nil&#125;func main() &#123; fmt.Println(Sqrt(2)) fmt.Println(Sqrt(-2))&#125; 结果121.4142135623730951 &lt;nil&gt;0 cannot Sqrt negative number:-2 练习 7：Reader 实现一个 Reader 类型，它产生一个 ASCII 字符 ‘A’ 的无限流。 1234567891011package mainimport \"golang.org/x/tour/reader\"type MyReader struct&#123;&#125;// TODO: 给 MyReader 添加一个 Read([]byte) (int, error) 方法func main() &#123; reader.Validate(MyReader&#123;&#125;)&#125; 实现123456789101112131415package mainimport \"golang.org/x/tour/reader\"type MyReader struct&#123;&#125;// TODO: 给 MyReader 添加一个 Read([]byte) (int, error) 方法func (r MyReader) Read(b []byte) (int, error) &#123; b[0] = 'A' return 1, nil&#125;func main() &#123; reader.Validate(MyReader&#123;&#125;)&#125; 练习 8：rot13Reader有种常见的模式是一个 io.Reader 包装另一个 io.Reader，然后通过某种方式修改其数据流。 例如，gzip.NewReader 函数接受一个 io.Reader（已压缩的数据流）并返回一个同样实现了 io.Reader 的 *gzip.Reader（解压后的数据流）。 编写一个实现了 io.Reader 并从另一个 io.Reader 中读取数据的 rot13Reader，通过应用 rot13 代换密码对数据流进行修改。 类型已经提供。实现 ```Read``` 方法以满足 ```io.Reader```。12345678910111213141516171819&#96;&#96;&#96;gopackage mainimport (&quot;io&quot;&quot;os&quot;&quot;strings&quot;)type rot13Reader struct &#123;r io.Reader&#125;func main() &#123;s :&#x3D; strings.NewReader(&quot;Lbh penpxrq gur pbqr!&quot;)r :&#x3D; rot13Reader&#123;s&#125;io.Copy(os.Stdout, &amp;r)&#125; 实现123456789101112131415161718192021222324252627282930313233343536package mainimport ( \"io\" \"os\" \"strings\")type rot13Reader struct &#123; r io.Reader&#125;// 实现 rot13 函数func rot13(out byte) byte &#123; //字母转换 switch &#123; case out &gt;= 'A' &amp;&amp; out &lt;= 'M' || out &gt;= 'a' &amp;&amp; out &lt;= 'm': out += 13 case out &gt;= 'N' &amp;&amp; out &lt;= 'Z' || out &gt;= 'n' &amp;&amp; out &lt;= 'z': out -= 13 &#125; return out&#125;func (fz rot13Reader) Read(b []byte) (int, error) &#123; n, e := fz.r.Read(b) for i := 0; i &lt; n; i++ &#123; b[i] = rot13(b[i]) &#125; return n, e&#125;func main() &#123; s := strings.NewReader(\"Lbh penpxrq gur pbqr!\") r := rot13Reader&#123;s&#125; io.Copy(os.Stdout, &amp;r)&#125; 结果1You cracked the code!% 练习 9：图像还记得之前编写的图片生成器 吗？我们再来编写另外一个，不过这次它将会返回一个 image.Image 的实现而非一个数据切片。定义你自己的 Image 类型，实现必要的方法并调用 pic.ShowImage。Bounds 应当返回一个 image.Rectangle ，例如 image.Rect(0, 0, w, h)。ColorModel 应当返回 color.RGBAModel。At 应当返回一个颜色。上一个图片生成器的值 v 对应于此次的 color.RGBA{v, v, 255, 255}。 12345678910package mainimport \"golang.org/x/tour/pic\"type Image struct&#123;&#125;func main() &#123; m := Image&#123;&#125; pic.ShowImage(m)&#125; 实现123456789101112131415161718192021222324252627package mainimport ( \"image\" \"image/color\" \"golang.org/x/tour/pic\")type Image struct&#123;&#125;func (i Image) ColorModel() color.Model &#123; //实现 Image 包中颜色模式的方法 return color.RGBAModel&#125;func (i Image) Bounds() image.Rectangle &#123; //实现 Image 包中生成图片边界的方法 return image.Rect(0, 0, 200, 200)&#125;func (i Image) At(x, y int) color.Color &#123; // 实现 Image 包中生成图像某个点的方法 return color.RGBA&#123;uint8(x), uint8(y), uint8(255), uint8(255)&#125;&#125;func main() &#123; m := Image&#123;&#125; pic.ShowImage(m)&#125;","categories":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"}]},{"title":"Python 判断变量的类型","slug":"python-variable","date":"2019-11-20T10:10:52.000Z","updated":"2020-12-04T12:22:19.659Z","comments":true,"path":"2019/11/20/python-variable/","link":"","permalink":"http://yoursite.com/2019/11/20/python-variable/","excerpt":"Python 判断变量的类型的方法","text":"Python 判断变量的类型的方法 python 判断变量的类型python的数据类型有： 数字(int) 浮点(float) 字符串(str) 列表(list) 元组(tuple) 字典(dict) 集合(set) 一般通过以下方法判断变量类型： isinstance(参数1, 参数2) 123i = 1isinstance(i, int)True 123i = \"test\"isinstance(i, str)True 123i = (1, 2, 3, 4, 5)isinstance(i, tuple)True type(参数1) 123i = 1type(i)&lt;class 'int'&gt; 123i = \"test\"type(i)&lt;class 'str'&gt; 123i = (1, 2, 3, 4, 5)type(i)&lt;class 'tuple'&gt; python 变量转换错误 ValueError123i = 3.1415926int(i)3 123i = 2float(i)2.0 12345i = \"test\"int(i)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;ValueError: invalid literal for int() with base 10: 'test' 123i = \"test\"tuple(i)('t', 'e', 's', 't') 123i = \"test\"list(i)['t', 'e', 's', 't'] 12345i = \"test\"dict(i)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;ValueError: dictionary update sequence element #0 has length 1; 2 is required 123i = \"test\"set(i)&#123;'e', 's', 't'&#125;","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Docker /etc/docker/daemon.json 文件的参数","slug":"docker-daemon-json","date":"2019-11-20T09:25:46.000Z","updated":"2020-12-04T12:14:45.328Z","comments":true,"path":"2019/11/20/docker-daemon-json/","link":"","permalink":"http://yoursite.com/2019/11/20/docker-daemon-json/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&#123; \"api-cors-header\":\"\", \"authorization-plugins\":[], \"bip\": \"\", \"bridge\":\"\", \"cgroup-parent\":\"\", \"cluster-store\":\"\", \"cluster-store-opts\":&#123;&#125;, \"cluster-advertise\":\"\", \"debug\": true, \"default-gateway\":\"\", \"default-gateway-v6\":\"\", \"default-runtime\":\"runc\", \"default-ulimits\":&#123;&#125;, \"disable-legacy-registry\":false, \"dns\": [\"192.168.1.1\"], # 设定容器DNS的地址，在容器的 /etc/resolv.conf文件中可查看。 \"dns-opts\": [], # 容器 /etc/resolv.conf 文件，其他设置 \"dns-search\": [], # 设定容器的搜索域，当设定搜索域为 .example.com 时，在搜索一个名为 host 的 主机时，DNS不仅搜索host，还会搜索host.example.com 。 注意：如果不设置， Docker 会默认用主机上的 /etc/resolv.conf 来配置容器。 \"exec-opts\": [], \"exec-root\":\"\", \"fixed-cidr\":\"\", \"fixed-cidr-v6\":\"\", \"data-root\":\"/var/lib/docker\", ＃ Docker运行时使用的根路径,根路径下的内容稍后介绍，默认/var/lib/docker \"group\": \"\", # Unix套接字的属组,仅指/var/run/docker.sock \"hosts\": [], # 设置容器hosts \"icc\": false, \"insecure-registries\": [], # 配置docker的私库地址 \"ip\":\"0.0.0.0\", \"iptables\": false, \"ipv6\": false, \"ip-forward\": false, # 默认true, 启用 net.ipv4.ip_forward ,进入容器后使用 sysctl -a | grepnet.ipv4.ip_forward 查看 \"ip-masq\":false, \"labels\":[\"nodeName=node-121\"], # docker主机的标签，很实用的功能,例如定义：–label nodeName=host-121 \"live-restore\": true, \"log-driver\":\"\", \"log-level\":\"\", \"log-opts\": &#123;&#125;, \"max-concurrent-downloads\":3, \"max-concurrent-uploads\":5, \"mtu\": 0, \"oom-score-adjust\":-500, \"pidfile\": \"\", # Docker守护进程的PID文件 \"raw-logs\": false, \"registry-mirrors\":[\"xxxx\"], # 镜像加速的地址，增加后在 docker info 中可查看。 \"runtimes\": &#123; \"runc\": &#123; \"path\": \"runc\" &#125;, \"custom\": &#123; \"path\":\"/usr/local/bin/my-runc-replacement\", \"runtimeArgs\": [ \"--debug\" ] &#125; &#125;, \"selinux-enabled\": false, # 默认 false，启用 selinux 支持 \"storage-driver\":\"\", \"storage-opts\": [], \"swarm-default-advertise-addr\":\"\", \"tls\": true, # 默认 false, 启动TLS认证开关 \"tlscacert\": \"\", # 默认 ~/.docker/ca.pem，通过CA认证过的的certificate文件路径 \"tlscert\": \"\", # 默认 ~/.docker/cert.pem，TLS的certificate文件路径 \"tlskey\": \"\", # 默认 ~/.docker/key.pem，TLS的key文件路径 \"tlsverify\": true, # 默认 false，使用TLS并做后台进程与客户端通讯的验证 \"userland-proxy\":false, \"userns-remap\":\"\" &#125;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"将 Nginx 日志格式化成 json","slug":"nginx-log-format-to-json","date":"2019-11-19T09:27:38.000Z","updated":"2020-12-04T12:21:16.459Z","comments":true,"path":"2019/11/19/nginx-log-format-to-json/","link":"","permalink":"http://yoursite.com/2019/11/19/nginx-log-format-to-json/","excerpt":"将 Nginx 日志格式化成 json 格式","text":"将 Nginx 日志格式化成 json 格式 1vim /etc/nginx/nginx.conf 123456789101112131415# 修改log_formatlog_format log_json &#39;&#123;&quot;timestamp&quot;:&quot;$time_local&quot;,&#39; &#39;&quot;http_host&quot;:&quot;$http_host&quot;,&#39; &#39;&quot;clinetip&quot;:&quot;$remote_addr&quot;,&#39; &#39;&quot;request&quot;:&quot;$request&quot;,&#39; &#39;&quot;status&quot;:&quot;$status&quot;,&#39; &#39;&quot;size&quot;:&quot;$body_bytes_sent&quot;,&#39; &#39;&quot;upstream_addr&quot;:&quot;$upstream_addr&quot;,&#39; &#39;&quot;upstream_status&quot;:&quot;$upstream_status&quot;,&#39; &#39;&quot;upstream_response_time&quot;:&quot;$upstream_response_time&quot;,&#39; &#39;&quot;request_time&quot;:&quot;$request_time&quot;,&#39; &#39;&quot;http_referer&quot;:&quot;$http_referer&quot;,&#39; &#39;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&#39; &#39;&quot;http_x_forwarded_for&quot;:&quot;$http_x_forwarded_for&quot;&#125;&#39;;access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log log_json;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"使用 ELK 搭建日志分析系统","slug":"elk","date":"2019-11-19T05:22:39.000Z","updated":"2020-12-04T12:23:38.074Z","comments":true,"path":"2019/11/19/elk/","link":"","permalink":"http://yoursite.com/2019/11/19/elk/","excerpt":"","text":"123456cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;security&#x2F;limits.conf* soft nproc 65535* hard nproc 65535* soft nofile 65535* hard nofile 65535EOF 123456789101112131415161718192021input &#123; tcp &#123; port &#x3D;&gt; 8002 codec &#x3D;&gt; json_lines &#125;&#125;filter&#123; # 如果message中以Retrieved hosts from InstanceDiscovery: 0开头 if([message]&#x3D;~ &quot;^Retrieved hosts from InstanceDiscovery: 0&quot;)&#123; # 丢弃 drop&#123;&#125; &#125;&#125;output &#123; elasticsearch &#123; hosts &#x3D;&gt; &quot;localhost:8001&quot; &#125; stdout &#123; codec &#x3D;&gt; rubydebug&#125;&#125; 12345filter &#123; json &#123; source &#x3D;&gt; &quot;message&quot; &#125;&#125;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"}]},{"title":"Filebeat 指南","slug":"filebeat","date":"2019-11-18T16:56:12.000Z","updated":"2020-12-04T12:14:27.642Z","comments":true,"path":"2019/11/19/filebeat/","link":"","permalink":"http://yoursite.com/2019/11/19/filebeat/","excerpt":"","text":"配置 Filebeat日志输入使用 log 输入从日志文件中读取行。 12345filebeat.inputs:- type: log paths: - /var/log/messages - /var/log/*.log 您可以配置额外的设置（例如 fields，include_lines，exclude_lines，multiline 等），从这些文件中获取行。您指定的选项将应用于此输入收集的所有文件。要将不同的配置设置应用于不同的文件，您需要定义多个输入节： 1234567891011filebeat.inputs:- type: log paths: - /var/log/system.log - /var/log/wifi.log- type: log paths: - \"/var/log/apache2/*\" fields: apache: true fields_under_root: true","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"}]},{"title":"habor","slug":"habor","date":"2019-11-18T06:21:52.000Z","updated":"2020-12-04T11:24:29.130Z","comments":true,"path":"2019/11/18/habor/","link":"","permalink":"http://yoursite.com/2019/11/18/habor/","excerpt":"","text":"curl -s 192.168.33.11:5000/v2/_catalog | json_reformatcurl -s 192.168.33.11:5000/v2/base/centos/tags/list | json_reformat","categories":[],"tags":[]},{"title":"Kubernetes 离线安装","slug":"kubernetes","date":"2019-10-14T17:31:26.000Z","updated":"2020-12-04T12:19:07.804Z","comments":true,"path":"2019/10/15/kubernetes/","link":"","permalink":"http://yoursite.com/2019/10/15/kubernetes/","excerpt":"","text":"IPADDRESS HOSTNAME ENVIROMENT KERNEL 192.168.33.50 k8smaster CentOS 7 5.3.7-1.el7.elrepo.x86_64 192.168.33.51 k8snode01 CentOS 7 5.3.7-1.el7.elrepo.x86_64 192.168.33.52 k8snode01 CentOS 7 5.3.7-1.el7.elrepo.x86_64 1. 设置域名解析12345cat &lt;&lt; EOF &gt;&gt; /etc/hosts192.168.33.50 k8smaster192.168.33.51 k8snode01192.168.33.52 k8snode01EOF 2. 安装相关依赖包1yum -y install conntrack ipvsadm sysstat wget git 3. 设置防火墙、SELINUX12345678910systemctl disable firewalld &amp;&amp; systemctl stop firewalldyum -y install iptables-servicessystemctl enable iptables &amp;&amp; systemctl start iptablesiptables -Fservice iptables savesetenforce 0vim &#x2F;etc&#x2F;selinux&#x2F;configSELINUX&#x3D;disabled 4. 设置时区调整系统时间123456timedatectl set-timezone Asia&#x2F;Shanghai# 将当前时间写入硬件时钟timedatectl set-local-rtc 0# 重启依赖于系统时间的服务systemctl restart rsyslogsystemctl restart crond 5. 关闭系统不需要的服务1systemctl disable postfix &amp;&amp; systemctl stop postfix 6. 设置rsyslogd和systemd journald1234567891011121314151617181920212223242526272829# 创建持久化保存日志的目录mkdir &#x2F;var&#x2F;log&#x2F;journalmkdir &#x2F;etc&#x2F;systemd&#x2F;journald.conf.dcat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;systemd&#x2F;journald.conf.d&#x2F;99-prophet.conf[Journal]# 持久化保存到磁盘Storage&#x3D;persistent# 压缩历史日志Compress&#x3D;yesSyncIntervalSec&#x3D;5mRateLimitInterval&#x3D;30sRateLimitBurst&#x3D;1000# 最大占用空间SystemMaxUse&#x3D;5G# 单个日志文件最大100MSystemMaxFileSize&#x3D;100M# 日志保存时间2周MaxRetentionSec&#x3D;2week# 不将日志转发到syslogForwardToSyslog&#x3D;noEOFsystemctl restart systemd-journald 7. 升级系统内核12345678910rpm --import https:&#x2F;&#x2F;www.elrepo.org&#x2F;RPM-GPG-KEY-elrepo.orgyum install https:&#x2F;&#x2F;www.elrepo.org&#x2F;elrepo-release-7.0-4.el7.elrepo.noarch.rpmyum --enablerepo&#x3D;elrepo-kernel install kernel-ml -ygrub2-mkconfig -o &#x2F;boot&#x2F;grub2&#x2F;grub.cfg# 设置默认启动为新内核sed -i &#39;s&#x2F;GRUB_DEFAULT&#x3D;saved&#x2F;GRUB_DEFAULT&#x3D;0&#x2F;g&#39; &#x2F;etc&#x2F;default&#x2F;grub# 重启reboot 8. 关闭SWAP12swapoff -ased -i &#39;s|^&#x2F;swapfile|#&#x2F;swapfile|g&#39; &#x2F;etc&#x2F;fstab 9. 调整内核参数12345678cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.confnet.bridge.bridge-nf-call-ip6tables &#x3D; 1net.bridge.bridge-nf-call-iptables &#x3D; 1net.ipv6.conf.all.disable_ipv6 &#x3D; 1net.ipv4.ip_forward &#x3D; 1EOFsysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf 10. kube-proxy开启ipvs的前置条件123456789101112131415modprobe br_netfiltercat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules# 查看是否已经正确加载所需的内核模块lsmod | grep -e ip_vs -e nf_conntrack_ipv4 11. 安装Docker12345678910111213141516171819202122232425sudo yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息sudo yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo# Step 3: 更新并安装 Docker-CEsudo yum makecache fastyum install -y docker-cesystemctl enable docker &amp;&amp; systemctl start docker# 配置daemoncat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;&#125;EOFmkdir -p &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d# 重启docker服务systemctl daemon-reload &amp;&amp; systemctl restart docker 12. 安装kubeadm和kubelet（1.4.1-0）12345678910111213cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# yum remove -y kubelet kubeadm kubectlyum -y install kubelet-1.14.1-0.x86_64 kubeadm-1.14.1-0.x86_64 kubectl-1.14.1-0.x86_64systemctl enable kubelet &amp;&amp; systemctl start kubelet 13. 使用kubeadm init初始化集群 下载离线安装所需的docker image（需要科学上网） 1kubeadm config images list 所需镜像清单 12345678k8s.gcr.io#coredns#1.3.1.tark8s.gcr.io#etcd#3.3.10.tark8s.gcr.io#kube-apiserver#v1.14.1.tark8s.gcr.io#kube-controller-manager#v1.14.1.tark8s.gcr.io#kube-proxy#v1.14.1.tark8s.gcr.io#kube-scheduler#v1.14.1.tark8s.gcr.io#pause#3.1.tarquay.io#coreos#flannel#v0.11.0-amd64.tar 导入docker image 1234for i in &#96;ls -1&#96;;dodocker load &lt; $idone 14. k8smaster初始化k8s集群1kubeadm config print init-defaults &gt; kubeadm-config.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: kubeadm.k8s.io&#x2F;v1beta1bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.33.50 bindPort: 6443nodeRegistration: criSocket: &#x2F;var&#x2F;run&#x2F;dockershim.sock name: k8smaster taints: - effect: NoSchedule key: node-role.kubernetes.io&#x2F;master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io&#x2F;v1beta1certificatesDir: &#x2F;etc&#x2F;kubernetes&#x2F;pkiclusterName: kubernetescontrolPlaneEndpoint: &quot;&quot;controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: &#x2F;var&#x2F;lib&#x2F;etcdimageRepository: k8s.gcr.iokind: ClusterConfigurationkubernetesVersion: v1.14.1networking: dnsDomain: cluster.local podSubnet: &quot;10.244.0.0&#x2F;16&quot; serviceSubnet: 10.96.0.0&#x2F;12scheduler: &#123;&#125;---apiVersion: kubeproxy.config.k8s.io&#x2F;v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs 12345kubeadm init --config&#x3D;kubeadm-config.yaml | tee kubeadm-init.logmkdir -p $HOME&#x2F;.kubesudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;configsudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config 查看节点状态 1234kubectl get nodeNAME STATUS ROLES AGE VERSIONk8smaster NotReady master 2m2s v1.14.1 123456kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125; 1234567891011kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-fb8b8dccf-4sr7j 0&#x2F;1 Pending 0 10m &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;coredns-fb8b8dccf-9lxf8 0&#x2F;1 Pending 0 10m &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;etcd-k8smaster 1&#x2F;1 Running 0 10m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-apiserver-k8smaster 1&#x2F;1 Running 0 9m58s 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-controller-manager-k8smaster 1&#x2F;1 Running 0 9m56s 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-r68r5 1&#x2F;1 Running 0 14s 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-proxy-gc9ms 1&#x2F;1 Running 0 10m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-scheduler-k8smaster 1&#x2F;1 Running 0 10m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt; 15. k8smaster安装flannel1234mkdir -p ~/k8s/cd ~/k8swget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml 16. k8snode01、k8snode02加入集群1234kubeadm join 192.168.33.50:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:91dd4c335d92e948075b8980f78beb112ebf7a23fffe156b64f90097b88d1612# 查看加入语句kubeadm token create --print-join-command 1234567891011121314kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScoredns-fb8b8dccf-4sr7j 1&#x2F;1 Running 0 14m 10.244.0.2 k8smaster &lt;none&gt; &lt;none&gt;coredns-fb8b8dccf-9lxf8 1&#x2F;1 Running 0 14m 10.244.0.3 k8smaster &lt;none&gt; &lt;none&gt;etcd-k8smaster 1&#x2F;1 Running 0 13m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-apiserver-k8smaster 1&#x2F;1 Running 0 13m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-controller-manager-k8smaster 1&#x2F;1 Running 0 13m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-m6mtp 1&#x2F;1 Running 0 2m11s 192.168.33.51 k8snode01 &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-qgmwp 1&#x2F;1 Running 0 2m5s 192.168.33.52 k8snode02 &lt;none&gt; &lt;none&gt;kube-flannel-ds-amd64-r68r5 1&#x2F;1 Running 0 3m47s 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-proxy-9tpgd 1&#x2F;1 Running 0 2m5s 192.168.33.52 k8snode02 &lt;none&gt; &lt;none&gt;kube-proxy-gc9ms 1&#x2F;1 Running 0 14m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt;kube-proxy-tdz9k 1&#x2F;1 Running 0 2m11s 192.168.33.51 k8snode01 &lt;none&gt; &lt;none&gt;kube-scheduler-k8smaster 1&#x2F;1 Running 0 13m 192.168.33.50 k8smaster &lt;none&gt; &lt;none&gt; 123456kubectl get nodeNAME STATUS ROLES AGE VERSIONk8smaster Ready master 16m v1.14.1k8snode01 Ready &lt;none&gt; 3m54s v1.14.1k8snode02 Ready &lt;none&gt; 3m48s v1.14.1 17. 安装kubernetes-dashboard","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://yoursite.com/tags/Kubernetes/"}]},{"title":"macOS 设置 launchpad 图标大小","slug":"macos_launchpad_config","date":"2019-10-14T17:31:26.000Z","updated":"2020-12-04T12:19:58.263Z","comments":true,"path":"2019/10/15/macos_launchpad_config/","link":"","permalink":"http://yoursite.com/2019/10/15/macos_launchpad_config/","excerpt":"KMacOS 设置 launchpad 图标大小","text":"KMacOS 设置 launchpad 图标大小 1234defaults write com.apple.dock springboard-rows -int 7defaults write com.apple.dock springboard-columns -int 6killall Dockdefaults write com.apple.dock ResetLaunchPad -bool TRUE;killall Dock","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"mac","slug":"mac","permalink":"http://yoursite.com/tags/mac/"}]},{"title":"MySQL Group Replication 安装及配置","slug":"mysql_group_replication","date":"2019-10-14T17:31:26.000Z","updated":"2020-12-04T12:20:31.567Z","comments":true,"path":"2019/10/15/mysql_group_replication/","link":"","permalink":"http://yoursite.com/2019/10/15/mysql_group_replication/","excerpt":"MySQL 组复制","text":"MySQL 组复制 安装Docker123456yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repoyum -y install docker-cesystemctl enable dockersystemctl start dockerdocker ps 创建网络123docker pull mysql:5.7docker network create --subnet&#x3D;192.168.100.0&#x2F;24 mysqlsubnetdocker network ls 编辑配置文件12345678910mkdir &#x2F;mysqldata &amp;&amp; cd &#x2F;mysqldatamkdir s&#123;1..3&#125;.&#x2F;conf.d&#x2F;├── s1│ └── my.cnf├── s2│ └── my.cnf└── s3 └── my.cnf /mysqldata/conf.d/s1/my.cnf 12345678910111213141516171819202122[mysqld]port&#x3D;3306datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysqlpid-file&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pidsocket&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sockserver_id&#x3D;1gtid_mode&#x3D;ONenforce_gtid_consistency&#x3D;ONmaster_info_repository&#x3D;TABLErelay_log_info_repository&#x3D;TABLEbinlog-format&#x3D;ROWbinlog_checksum&#x3D;NONElog-slave-updates&#x3D;1log_bin&#x3D;binlogrelay-log&#x3D;bogon-relay-bintransaction_write_set_extraction &#x3D; XXHASH64loose-group_replication_group_name&#x3D;&quot;81263447-5a2b-11e9-94c6-0242c0a86465&quot;loose-group_replication_start_on_boot &#x3D; offloose-group_replication_local_address &#x3D; &#39;192.168.100.101:33061&#39;loose-group_replication_group_seeds &#x3D;&#39;192.168.100.101:33061,192.168.100.103:33061,192.168.100.105:33061&#39;loose-group_replication_bootstrap_group &#x3D; off /mysqldata/conf.d/s2/my.cnf 12345678910111213141516171819202122[mysqld]port&#x3D;3306datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysqlpid-file&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pidsocket&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sockserver_id&#x3D;3gtid_mode&#x3D;ONenforce_gtid_consistency&#x3D;ONmaster_info_repository&#x3D;TABLErelay_log_info_repository&#x3D;TABLEbinlog-format&#x3D;ROWbinlog_checksum&#x3D;NONElog-slave-updates&#x3D;1log_bin&#x3D;binlogrelay-log&#x3D;bogon-relay-bintransaction_write_set_extraction &#x3D; XXHASH64loose-group_replication_group_name&#x3D;&quot;81263447-5a2b-11e9-94c6-0242c0a86465&quot;loose-group_replication_start_on_boot &#x3D; offloose-group_replication_local_address &#x3D; &#39;192.168.100.103:33061&#39;loose-group_replication_group_seeds &#x3D;&#39;192.168.100.101:33061,192.168.100.103:33061,192.168.100.105:33061&#39;loose-group_replication_bootstrap_group &#x3D; off /mysqldata/conf.d/s2/my.cnf 12345678910111213141516171819202122[mysqld]port&#x3D;3306datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysqlpid-file&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pidsocket&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.sockserver_id&#x3D;5gtid_mode&#x3D;ONenforce_gtid_consistency&#x3D;ONmaster_info_repository&#x3D;TABLErelay_log_info_repository&#x3D;TABLEbinlog-format&#x3D;ROWbinlog_checksum&#x3D;NONElog-slave-updates&#x3D;1log_bin&#x3D;binlogrelay-log&#x3D;bogon-relay-bintransaction_write_set_extraction &#x3D; XXHASH64loose-group_replication_group_name&#x3D;&quot;81263447-5a2b-11e9-94c6-0242c0a86465&quot;loose-group_replication_start_on_boot &#x3D; offloose-group_replication_local_address &#x3D; &#39;192.168.100.105:33061&#39;loose-group_replication_group_seeds &#x3D;&#39;192.168.100.101:33061,192.168.100.103:33061,192.168.100.105:33061&#39;loose-group_replication_bootstrap_group &#x3D; off 启动mysql123docker run --detach --memory&#x3D;512m --memory-swap&#x3D;1g --hostname&#x3D;mgr-s1 --net&#x3D;mysqlsubnet --ip&#x3D;192.168.100.101 --add-host mgr-s2:192.168.100.103 --add-host mgr-s3:192.168.100.105 --publish 3306:3306 --volume&#x3D;&#x2F;mysqldata&#x2F;conf.d&#x2F;s1&#x2F;:&#x2F;etc&#x2F;mysql&#x2F;conf.d --volume&#x3D;&#x2F;mysqldata&#x2F;s1:&#x2F;var&#x2F;lib&#x2F;mysql --name&#x3D;mgr-s1 -e MYSQL_ROOT_PASSWORD&#x3D;password -d mysql:5.7docker run --detach --memory&#x3D;512m --memory-swap&#x3D;1g --hostname&#x3D;mgr-s2 --net&#x3D;mysqlsubnet --ip&#x3D;192.168.100.103 --add-host mgr-s1:192.168.100.101 --add-host mgr-s3:192.168.100.105 --publish 3307:3306 --volume&#x3D;&#x2F;mysqldata&#x2F;conf.d&#x2F;s2&#x2F;:&#x2F;etc&#x2F;mysql&#x2F;conf.d --volume&#x3D;&#x2F;mysqldata&#x2F;s2:&#x2F;var&#x2F;lib&#x2F;mysql --name&#x3D;mgr-s2 -e MYSQL_ROOT_PASSWORD&#x3D;password -d mysql:5.7docker run --detach --memory&#x3D;512m --memory-swap&#x3D;1g --hostname&#x3D;mgr-s3 --net&#x3D;mysqlsubnet --ip&#x3D;192.168.100.105 --add-host mgr-s1:192.168.100.101 --add-host mgr-s2:192.168.100.103 --publish 3308:3306 --volume&#x3D;&#x2F;mysqldata&#x2F;conf.d&#x2F;s3&#x2F;:&#x2F;etc&#x2F;mysql&#x2F;conf.d --volume&#x3D;&#x2F;mysqldata&#x2F;s3:&#x2F;var&#x2F;lib&#x2F;mysql --name&#x3D;mgr-s3 -e MYSQL_ROOT_PASSWORD&#x3D;password -d mysql:5.7 设置复制组1234567891011121314151617docker exec -it mgr-s1 &#x2F;bin&#x2F;bashmysql -uroot -ppasswordSET SQL_LOG_BIN&#x3D;0;CREATE USER rpl_user@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#39;%&#39;;FLUSH PRIVILEGES;SET SQL_LOG_BIN&#x3D;1;CHANGE MASTER TO MASTER_USER&#x3D;&#39;rpl_user&#39;, MASTER_PASSWORD&#x3D;&#39;password&#39; FOR CHANNEL &#39;group_replication_recovery&#39;;INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;;SHOW PLUGINS;SET GLOBAL group_replication_bootstrap_group&#x3D;ON;START GROUP_REPLICATION;SET GLOBAL group_replication_bootstrap_group&#x3D;OFF;SELECT * FROM performance_schema.replication_group_members; 向复制组中增加成员1123456789101112131415docker exec -it mgr-s2 &#x2F;bin&#x2F;bashmysql -uroot -ppasswordSET SQL_LOG_BIN&#x3D;0;CREATE USER rpl_user@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#39;%&#39;;FLUSH PRIVILEGES;SET SQL_LOG_BIN&#x3D;1;CHANGE MASTER TO MASTER_USER&#x3D;&#39;rpl_user&#39;, MASTER_PASSWORD&#x3D;&#39;password&#39; FOR CHANNEL &#39;group_replication_recovery&#39;;INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;;SHOW PLUGINS;set global group_replication_allow_local_disjoint_gtids_join&#x3D;ON;START GROUP_REPLICATION;SELECT * FROM performance_schema.replication_group_members; 向复制组中增加成员2123456789101112131415docker exec -it mgr-s3 &#x2F;bin&#x2F;bashmysql -uroot -ppasswordSET SQL_LOG_BIN&#x3D;0;CREATE USER rpl_user@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#39;%&#39;;FLUSH PRIVILEGES;SET SQL_LOG_BIN&#x3D;1;CHANGE MASTER TO MASTER_USER&#x3D;&#39;rpl_user&#39;, MASTER_PASSWORD&#x3D;&#39;password&#39; FOR CHANNEL &#39;group_replication_recovery&#39;;INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;;SHOW PLUGINS;set global group_replication_allow_local_disjoint_gtids_join&#x3D;ON;START GROUP_REPLICATION;SELECT * FROM performance_schema.replication_group_members;","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Cannot set LC_ALL to default locale","slug":"issuse_locale","date":"2019-10-13T16:00:00.000Z","updated":"2020-12-04T11:24:29.131Z","comments":true,"path":"2019/10/14/issuse_locale/","link":"","permalink":"http://yoursite.com/2019/10/14/issuse_locale/","excerpt":"locale: Cannot set LC_ALL to default locale: No such file or directory","text":"locale: Cannot set LC_ALL to default locale: No such file or directory 123456789101112131415161718[root@kubemaster ~]# localelocale: Cannot set LC_CTYPE to default locale: No such file or directorylocale: Cannot set LC_MESSAGES to default locale: No such file or directorylocale: Cannot set LC_ALL to default locale: No such file or directoryLANG&#x3D;zh_CN.UTF-8LC_CTYPE&#x3D;&quot;zh_CN.UTF-8&quot;LC_NUMERIC&#x3D;&quot;zh_CN.UTF-8&quot;LC_TIME&#x3D;&quot;zh_CN.UTF-8&quot;LC_COLLATE&#x3D;&quot;zh_CN.UTF-8&quot;LC_MONETARY&#x3D;&quot;zh_CN.UTF-8&quot;LC_MESSAGES&#x3D;&quot;zh_CN.UTF-8&quot;LC_PAPER&#x3D;&quot;zh_CN.UTF-8&quot;LC_NAME&#x3D;&quot;zh_CN.UTF-8&quot;LC_ADDRESS&#x3D;&quot;zh_CN.UTF-8&quot;LC_TELEPHONE&#x3D;&quot;zh_CN.UTF-8&quot;LC_MEASUREMENT&#x3D;&quot;zh_CN.UTF-8&quot;LC_IDENTIFICATION&#x3D;&quot;zh_CN.UTF-8&quot;LC_ALL&#x3D;zh_CN.UTF-8 1yum -y install glibc","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"基于 GTID 的 MySQL 双主安装及配置","slug":"mysql_replication","date":"2019-09-14T17:31:26.000Z","updated":"2020-12-04T12:20:41.183Z","comments":true,"path":"2019/09/15/mysql_replication/","link":"","permalink":"http://yoursite.com/2019/09/15/mysql_replication/","excerpt":"基于 GTID 的 MySQL 双主安装及配置","text":"基于 GTID 的 MySQL 双主安装及配置 环境 CentOS 7 MySQL 5.7 hostname ipaddress mysql01 192.168.33.31 mysql02 192.168.33.32 1. 下载MySQL安装包mysql-community-server-5.7.28mysql-community-client-5.7.28mysql-community-common-5.7.28mysql-community-libs-5.7.28mysql-community-libs-compat-5.7.28mysql-community-devel-5.7.28 2. 安装MySQL12[root@mysql01 ~]# yum -y remove mariadb-*[root@mysql01 ~]# rpm -ivh mysql-community-* 12[root@mysql02 ~]# yum -y remove mariadb-*[root@mysql02 ~]# rpm -ivh mysql-community-* 3. 配置/etc/my.cnf123456789101112131415[root@mysql01 ~]# cat &#x2F;etc&#x2F;my.cnf | grep -Ev &quot;#|^$&quot;[mysqld]server-id &#x3D; 1log-bin &#x3D; mysql-binbinlog_format &#x3D; rowgtid_mode &#x3D; onenforce_gtid_consistency &#x3D; onlog-slave-updates &#x3D; onauto_increment_offset &#x3D; 1auto_increment_increment &#x3D; 2datadir &#x3D; &#x2F;var&#x2F;lib&#x2F;mysqlsocket &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.socksymbolic-links &#x3D; 0log-error &#x3D; &#x2F;var&#x2F;log&#x2F;mysqld.logpid-file &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid 12345678910111213[root@mysql02 ~]# cat &#x2F;etc&#x2F;my.cnf | grep -Ev &quot;#|^$&quot;server-id &#x3D; 2log-bin &#x3D; mysql-binbinlog_format &#x3D; rowgtid_mode &#x3D; onenforce_gtid_consistency &#x3D; onauto_increment_offset &#x3D; 2auto_increment_increment &#x3D; 2datadir &#x3D; &#x2F;var&#x2F;lib&#x2F;mysqlsocket &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.socksymbolic-links &#x3D; 0log-error &#x3D; &#x2F;var&#x2F;log&#x2F;mysqld.logpid-file &#x3D; &#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid 3. 配置replication mysql01、mysql02创建同步用户 12345[root@mysql01 ~]# systemctl enable mysqld[root@mysql01 ~]# systemctl start mysqld[root@mysql01 ~]# mysql -uroot -pP@ssw0rdmysql&gt; create user replication@&#39;%&#39; identified by &#39;P@ssw0rd&#39;;mysql&gt; grant replication slave on *.* to replication@&#39;%&#39;; 12345[root@mysql02 ~]# systemctl enable mysqld[root@mysql02 ~]# systemctl start mysqld[root@mysql02 ~]# mysql -uroot -pP@ssw0rdmysql&gt; create user replication@&#39;%&#39; identified by &#39;P@ssw0rd&#39;;mysql&gt; grant replication slave on *.* to replication@&#39;%&#39;; 备库配置slave 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[root@mysql02 ~]# mysql -uroot -pP@ssw0rdmysql&gt; CHANGE MASTER TO mysql&gt; MASTER_HOST&#x3D;&#39;192.168.33.31&#39;, mysql&gt; MASTER_USER&#x3D;&#39;replication&#39;, mysql&gt; MASTER_PASSWORD&#x3D;&#39;P@ssw0rd&#39;, mysql&gt; MASTER_AUTO_POSITION&#x3D;1;mysql&gt; start slave;mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.33.31 Master_User: replication Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000005 Read_Master_Log_Pos: 1146 Relay_Log_File: mysql02-relay-bin.000003 Relay_Log_Pos: 1359 Relay_Master_Log_File: mysql-bin.000005 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 1146 Relay_Log_Space: 1568 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: be182906-ef69-11e9-b8e6-5254008afee6 Master_Info_File: &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: be182906-ef69-11e9-b8e6-5254008afee6:1-5 Executed_Gtid_Set: be182906-ef69-11e9-b8e6-5254008afee6:1-5 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version:1 row in set (0.00 sec) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@mysql01 ~]# mysql -uroot -pP@ssw0rdmysql&gt; CHANGE MASTER TO mysql&gt; MASTER_HOST&#x3D;&#39;192.168.33.32&#39;, mysql&gt; MASTER_USER&#x3D;&#39;replication&#39;, mysql&gt; MASTER_PASSWORD&#x3D;&#39;P@ssw0rd&#39;, mysql&gt; MASTER_AUTO_POSITION&#x3D;1;mysql&gt; start slave;mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.33.32 Master_User: replication Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000003 Read_Master_Log_Pos: 859 Relay_Log_File: mysql01-relay-bin.000007 Relay_Log_Pos: 1072 Relay_Master_Log_File: mysql-bin.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 859 Relay_Log_Space: 1581 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 2 Master_UUID: dc67074d-ef6a-11e9-be75-5254008afee6 Master_Info_File: &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: dc67074d-ef6a-11e9-be75-5254008afee6:1-4 Executed_Gtid_Set: be182906-ef69-11e9-b8e6-5254008afee6:1-31944,dc67074d-ef6a-11e9-be75-5254008afee6:1-4 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version:1 row in set (0.00 sec)","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"开启mysql慢查询和死锁日志","slug":"mysql_slow_query","date":"2019-09-14T17:31:26.000Z","updated":"2020-12-04T12:20:48.294Z","comments":true,"path":"2019/09/15/mysql_slow_query/","link":"","permalink":"http://yoursite.com/2019/09/15/mysql_slow_query/","excerpt":"开启mysql慢查询和死锁日志","text":"开启mysql慢查询和死锁日志 显示慢查询状态及日志目录12345678show variables like &#39;%slow_query_log%&#39;;+---------------------+--------------------------------------+| Variable_name | Value |+---------------------+--------------------------------------+| slow_query_log | OFF || slow_query_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;9e6bec7d7160-slow.log |+---------------------+--------------------------------------+ 开启慢查询 说明: 1开启;0关闭; 1set global slow_query_log &#x3D; 1; 显示慢查询阈值(单位秒) 默认执行时间超过10s才会被记录到日志 1234567show variables like &#39;%long_query%&#39;;+-----------------+-----------+| Variable_name | Value |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+ 设置慢查询阈值 注意:设置后需要重新打开mysql客户端才能到最新的值 1set global long_query_time &#x3D; 0.8; 查看死锁的日志是否开启 1234567show variables like &quot;%innodb_print_all_deadlocks%&quot;;+----------------------------+-------+| Variable_name | Value |+----------------------------+-------+| innodb_print_all_deadlocks | OFF |+----------------------------+-------+ 开启记录死锁 1set global innodb_print_all_deadlocks&#x3D;1 查看最近一次deadlock 1show engine innodb status\\G;","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"pip 使用国内源","slug":"pip_cn","date":"2019-09-14T17:31:26.000Z","updated":"2020-12-04T12:21:52.134Z","comments":true,"path":"2019/09/15/pip_cn/","link":"","permalink":"http://yoursite.com/2019/09/15/pip_cn/","excerpt":"pip 使用国内源","text":"pip 使用国内源 1234567mkdir ~&#x2F;.pipcat &lt;&lt; EOF &gt; ~&#x2F;.pip&#x2F;pip.conf[global]index-url &#x3D; https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple[install]trusted-host &#x3D; tsinghua.edu.cnEOF","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"使用 vagrant 搭建 kubernetes 基础环境","slug":"vagrant_k8s","date":"2019-09-14T17:31:26.000Z","updated":"2020-12-04T11:24:29.145Z","comments":true,"path":"2019/09/15/vagrant_k8s/","link":"","permalink":"http://yoursite.com/2019/09/15/vagrant_k8s/","excerpt":"使用 vagrant 搭建 kubernetes 基础环境","text":"使用 vagrant 搭建 kubernetes 基础环境 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# -*- mode: ruby -*-# vi: set ft&#x3D;ruby :ENV[&quot;LC_ALL&quot;] &#x3D; &quot;en_US.UTF-8&quot;Vagrant.configure(&quot;2&quot;) do |config| config.vm.define &quot;kubemaster&quot; do |kubemaster| kubemaster.vm.box &#x3D; &quot;centos&#x2F;7&quot; kubemaster.vm.hostname &#x3D; &quot;kubemaster&quot; kubemaster.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.100&quot; kubemaster.vm.provider &quot;virtualbox&quot; do |vb| vb.gui &#x3D; false vb.cpus &#x3D; 2 vb.memory &#x3D; &quot;1024&quot; end end config.vm.define &quot;kubenode01&quot; do |kubenode01| kubenode01.vm.box &#x3D; &quot;centos&#x2F;7&quot; kubenode01.vm.hostname &#x3D; &quot;kubenode01&quot; kubenode01.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.101&quot; kubenode01.vm.provider &quot;virtualbox&quot; do |vb| vb.gui &#x3D; false vb.cpus &#x3D; 2 vb.memory &#x3D; &quot;1024&quot; end end config.vm.define &quot;kubenode02&quot; do |kubenode02| kubenode02.vm.box &#x3D; &quot;centos&#x2F;7&quot; kubenode02.vm.hostname &#x3D; &quot;kubenode02&quot; kubenode02.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.102&quot; kubenode02.vm.provider &quot;virtualbox&quot; do |vb| vb.gui &#x3D; false vb.cpus &#x3D; 2 vb.memory &#x3D; &quot;1024&quot; end end config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL sudo -i echo &quot;设置SSH&quot; sed -i &#39;s&#x2F;^#PermitRootLogin yes&#x2F;PermitRootLogin yes&#x2F;g&#39; &#x2F;etc&#x2F;ssh&#x2F;sshd_config sed -i &#39;s&#x2F;PasswordAuthentication no&#x2F;PasswordAuthentication yes&#x2F;g&#39; &#x2F;etc&#x2F;ssh&#x2F;sshd_config systemctl restart sshd echo &quot;manager&quot; | passwd --stdin root echo &quot;manager&quot; | passwd --stdin vagrant echo &quot;# 关闭firewalld、selinux&quot; setenforce 0 sed -i &#39;s&#x2F;^SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;g&#39; &#x2F;etc&#x2F;selinux&#x2F;config systemctl disable firewalld &amp;&amp; systemctl stop firewalld echo &quot;# 设置&#x2F;etc&#x2F;hosts&quot; cat &lt;&lt; EOF &gt;&gt; &#x2F;etc&#x2F;hosts192.168.33.100 kubemaster192.168.33.101 kubenode01192.168.33.102 kubenode02EOF echo &quot;# 安装依赖&quot; yum makecache yum -y install vim wget curl sysstat bind-utils zlib-devel openssl-devel conntrack ipvsadm sysstat wget git iptables-services yum-utils device-mapper-persistent-data lvm2 net-tools echo &quot;# 安装docker&quot; yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo yum install -y docker-ce systemctl enable docker &amp;&amp; systemctl start docker cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;docker&#x2F;daemon.json&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;], &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;100m&quot; &#125;&#125;EOF mkdir -p &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d systemctl daemon-reload &amp;&amp; systemctl restart docker echo &quot;# 启用iptables&quot; systemctl enable iptables &amp;&amp; systemctl start iptables iptables -F service iptables save echo &quot;# 关闭系统不需要的服务&quot; systemctl disable postfix &amp;&amp; systemctl stop postfix echo &quot;# kube-proxy开启ipvs&quot; modprobe br_netfilter cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules#!&#x2F;bin&#x2F;bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOF chmod 755 &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules &amp;&amp; bash &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules lsmod | grep -e ip_vs -e nf_conntrack_ipv4 echo &quot;# 调整内核参数&quot; cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.confnet.bridge.bridge-nf-call-ip6tables &#x3D; 1net.bridge.bridge-nf-call-iptables &#x3D; 1net.ipv6.conf.all.disable_ipv6 &#x3D; 1net.ipv4.ip_forward &#x3D; 1EOF sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf echo &quot;# 添加kubernetes源&quot; cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo[kubernetes]name&#x3D;Kubernetesbaseurl&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;repos&#x2F;kubernetes-el7-x86_64&#x2F;enabled&#x3D;1gpgcheck&#x3D;1repo_gpgcheck&#x3D;1gpgkey&#x3D;https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;yum-key.gpg https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;kubernetes&#x2F;yum&#x2F;doc&#x2F;rpm-package-key.gpgEOF SHELLend","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"vagrant","slug":"vagrant","permalink":"http://yoursite.com/tags/vagrant/"},{"name":"virtualbox","slug":"virtualbox","permalink":"http://yoursite.com/tags/virtualbox/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"}]},{"title":"Git 指南","slug":"git","date":"2019-05-25T16:00:00.000Z","updated":"2020-12-04T12:15:40.286Z","comments":true,"path":"2019/05/26/git/","link":"","permalink":"http://yoursite.com/2019/05/26/git/","excerpt":"","text":"1. 获取 Git 仓库在现有目录中初始化仓库1git init 克隆现有的仓库1git clone https://github.com/libgit2/libgit2 mylibgit 2. 记录每次更新到仓库检查当前文件状态1git status 跟踪新文件12git add READMEgit status 暂存已修改文件状态简览12git status --shortgit status -s 忽略文件使用 .gitignore 文件 所有空行或者以 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 glob 模式 星号（*）匹配零个或多个任意字符； [abc] 匹配任何一个列在方括号中的字符； 问号（?）只匹配一个任意字符； 如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配； 使用两个星号（*) 表示匹配任意中间目录。 查看已暂存和未暂存的修改 查看尚未暂存的文件更新了哪些部分 1git diff 查看已暂存的将要添加到下次提交里的内容 12git diff --stagedgit diff --cached 提交更新1git commit -m \"first commit\" 跳过使用暂存区域1git commit -a -m \"second commit\" 移除文件1git rm [file_name] 把文件从 Git 仓库中删除，文件保留在当前工作目录中 1git rm --cached [file_name] 移动文件1git mv file_from file_to 3. 查看提交历史1git log 12345678git log -p -2 # -p 显示每次提交的内容差异，-2 仅显示最近两次提交git log --stat # 查看提交的简略的统计信息git log --oneline # 将每个提交放在一行显示git log --shortgit log --fullgit log --fullergit log --pretty=onlinegit log --pretty=format:\"%h - %an, %ar : %s\" --graph # 定制要显示的记录格式 git log 常用选项 选项 说明 -p 按补丁格式显示每个更新之间的差异 –stat 显示每次更新的文件修改统计信息。 –shortstat 只显示 –stat 中最后的行数修改添加移除统计。 –name-only 仅在提交信息后显示已修改的文件清单。 –name-status 显示新增、修改、删除的文件清单。 –abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。 –relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。 –graph 显示 ASCII 图形表示的分支合并历史。 –pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）。 git log --pretty=format 常用的选项 选项 说明 %H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 –date= 选项定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者（committer）的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期，按多久以前的方式显示 %s 提交说明 限制输出长度1git log --since=2.weeks 限制 git log 输出的选项 选项 说明 -(n) 仅显示最近的 n 条提交 –since, –after 仅显示指定时间之后的提交 –until, –before 仅显示指定时间之前的提交 –author 仅显示指定作者相关的提交 –committer 仅显示指定提交者相关的提交 –grep 仅显示含指定关键字的提交 -S 仅显示添加或移除了某个关键字的提交 4. 撤消操作1git commit --amend 取消暂存的文件12# git reset HEAD &lt;file&gt; ...git reset HEAD CONTRIBUTING.md 撤消对文件的修改12# git checkout -- &lt;file&gt;git checkout -- CONTRIBUTING.md 5. 远程仓库的使用12345git clone https://github.com/schacon/ticgitgit remotegit remote -vgit remote add pb https://github.com/paulboone/ticgitgit fetch pb 从远程仓库中抓取与拉取1git fetch [remote-name] 推送到远程仓库1git push origin master 查看远程仓库12# git remote show [remote-name]git remote show origin 远程仓库的移除与重命名12git remote rename pb paulgit remote rm paul 6. 打标签列出标签12git taggit tag -l 'v1.8.5*' 创建标签附注标签123git tag -a v1.4 -m 'my version 1.4'git taggit show v1.4 # 查看标签信息与对应的提交信息 轻量标签12git tag v1.4-lwgit tag 后期打标签12git log --pretty=onelinegit tag -a v1.2 &lt;部分校验和&gt; # git tag -a v1.2 9fceb02 共享标签12git push origin v1.5git push origin --tags # 一次性推送全部标签 检出标签12# 使用 git checkout -b [branchname] [tagname] 在特定的标签上创建一个新分支git checkout -b version2 v2.0.0 7. Git 别名12345678git config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.ci commitgit config --global alias.st statusgit config --global alias.unstage 'reset HEAD --'git config --global alias.last 'log -1 HEAD'# 执行外部命令，在命令前面加入 ! 符号git config --global alias.visual '!gitk'","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"Prometheus + Grafana","slug":"promethues","date":"2019-02-27T11:59:14.000Z","updated":"2020-12-04T12:27:52.548Z","comments":true,"path":"2019/02/27/promethues/","link":"","permalink":"http://yoursite.com/2019/02/27/promethues/","excerpt":"开源监控平台 Prometheus","text":"开源监控平台 Prometheus 安装 GO12[root@master ~]# yum -y install go[root@mysqlnode05 go]# go version 安装 prometheus12345[root@master ~]# tar -zxvf prometheus-2.7.1.linux-amd64.tar.gz[root@master ~]# mv prometheus-2.7.1.linux-amd64 /appdata/prometheus[root@master ~]# cd /appdata/prometheus/# 修改prometheus.yml文件，配置targets其中的IP和端口则是对应的exporter的监听端口[root@master ~]# vim prometheus.yml 12345678910111213141516171819202122232425262728293031323334353637global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).alerting: alertmanagers: - static_configs: - targets: # - alertmanager:9093rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\"scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' static_configs: - targets: ['192.168.41.131:9090'] - job_name: 'master' static_configs: - targets: ['192.168.41.131:9100'] labels: instance: master - job_name: 'slave' static_configs: - targets: ['192.168.41.132:9100'] labels: instance: slave - job_name: 'mysql-master' static_configs: - targets: ['192.168.41.131:9104'] labels: instance: master - job_name: 'mysql-slave' static_configs: - targets: ['192.168.41.132:9104'] labels: instance: slave 12# 启动并通过web访问[root@master ~]# /appdata/prometheus/prometheus --config.file /appdata/prometheus/prometheus.yml &gt;&gt; /appdata/prometheus/prometheus.log 2&gt;&amp;1 &amp; 安装 mysqld_exporter123456789[root@master ~]# tar -zxvf mysqld_exporter-0.11.0.linux-amd64.tar.gz[root@master ~]# cp mysqld_exporter-0.11.0.linux-amd64/mysqld_exporter /appdata/prometheus/[root@master ~]# mysql -uroot -p# 创建专用用户mysql&gt; create user 'prometheus'@'%' identified by 'xxxxxx';mysql&gt; grant REPLICATION CLIENT,PROCESS,SELECT ON *.* TO 'prometheus'@'%';mysql&gt; flush privileges;# 创建exporter配置文件[root@master ~]# vim /appdata/prometheus/.my.cnf 123[client]user&#x3D;mysql_promepassword&#x3D;Aa123456789 12# 启动mysqld_exporter[root@master ~]# /appdata/prometheus/mysqld_exporter --config.my-cnf /appdata/prometheus/.my.cnf &gt;&gt; /appdata/prometheus/mysqld_exporter.log 2&gt;&amp;1 &amp; 安装 node_exporter1234[root@master ~]# tar -zxvf node_exporter-0.17.0.linux-amd64.tar.gz[root@master ~]# cp node_exporter-0.17.0.linux-amd64/node_exporter /appdata/prometheus/# 启动node_exporter[root@master ~]# /appdata/prometheus/node_exporter &gt;&gt; /appdata/prometheus/node_exporter.log 2&gt;&amp;1 &amp; 查看 target status浏览器访问 http://192.168.31.131:9090 安装 grafana12345[root@master ~]# wget https://dl.grafana.com/oss/release/grafana-6.0.0-1.x86_64.rpm [root@master ~]# yum -y install grafana-6.0.0-1.x86_64.rpm# 启动grafana[root@master ~]# systemctl enable grafana-server[root@master ~]# systemctl start grafana-server 添加数据源浏览器访问 http://192.168.31.131:3000","categories":[{"name":"monitor","slug":"monitor","permalink":"http://yoursite.com/categories/monitor/"}],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"http://yoursite.com/tags/prometheus/"}]},{"title":"MySQL 安装指南","slug":"mysql","date":"2019-02-17T16:00:00.000Z","updated":"2020-12-04T12:20:52.926Z","comments":true,"path":"2019/02/18/mysql/","link":"","permalink":"http://yoursite.com/2019/02/18/mysql/","excerpt":"MySQL 安装指南","text":"MySQL 安装指南 1. 安装并初始化数据库1234567891011121314[root@master ~]# lsmysql-8.0.15-linux-glibc2.12-x86_64.tar.xz[root@master ~]# tar -Jxf mysql-8.0.15-linux-glibc2.12-x86_64.tar.xz[root@master ~]# lsmysql-8.0.15-linux-glibc2.12-x86_64 mysql-8.0.15-linux-glibc2.12-x86_64.tar.xz[root@master ~]# mkdir /appdata [root@master ~]# mv mysql-8.0.15-linux-glibc2.12-x86_64 /appdata/mysql[root@master ~]# cd /appdata/mysql/bin[root@master bin]# ./mysqld --verbose --help[root@master bin]# ./mysqld --initialize --user=mysql2019-02-17T13:24:47.271942Z 0 [Warning] [MY-011070] [Server] 'Disabling symbolic links using --skip-symbolic-links (or equivalent) is the default. Consider not using this option as it' is deprecated and will be removed in a future release.2019-02-17T13:24:47.272022Z 0 [System] [MY-013169] [Server] /appdata/mysql/bin/mysqld (mysqld 8.0.15) initializing of server in progress as process 95172019-02-17T13:24:49.230753Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: fYd00.&lt;Ucx:02019-02-17T13:24:50.553995Z 0 [System] [MY-013170] [Server] /appdata/mysql/bin/mysqld (mysqld 8.0.15) initializing of server has completed 2. 编辑自定义配置文件1[root@master ~]# vim /etc/my.cnf 1234567891011121314151617[mysqld]port&#x3D;3306basedir&#x3D;&#x2F;appdata&#x2F;mysqldatadir&#x3D;&#x2F;appdata&#x2F;mysql&#x2F;datasocket&#x3D;&#x2F;appdata&#x2F;mysql&#x2F;data&#x2F;mysql.socklog-bin&#x3D;mysql-binserver-id&#x3D;1binlog_format&#x3D;MIXEDgtid_mode &#x3D; onenforce_gtid_consistency &#x3D; 1log_slave_updates &#x3D; 1max_allowed_packet &#x3D; 128Minteractive_timeout &#x3D; 28800000wait_timeout &#x3D; 28800000[client]socket&#x3D;&#x2F;appdata&#x2F;mysql&#x2F;data&#x2F;mysql.sock 3. 启动MySQL12[root@master ~]# cp /appdata/mysql/support-files/mysql.server /etc/init.d/[root@master ~]# vim /etc/init.d/mysql.server 12basedir&#x3D;&#x2F;appdata&#x2F;mysqldatadir&#x3D;&#x2F;appdata&#x2F;mysql&#x2F;data 1[root@master ~]# /etc/init.d/mysql.server start 4. 设置主从同步1[root@master ~]# mysql -uroot -pfYd00.&lt;Ucx:0 12345678910111213141516171819202122232425262728293031323334353637383940mysql&gt; ALTER USER root@'localhost' IDENTIFIED BY 'Abc123';Query OK, 0 rows affected (0.04 sec)mysql&gt; CREATE USER replication@'%' IDENTIFIED WITH 'mysql_native_password' BY 'replication';Query OK, 0 rows affected (0.04 sec)mysql&gt; grant replication slave on *.* to replication@'%';Query OK, 0 rows affected (0.00 sec)mysql&gt; ALTER TABLE mysql.slave_master_info ENGINE=InnoDB;Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; ALTER TABLE mysql.slave_relay_log_info ENGINE=InnoDB;Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; reset slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; CHANGE MASTER TO MASTER_HOST=\"slave.example.com\",MASTER_USER='replication',MASTER_PASSWORD=\"replication\",MASTER_AUTO_POSITION=1;Query OK, 0 rows affected, 2 warnings (0.01 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: slave.example.com Master_User: replication Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000015 Read_Master_Log_Pos: 1567 Relay_Log_File: master-relay-bin.000003 Relay_Log_Pos: 456 Relay_Master_Log_File: mysql-bin.000015 Slave_IO_Running: Yes Slave_SQL_Running: Yes 5. 问题处理 Error_code: MY-002061 不兼容的变化： 在caching_sha2_password和 sha256_password认证插件提供比更安全的密码加密 mysql_native_password插件，并 caching_sha2_password提供了比更好的性能sha256_password。由于这些优越的安全性和性能特性 caching_sha2_password，它现在是首选的身份验证插件，而且也是默认的身份验证插件而不是 mysql_native_password。此更改会影响服务器和libmysqlclient客户端库： 对于服务器，default_authentication_plugin 系统变量的默认值 从更改 mysql_native_password为 caching_sha2_password。 该libmysqlclient库将其 caching_sha2_password视为默认的身份验证插件而不是 mysql_native_password。 此更改仅影响用于创建新MySQL帐户的身份验证插件。对于已升级安装中已存在的帐户，其身份验证插件保持不变。 使用经过身份验证的帐户的客户端 caching_sha2_password必须使用安全连接（使用TCP使用TLS / SSL凭据，Unix套接字文件或共享内存制作），或使用RSA密钥对支持密码交换的未加密连接。此安全要求不适用 mysql_native_passsword，因此交换机 caching_sha2_password可能需要其他配置（请参阅 缓存SHA-2可插入身份验证）。但是，默认情况下，MySQL 8.0中的客户端连接更喜欢使用TLS / SSL，因此已满足该首选项的客户端可能不需要其他配置。 因为caching_sha2_password现在也是libmysqlclient客户端库中的默认身份验证插件，所以 身份验证需要在客户端/服务器协议中进行额外的往返，以便从MySQL 8.0客户端连接到使用mysql_native_password（以前的默认身份验证插件）的帐户 ，除非调用客户端程序一个 –default-auth=mysql_native_password 选择。 不兼容：尚未更新的客户端和连接器 caching_sha2_password 无法连接到通过身份验证的帐户，caching_sha2_password 因为他们无法将此插件识别为有效。要解决此问题，请libmysqlclient从MySQL 8.0.4或更高版本重新链接客户端 ，或获取可识别的更新连接器 caching_sha2_password。 不兼容：尚未更新的客户端和连接器 caching_sha2_password可能无法连接到配置caching_sha2_password为默认身份验证插件的MySQL 8.0服务器 ，甚至使用未通过身份验证的帐户caching_sha2_password。出现此问题的原因是服务器为客户端指定其默认身份验证插件的名称。如果客户端或连接器基于未正常处理无法识别的默认身份验证插件的客户端/服务器协议实现，则可能会失败并显示错误。 ERROR 1872 (HY000): Slave failed to initialize relay log info structure from the repository","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Kubernetes 离线安装","slug":"k8s","date":"2019-02-06T17:31:26.000Z","updated":"2020-12-04T12:18:53.396Z","comments":true,"path":"2019/02/07/k8s/","link":"","permalink":"http://yoursite.com/2019/02/07/k8s/","excerpt":"Kubernetes 离线安装","text":"Kubernetes 离线安装 123456789101112131415161718192021cat /etc/hosts192.168.61.11 node1192.168.61.12 node2systemctl stop firewalldsystemctl disable firewalldsetenforce 0vim /etc/selinux/configSELINUX=disabledvim /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1modprobe br_netfiltersysctl -p /etc/sysctl.d/k8s.conf kube-proxy开启ipvs的前置条件123456789101112cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4# 查看是否已经正确加载所需的内核模块lsmod | grep -e ip_vs -e nf_conntrack_ipv4 安装Docker123456789101112131415sudo yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息sudo yum-config-manager --add-repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo# Step 3: 更新并安装 Docker-CEsudo yum makecache fastyum list docker-ce.x86_64 --showduplicates |sort -ryum makecache fastyum install -y --setopt&#x3D;obsoletes&#x3D;0 \\ docker-ce-18.06.1.ce-3.el7systemctl start dockersystemctl enable docker 1iptables -nvL 安装kubeadm和kubelet123456789101112cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFyum install -y kubelet kubeadm kubectlsystemctl enable kubelet &amp;&amp; systemctl start kubelet 1234567kubelet –helpcat &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;kubelet.service.d&#x2F;10-kubeadm.confvim &#x2F;etc&#x2F;sysconfig&#x2F;kubeletKUBELET_EXTRA_ARGS&#x3D;--fail-swap-on&#x3D;false 使用kubeadm init初始化集群12345678910111213141516171819202122232425262728293031323334353637kubeadm config images list#!/bin/bashimages=(kube-apiserver:v1.13.3 kube-controller-manager:v1.13.3 kube-scheduler:v1.13.3 kube-proxy:v1.13.3 pause:3.1 etcd:3.2.24)for imageName in $&#123;images[@]&#125; ; do docker pull mirrorgooglecontainers/$imageName docker tag mirrorgooglecontainers/$imageName k8s.gcr.io/$imageName docker rmi mirrorgooglecontainers/$imageNamedone docker pull coredns/coredns:1.2.6 docker tag coredns/coredns:1.2.6 k8s.gcr.io/coredns:1.2.6 docker rmi coredns/coredns:1.2.6kubeadm init \\ --kubernetes-version=v1.13.0 \\ --pod-network-cidr=10.244.0.0/16 \\ --apiserver-advertise-address=192.168.41.132 \\ --ignore-preflight-errors=Swap# running with swap on is not supported. Please disable swap# 添加--ignore-preflight-errors=Swap参数忽略这个错误mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configkubeadm join 192.168.41.132:6443 --token e4xr2p.xvfc3dr6a4dvz8se --discovery-token-ca-cert-hash sha256:7f99258581c9118551ec500b61bf3d732ed6e31799e5074fc5f75b784633410akubectl get cs# 集群初始化如果遇到问题，可以使用下面的命令进行清理kubeadm reset 安装Pod Network1234mkdir -p ~/k8s/cd ~/k8swget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlkubectl apply -f kube-flannel.yml","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"},{"name":"Kubernetes","slug":"linux/Kubernetes","permalink":"http://yoursite.com/categories/linux/Kubernetes/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://yoursite.com/tags/Kubernetes/"}]},{"title":"MySQL 组复制","slug":"mgr","date":"2019-01-30T04:24:39.000Z","updated":"2020-12-04T12:20:21.130Z","comments":true,"path":"2019/01/30/mgr/","link":"","permalink":"http://yoursite.com/2019/01/30/mgr/","excerpt":"MySQL 组复制","text":"MySQL 组复制 1. 部署组复制实例假定MySQL Server已下载并解压缩到名为的目录中mysql-8.0。以下过程使用一台物理计算机，因此每个MySQL服务器实例都需要该实例的特定数据目录。在名为的目录中创建数据目录data 并初始化每个目录。 1234mkdir datamysql-8.0&#x2F;bin&#x2F;mysqld --initialize-insecure --basedir&#x3D;$PWD&#x2F;mysql-8.0 --datadir&#x3D;$PWD&#x2F;data&#x2F;s1mysql-8.0&#x2F;bin&#x2F;mysqld --initialize-insecure --basedir&#x3D;$PWD&#x2F;mysql-8.0 --datadir&#x3D;$PWD&#x2F;data&#x2F;s2mysql-8.0&#x2F;bin&#x2F;mysqld --initialize-insecure --basedir&#x3D;$PWD&#x2F;mysql-8.0 --datadir&#x3D;$PWD&#x2F;data&#x2F;s3 里面data/s1，data/s2， data/s3是一个初始化的数据目录，包含了MySQL系统数据库和相关表等等 –initialize-insecure在生产环境中使用，它仅用于简化教程。 2. 配置组复制实例组Replication Server设置要安装和使用组复制插件，必须正确配置MySQL Server实例。建议将配置存储在实例的配置文件中。以下是组中第一个实例的配置，在此过程中称为s1。以下部分显示了示例服务器配置。 12345678[mysqld]# server configurationdatadir&#x3D;&lt;full_path_to_data&gt;&#x2F;data&#x2F;s1basedir&#x3D;&lt;full_path_to_bin&gt;&#x2F;mysql-8.0&#x2F;port&#x3D;24801socket&#x3D;&lt;full_path_to_sock_dir&gt;&#x2F;s1.sock 这些设置将MySQL服务器配置为使用先前创建的数据目录以及服务器应打开的端口并开始侦听传入连接。 使用非默认端口24801是因为在本教程中，三个服务器实例使用相同的主机名。在具有三台不同机器的设置中，这不是必需的。 组复制需要成员之间的网络连接，这意味着每个成员必须能够解析所有其他成员的网络地址。例如，在本教程中，所有三个实例都在一台机器上运行，因此为了确保成员可以相互联系，您可以在选项文件中添加一行，例如 report_host=127.0.0.1。 复制框架以下设置根据MySQL组复制要求配置复制。 1234server_id&#x3D;1gtid_mode&#x3D;ONenforce_gtid_consistency&#x3D;ONbinlog_checksum&#x3D;NONE 这些设置将服务器配置为使用唯一标识符编号1，以启用全局事务标识符，以允许仅执行可使用GTID安全记录的语句，以及禁用写入写入二进制日志的事件的校验和。 如果您使用的是早于8.0.3的MySQL版本，其中默认值已针对复制进行了改进，则需要将这些行添加到成员的选项文件中。 12345log_bin&#x3D;binloglog_slave_updates&#x3D;ONbinlog_format&#x3D;ROWmaster_info_repository&#x3D;TABLErelay_log_info_repository&#x3D;TABLE 这些设置指示服务器打开二进制日志记录，使用基于行的格式，将复制元数据存储在系统表而不是文件中，并禁用二进制日志事件校验和。有关更多详细信息，请参见 第18.8.1节“组复制要求”。 组复制设置此时，该my.cnf文件确保配置服务器并指示在给定配置下实例化复制基础结构。以下部分配置服务器的“组复制”设置。 123456transaction_write_set_extraction&#x3D;XXHASH64group_replication_group_name&#x3D;&quot;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa&quot;group_replication_start_on_boot&#x3D;offgroup_replication_local_address&#x3D; &quot;127.0.0.1:24901&quot;group_replication_group_seeds&#x3D; &quot;127.0.0.1:24901,127.0.0.1:24902,127.0.0.1:24903&quot;group_replication_bootstrap_group&#x3D;off 配置 transaction_write_set_extraction 指示服务器对于每个事务，它必须收集写集并使用XXHASH64散列算法将其编码为散列。从MySQL 8.0.2开始，此设置是默认设置，因此可以省略此行。 配置 group_replication_group_name 告诉插件它正在加入或创建的组被命名为”aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa”，group_replication_group_name的值 必须是有效的UUID。在二进制日志中为组复制事件设置GTID时，将在内部使用此UUID。使用SELECT UUID()生成一个UUID。 配置 group_replication_start_on_boot 指示插件在服务器启动时不自动启动操作。这在设置组复制时很重要，因为它确保您可以在手动启动插件之前配置服务器。配置成员后，您可以设置 group_replication_start_on_boot 为on，以便在服务器引导时自动启动Group Replication。 配置 group_replication_local_address 告诉插件使用网络地址127.0.0.1和端口24901与组中的其他成员进行内部通信。 组复制将此地址用于涉及组通信引擎（XCom，Paxos变体）的远程实例的内部成员到成员连接。此地址必须与用于SQL的主机名和端口不同，并且不得用于客户端应用程序。在运行组复制时，必须为组成员之间的内部通信保留它。 配置的网络地址 group_replication_local_address 必须可由所有组成员解析。例如，如果每个服务器实例位于具有固定网络地址的其他计算机上，则可以使用计算机的IP地址，例如10.0.0.1。如果使用主机名，则必须使用完全限定名称，并确保它可以通过DNS解析，并且配置正确 /etc/hosts文件或其他名称解析过程。从MySQL 8.0.14开始，可以使用IPv6地址（或解析它们的主机名）以及IPv4地址。组可以包含使用IPv6的成员和使用IPv4的成员的混合。 建议的端口 group_replication_local_address 是33061。在本教程中，我们使用在一台计算机上运行的三个服务器实例，因此端口24901到24903用于内部通信网络地址。 group_replication_local_address Group Replication使用它作为复制组中组成员的唯一标识符。只要主机名或IP地址都不同，您就可以为复制组的所有成员使用相同的端口，并且如本教程所示，只要具有相同的主机名或IP地址，就可以使用相同的主机名或IP地址。港口都不一样。 配置 group_replication_group_seeds 设置组成员的主机名和端口，新成员使用它们建立与组的连接。这些成员称为种子成员。建立连接后，将列出组成员身份信息 performance_schema.replication_group_members。通常， group_replication_group_seeds 列表包含hostname:port每个组成员的列表 group_replication_local_address，但这不是强制性的，可以选择组成员的子集作为种子。 该hostname:port列在 group_replication_group_seeds 是种子构件的内部网络地址，由被配置 group_replication_local_address ，而不是SQL hostname:port用于客户端连接，并且例如在显示 performance_schema.replication_group_members 表中。 启动该组的服务器不使用此选项，因为它是初始服务器，因此，它负责引导组。换句话说，引导该组的服务器上的任何现有数据都是用作下一个加入成员的数据。第二个服务器连接要求组中唯一的成员加入，第二个服务器上的任何缺失数据都从引导成员上的施主数据中复制，然后组扩展。加入的第三个服务器可以要求这两个服务器中的任何一个加入，数据被同步到新成员，然后该组再次扩展。 在同时加入多个服务器时，请确保它们指向已在该组中的种子成员。不要使用也加入该组的成员作为种子，因为他们在联系时可能尚未加入该组。 最好首先启动引导程序成员，然后让它创建组。然后使其成为正在加入的其余成员的种子成员。这确保了在连接其余成员时形成的组。 不支持创建组并同时加入多个成员。它可能有效，但可能是操作竞争，然后加入该组的行为最终会出错或超时。 加入成员必须使用种子成员在group_replication_group_seeds 选项中通告的相同协议（IPv4或IPv6）与种子成员通信 。出于组复制的IP地址白名单的目的，种子成员上的白名单必须包含种子成员提供的协议的加入成员的IP地址，或者解析为该协议的地址的主机名。除了加入成员之外，还必须设置此地址或主机名并列入白名单 group_replication_local_address 如果该地址的协议与种子成员的通告协议不匹配。如果加入成员没有适当协议的白名单地址，则拒绝其连接尝试。有关更多信息，请参见 第18.5.1节“IP地址白名单”。 配置 group_replication_bootstrap_group 指示插件是否引导组。 此选项只能在任何时候在一个服务器实例上使用，通常是第一次引导组时（或者在整个组关闭并重新备份的情况下）。如果多次引导组，例如当多个服务器实例设置了此选项时，则可以创建一个人工分裂脑情景，其中存在两个具有相同名称的不同组。在第一个服务器实例联机后禁用此选项。组中所有服务器的配置非常相似。您需要更改有关每个服务器的细节（例如server_id， datadir， group_replication_local_address）。本教程稍后将对此进行说明。 3. 用户凭证组复制使用异步复制协议来实现 分布式恢复过程依赖于名为的复制通道group_replication_recovery，该通道用于将来自供体成员的事务转移到加入该组的成员。因此，您需要设置具有正确权限的复制用户，以便组复制可以建立直接的成员到成员恢复复制通道。 使用选项文件启动服务器： 1mysql-8.0&#x2F;bin&#x2F;mysqld --defaults-file&#x3D;data&#x2F;s1&#x2F;s1.cnf 使用该REPLICATION-SLAVE权限创建MySQL用户 。可以在二进制日志中捕获此过程，然后您可以依靠分布式恢复来复制用于创建用户的语句。或者，您可以禁用二进制日志记录，然后在每个成员上手动创建用户，例如，如果要避免将更改传播到其他服务器实例。要禁用二进制日志记录，请连接到服务器s1并发出以下语句： 1mysql&gt; SET SQL_LOG_BIN&#x3D;0; 在以下示例中rpl_user，将password显示具有密码 的用户 。配置服务器时，请使用合适的用户名和密码。 123mysql&gt; CREATE USER rpl_user@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;mysql&gt; GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#39;%&#39;;mysql&gt; FLUSH PRIVILEGES; 如果禁用了二进制日志记录，则在创建用户后再次启用它。 1mysql&gt; SET SQL_LOG_BIN&#x3D;1; 配置用户后，使用该 CHANGE MASTER TO语句将服务器配置为group_replication_recovery在下次需要从另一个成员恢复其状态时使用复制通道的给定凭据 。发出以下，替换 rpl_user和 password与创建用户时使用的值。 12mysql&gt; CHANGE MASTER TO MASTER_USER&#x3D;&#39;rpl_user&#39;, MASTER_PASSWORD&#x3D;&#39;password&#39; \\\\ FOR CHANNEL &#39;group_replication_recovery&#39;; 分布式恢复是加入组的服务器采取的第一步，并且没有与组成员相同的事务集。如果没有为group_replication_recovery 复制通道正确设置这些凭据，并且rpl_user如图所示，则服务器无法连接到供体成员并运行分布式恢复过程以与其他组成员同步，因此最终无法加入该组。 同样，如果服务器无法通过服务器正确识别其他成员，hostname则恢复过程可能会失败。建议运行MySQL的操作系统具有正确配置的唯一 hostname，使用DNS或本地设置。这hostname可以Member_host在performance_schema.replication_group_members 表格的列中 进行验证 。如果多个组成员外部化hostname操作系统的默认 设置，则成员可能无法解析为正确的成员地址而无法加入该组。在这种情况下，使用report_host配置hostname由每个服务器外部化的唯一。 使用组复制和缓存SHA-2用户凭据插件默认情况下，在MySQL 8中创建的用户使用 缓存SHA-2可插入身份验证。如果rpl_user您配置分布式恢复使用缓存SHA-2认证插件并没有使用安全套接字层支持（SSL） 的group_replication_recovery 复制通道，RSA密钥用于密码交换，创建SSL和RSA证书和密钥，您可以将rpl_user应该从组中恢复其状态的成员的公钥复制 到该组，也可以将捐赠者配置为在请求时提供公钥。 更安全的方法是将公钥复制 rpl_user到应该从捐赠者恢复组状态的成员。然后，您需要group_replication_recovery_public_key_path 在加入组的成员上配置 系统变量，并为其提供公钥的路径rpl_user。 可选地，不太安全的方法是设置 group_replication_recovery_get_public_key=ON 捐赠者，以便他们rpl_user在加入组时提供成员的公钥 。无法验证服务器的身份，因此只有group_replication_recovery_get_public_key=ON 在您确定没有服务器身份被泄露的风险时才会设置 ，例如通过中间人攻击。 4. 启动组复制配置并启动服务器s1后，安装组复制插件。连接到服务器并发出以下命令： 1INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;; mysql.session在加载组复制之前，用户必须存在。 MySQL 8.0.2版中添加了mysql.session。如果使用早期版本初始化数据字典，则必须运行 mysql_upgrade过程。如果未运行升级，则组复制无法以错误消息启动尝试使用用户访问服务器时出现错误：mysql.session@localhost。确保用户在服务器中，并且在服务器更新后运行了mysql_upgrade。 要检查插件是否已成功安装，请发出 SHOW PLUGINS;并检查输出。它应该显示如下： 12345678910mysql&gt; SHOW PLUGINS;+----------------------------+----------+--------------------+----------------------+-------------+| Name | Status | Type | Library | License |+----------------------------+----------+--------------------+----------------------+-------------+| binlog | ACTIVE | STORAGE ENGINE | NULL | PROPRIETARY |(...)| group_replication | ACTIVE | GROUP REPLICATION | group_replication.so | PROPRIETARY |+----------------------------+----------+--------------------+----------------------+-------------+ 要启动该组，请指示服务器s1引导该组，然后启动组复制。此引导程序应仅由单个服务器完成，该服务器启动组并且只执行一次。这就是为什么bootstrap配置选项的值未保存在配置文件中的原因。如果它保存在配置文件中，则在重新启动时，服务器会自动引导具有相同名称的第二个组。这将导致两个具有相同名称的不同组。同样的推理适用于在此选项设置为的情况下停止并重新启动插件ON。 123SET GLOBAL group_replication_bootstrap_group&#x3D;ON;START GROUP_REPLICATION;SET GLOBAL group_replication_bootstrap_group&#x3D;OFF; 一旦START GROUP_REPLICATION 语句返回，该集团已启动。您可以检查该组现在是否已创建，并且其中包含一个成员： 123456mysql&gt; SELECT * FROM performance_schema.replication_group_members;+---------------------------+--------------------------------------+-------------+-------------+---------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+-------------+-------------+---------------+| group_replication_applier | ce9be252-2b71-11e6-b8f4-00212844f856 | myhost | 24801 | ONLINE |+---------------------------+--------------------------------------+-------------+-------------+---------------+ 此表中的信息确认组中有成员具有唯一标识符 ce9be252-2b71-11e6-b8f4-00212844f856，它正在ONLINE并且正在myhost 侦听端口上的客户端连接 24801。 为了证明服务器确实在一个组中并且它能够处理负载，创建一个表并向其添加一些内容。 1234mysql&gt; CREATE DATABASE test;mysql&gt; USE test;mysql&gt; CREATE TABLE t1 (c1 INT PRIMARY KEY, c2 TEXT NOT NULL);mysql&gt; INSERT INTO t1 VALUES (1, &#39;Luis&#39;); 检查表的内容t1和二进制日志。 123456789101112131415161718192021222324252627mysql&gt; SELECT * FROM t1;+----+------+| c1 | c2 |+----+------+| 1 | Luis |+----+------+mysql&gt; SHOW BINLOG EVENTS;+---------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------+| binlog.000001 | 4 | Format_desc | 1 | 123 | Server ver: 8.0.2-gr080-log, Binlog ver: 4 || binlog.000001 | 123 | Previous_gtids | 1 | 150 | || binlog.000001 | 150 | Gtid | 1 | 211 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:1&#39; || binlog.000001 | 211 | Query | 1 | 270 | BEGIN || binlog.000001 | 270 | View_change | 1 | 369 | view_id&#x3D;14724817264259180:1 || binlog.000001 | 369 | Query | 1 | 434 | COMMIT || binlog.000001 | 434 | Gtid | 1 | 495 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:2&#39; || binlog.000001 | 495 | Query | 1 | 585 | CREATE DATABASE test || binlog.000001 | 585 | Gtid | 1 | 646 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:3&#39; || binlog.000001 | 646 | Query | 1 | 770 | use &#96;test&#96;; CREATE TABLE t1 (c1 INT PRIMARY KEY, c2 TEXT NOT NULL) || binlog.000001 | 770 | Gtid | 1 | 831 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:4&#39; || binlog.000001 | 831 | Query | 1 | 899 | BEGIN || binlog.000001 | 899 | Table_map | 1 | 942 | table_id: 108 (test.t1) || binlog.000001 | 942 | Write_rows | 1 | 984 | table_id: 108 flags: STMT_END_F || binlog.000001 | 984 | Xid | 1 | 1011 | COMMIT &#x2F;* xid&#x3D;38 *&#x2F; |+---------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------+ 如上所示，创建了数据库和表对象，并将相应的DDL语句写入二进制日志。此外，数据已插入表中并写入二进制日志。当组成长并且新成员尝试赶上并联机时执行分布式恢复时，下一节将说明二进制日志条目的重要性。 5. 向组添加实例此时，该组中有一个成员服务器s1，其中包含一些数据。现在是时候通过添加先前配置的其他两个服务器来扩展组。 添加第二个实例为了添加第二个实例，服务器s2，首先为它创建配置文件。配置类似于用于服务器s1的配置，除了诸如数据目录的位置，s2将要监听的端口或其之外的配置 server_id。这些不同的行在下面的列表中突出显示。 1234567891011121314151617181920212223242526[mysqld]# server configurationdatadir&#x3D;&lt;full_path_to_data&gt;&#x2F;data&#x2F;s2basedir&#x3D;&lt;full_path_to_bin&gt;&#x2F;mysql-8.0&#x2F;port&#x3D;24802socket&#x3D;&lt;full_path_to_sock_dir&gt;&#x2F;s2.sock## Replication configuration parameters#server_id&#x3D;2gtid_mode&#x3D;ONenforce_gtid_consistency&#x3D;ONbinlog_checksum&#x3D;NONE## Group Replication configuration#transaction_write_set_extraction&#x3D;XXHASH64group_replication_group_name&#x3D;&quot;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa&quot;group_replication_start_on_boot&#x3D;offgroup_replication_local_address&#x3D; &quot;127.0.0.1:24902&quot;group_replication_group_seeds&#x3D; &quot;127.0.0.1:24901,127.0.0.1:24902,127.0.0.1:24903&quot;group_replication_bootstrap_group&#x3D; off 与服务器s1的过程类似，使用选项文件启动服务器。 1mysql-8.0&#x2F;bin&#x2F;mysqld --defaults-file&#x3D;data&#x2F;s2&#x2F;s2.cnf 然后按如下方式配置恢复凭据。这些命令与设置服务器s1时使用的命令相同，因为用户在组内共享。在s2上发布以下语句。 123456SET SQL_LOG_BIN&#x3D;0;CREATE USER rpl_user@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#39;%&#39;;SET SQL_LOG_BIN&#x3D;1;CHANGE MASTER TO MASTER_USER&#x3D;&#39;rpl_user&#39;, MASTER_PASSWORD&#x3D;&#39;password&#39; \\\\ FOR CHANNEL &#39;group_replication_recovery&#39;; 如果您使用的是缓存SHA-2身份验证插件（MySQL 8中的默认设置），请参阅 使用组复制和缓存SHA-2用户凭据插件。 安装组复制插件并开始将服务器加入组的过程。以下示例以与部署服务器s1时相同的方式安装插件。 1mysql&gt; INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;; 将服务器s2添加到组中。 1mysql&gt; START GROUP_REPLICATION; 与之前的步骤（与s1上执行的步骤相同）不同，此处的区别在于， 在启动组复制之前不会发出SET GLOBAL group_replication_bootstrap_group=ON;，因为该组已由服务器s1创建并引导。此时，只需将服务器s2添加到现有组中。 当组复制成功启动并且服务器加入组时，它会检查 super_read_only变量。通过super_read_only 在成员的配置文件中设置为ON，可以确保因任何原因启动组复制时出现故障的服务器不接受事务。如果服务器应将该组作为读写实例加入，例如作为单主组中的主要组或多主组的成员，则当该 super_read_only变量设置为ON时，则在加入时将其设置为OFF群组。 performance_schema.replication_group_members 再次 检查 表显示该组中现在有两个 ONLINE服务器。 1234567mysql&gt; SELECT * FROM performance_schema.replication_group_members;+---------------------------+--------------------------------------+-------------+-------------+---------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+-------------+-------------+---------------+| group_replication_applier | 395409e1-6dfa-11e6-970b-00212844f856 | myhost | 24801 | ONLINE || group_replication_applier | ac39f1e6-6dfa-11e6-a69d-00212844f856 | myhost | 24802 | ONLINE |+---------------------------+--------------------------------------+-------------+-------------+---------------+ 由于服务器s2也标记为ONLINE，它必须已经自动赶上服务器s1。验证它确实已与服务器s1同步，如下所示。 1234567891011121314151617181920212223242526272829303132333435363738mysql&gt; SHOW DATABASES LIKE &#39;test&#39;;+-----------------+| Database (test) |+-----------------+| test |+-----------------+mysql&gt; SELECT * FROM test.t1;+----+------+| c1 | c2 |+----+------+| 1 | Luis |+----+------+mysql&gt; SHOW BINLOG EVENTS;+---------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+| binlog.000001 | 4 | Format_desc | 2 | 123 | Server ver: 8.0.3-log, Binlog ver: 4 || binlog.000001 | 123 | Previous_gtids | 2 | 150 | || binlog.000001 | 150 | Gtid | 1 | 211 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:1&#39; || binlog.000001 | 211 | Query | 1 | 270 | BEGIN || binlog.000001 | 270 | View_change | 1 | 369 | view_id&#x3D;14724832985483517:1 || binlog.000001 | 369 | Query | 1 | 434 | COMMIT || binlog.000001 | 434 | Gtid | 1 | 495 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:2&#39; || binlog.000001 | 495 | Query | 1 | 585 | CREATE DATABASE test || binlog.000001 | 585 | Gtid | 1 | 646 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:3&#39; || binlog.000001 | 646 | Query | 1 | 770 | use &#96;test&#96;; CREATE TABLE t1 (c1 INT PRIMARY KEY, c2 TEXT NOT NULL) || binlog.000001 | 770 | Gtid | 1 | 831 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:4&#39; || binlog.000001 | 831 | Query | 1 | 890 | BEGIN || binlog.000001 | 890 | Table_map | 1 | 933 | table_id: 108 (test.t1) || binlog.000001 | 933 | Write_rows | 1 | 975 | table_id: 108 flags: STMT_END_F || binlog.000001 | 975 | Xid | 1 | 1002 | COMMIT &#x2F;* xid&#x3D;30 *&#x2F; || binlog.000001 | 1002 | Gtid | 1 | 1063 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:5&#39; || binlog.000001 | 1063 | Query | 1 | 1122 | BEGIN || binlog.000001 | 1122 | View_change | 1 | 1261 | view_id&#x3D;14724832985483517:2 || binlog.000001 | 1261 | Query | 1 | 1326 | COMMIT |+---------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+ 如上所示，第二台服务器已添加到组中，并自动从服务器s1复制了更改。根据分布式恢复过程，这意味着在加入组之后并且在被声明在线之前，服务器s2已经自动连接到服务器s1并从中获取丢失的数据。换句话说，它将事务从缺少的s1的二进制日志复制到它加入组的时间点。 添加其他实例向组添加其他实例与添加第二个服务器的步骤顺序基本相同，只是必须更改配置，因为必须更改服务器s2。总结所需的命令： 创建配置文件 12345678910111213141516171819202122232425[mysqld]# server configurationdatadir&#x3D;&lt;full_path_to_data&gt;&#x2F;data&#x2F;s3basedir&#x3D;&lt;full_path_to_bin&gt;&#x2F;mysql-8.0&#x2F;port&#x3D;24803socket&#x3D;&lt;full_path_to_sock_dir&gt;&#x2F;s3.sock## Replication configuration parameters#server_id&#x3D;3gtid_mode&#x3D;ONenforce_gtid_consistency&#x3D;ONbinlog_checksum&#x3D;NONE## Group Replication configuration#group_replication_group_name&#x3D;&quot;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa&quot;group_replication_start_on_boot&#x3D;offgroup_replication_local_address&#x3D; &quot;127.0.0.1:24903&quot;group_replication_group_seeds&#x3D; &quot;127.0.0.1:24901,127.0.0.1:24902,127.0.0.1:24903&quot;group_replication_bootstrap_group&#x3D; off 启动服务器 1mysql-8.0&#x2F;bin&#x2F;mysqld --defaults-file&#x3D;data&#x2F;s3&#x2F;s3.cnf 配置group_replication_recovery通道的恢复凭据。 1234567SET SQL_LOG_BIN&#x3D;0;CREATE USER rpl_user@&#39;%&#39; IDENTIFIED BY &#39;password&#39;;GRANT REPLICATION SLAVE ON *.* TO rpl_user@&#39;%&#39;;FLUSH PRIVILEGES;SET SQL_LOG_BIN&#x3D;1;CHANGE MASTER TO MASTER_USER&#x3D;&#39;rpl_user&#39;, MASTER_PASSWORD&#x3D;&#39;password&#39; \\\\FOR CHANNEL &#39;group_replication_recovery&#39;; 安装Group Replication插件并启动它。 12INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;;START GROUP_REPLICATION; 此时，服务器s3已启动并正在运行，已加入该组并赶上该组中的其他服务器。performance_schema.replication_group_members 再次咨询 表证实了这种情况。 12345678mysql&gt; SELECT * FROM performance_schema.replication_group_members;+---------------------------+--------------------------------------+-------------+-------------+---------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+-------------+-------------+---------------+| group_replication_applier | 395409e1-6dfa-11e6-970b-00212844f856 | myhost | 24801 | ONLINE || group_replication_applier | 7eb217ff-6df3-11e6-966c-00212844f856 | myhost | 24803 | ONLINE || group_replication_applier | ac39f1e6-6dfa-11e6-a69d-00212844f856 | myhost | 24802 | ONLINE |+---------------------------+--------------------------------------+-------------+-------------+---------------+ 在服务器s2或服务器s1上发出相同的查询会产生相同的结果。此外，您可以验证服务器s3是否也赶上了： 123456789101112131415161718192021222324252627282930313233343536373839404142mysql&gt; SHOW DATABASES LIKE &#39;test&#39;;+-----------------+| Database (test) |+-----------------+| test |+-----------------+mysql&gt; SELECT * FROM test.t1;+----+------+| c1 | c2 |+----+------+| 1 | Luis |+----+------+mysql&gt; SHOW BINLOG EVENTS;+---------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+| binlog.000001 | 4 | Format_desc | 3 | 123 | Server ver: 8.0.3-log, Binlog ver: 4 || binlog.000001 | 123 | Previous_gtids | 3 | 150 | || binlog.000001 | 150 | Gtid | 1 | 211 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:1&#39; || binlog.000001 | 211 | Query | 1 | 270 | BEGIN || binlog.000001 | 270 | View_change | 1 | 369 | view_id&#x3D;14724832985483517:1 || binlog.000001 | 369 | Query | 1 | 434 | COMMIT || binlog.000001 | 434 | Gtid | 1 | 495 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:2&#39; || binlog.000001 | 495 | Query | 1 | 585 | CREATE DATABASE test || binlog.000001 | 585 | Gtid | 1 | 646 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:3&#39; || binlog.000001 | 646 | Query | 1 | 770 | use &#96;test&#96;; CREATE TABLE t1 (c1 INT PRIMARY KEY, c2 TEXT NOT NULL) || binlog.000001 | 770 | Gtid | 1 | 831 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:4&#39; || binlog.000001 | 831 | Query | 1 | 890 | BEGIN || binlog.000001 | 890 | Table_map | 1 | 933 | table_id: 108 (test.t1) || binlog.000001 | 933 | Write_rows | 1 | 975 | table_id: 108 flags: STMT_END_F || binlog.000001 | 975 | Xid | 1 | 1002 | COMMIT &#x2F;* xid&#x3D;29 *&#x2F; || binlog.000001 | 1002 | Gtid | 1 | 1063 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:5&#39; || binlog.000001 | 1063 | Query | 1 | 1122 | BEGIN || binlog.000001 | 1122 | View_change | 1 | 1261 | view_id&#x3D;14724832985483517:2 || binlog.000001 | 1261 | Query | 1 | 1326 | COMMIT || binlog.000001 | 1326 | Gtid | 1 | 1387 | SET @@SESSION.GTID_NEXT&#x3D; &#39;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:6&#39; || binlog.000001 | 1387 | Query | 1 | 1446 | BEGIN || binlog.000001 | 1446 | View_change | 1 | 1585 | view_id&#x3D;14724832985483517:3 || binlog.000001 | 1585 | Query | 1 | 1650 | COMMIT |+---------------+------+----------------+-----------+-------------+--------------------------------------------------------------------+","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"使用 Powerline 美化终端","slug":"powerline","date":"2019-01-28T16:00:00.000Z","updated":"2020-12-04T12:21:57.181Z","comments":true,"path":"2019/01/29/powerline/","link":"","permalink":"http://yoursite.com/2019/01/29/powerline/","excerpt":"使用 Powerline 美化终端","text":"使用 Powerline 美化终端 安装 python3Ubuntu 1[root@ubuntu ~]# sudo apt install python3 python3-pip 安装 powerline1234567891011[root@ubuntu ~]# python3 -m pip install powerline-status[root@ubuntu ~]# python3 -m pip show powerline-statusName: powerline-statusVersion: 2.7Summary: The ultimate statusline&#x2F;prompt utility.Home-page: https:&#x2F;&#x2F;github.com&#x2F;powerline&#x2F;powerlineAuthor: Kim SilkebaekkenAuthor-email: kim.silkebaekken+vim@gmail.comLicense: MITLocation: &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packagesRequires: 设置 bash1[root@ubuntu ~]# vim ~/.bashrc 1234powerline-daemon -qPOWERLINE_BASH_CONTINUATION&#x3D;1POWERLINE_BASH_SELECT&#x3D;1. &#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;powerline&#x2F;bindings&#x2F;bash&#x2F;powerline.sh 效果图 设置 vim1[root@ubuntu ~]# vim ~/.vimrc 123set rtp+&#x3D;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.6&#x2F;dist-packages&#x2F;powerline&#x2F;bindings&#x2F;vim&#x2F;set laststatus&#x3D;2set t_Co&#x3D;256 效果图","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"MySQL 常用函数","slug":"mysql_function","date":"2019-01-14T16:00:00.000Z","updated":"2020-12-04T11:24:29.138Z","comments":true,"path":"2019/01/15/mysql_function/","link":"","permalink":"http://yoursite.com/2019/01/15/mysql_function/","excerpt":"MySQL 常用函数","text":"MySQL 常用函数 文本处理函数 函数名 说明 left( ) 返回串左边的字符 right( ) 返回串右边的字符 length( ) 返回串的长度 locate( ) 找出串的一个子串 lower( ) 将串转换为小写 upper( ) 将串转换为大写 ltrim( ) 去掉串左边的空格 rtrim( ) 去掉串右边的空格 soundex( ) 返回串的SOUNDEX值 substring( ) 返回子串的字符 ## 日期和时间处理函数 函数名 说明 adddate( ) 增加一个日期（天、周等） addtime( ) 增加一个时间（时、分等） curdate( ) 返回当前日期 curtime( ) 返回当前时间 date( ) 返回日期时间的日期部分 datediff( ) 计算两个日期之差 date_add( ) 高度灵活的日期运算函数 date_format( ) 返回一个格式化的日期或时间串 day( ) 返回一个日期的天数部分 dayofweek( ) 对于一个日期，返回对应的星期几 hour( ) 返回一个时间的小时部分 minute( ) 返回一个时间的分钟部分 month( ) 返回一个日期的月份部分 now( ) 返回当前日期和时间 second( ) 返回一个时间的秒部分 time( ) 返回一个日期时间的时间部分 year( ) 返回一个日期的年份部分 数值处理函数 函数名 说明 abs( ) 返回一个数的绝对值 cos( ) 返回一个角度的余弦 exp( ) 返回一个数的指数值 mod( ) 返回除操作的余数 pi( ) 返回圆周率 rand( ) 返回一个随机数 sin( ) 返回一个角度的正弦 sqrt( ) 返回一个数的平方根 tan( ) 返回一个角度的正切 聚集函数 函数名 说明 avg( ) 返回某列的平均值 count( ) 返回某列的行数 max( ) 返回某列的最大值 min( ) 返回某列的最小值 sum( ) 返回某列值之和","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"uWSGI 部署 Django 应用","slug":"uwsgi","date":"2019-01-06T16:00:00.000Z","updated":"2020-12-04T11:24:29.145Z","comments":true,"path":"2019/01/07/uwsgi/","link":"","permalink":"http://yoursite.com/2019/01/07/uwsgi/","excerpt":"uWSGI 部署 Django 应用","text":"uWSGI 部署 Django 应用 准备项目代码123mkdir -p /appdata/uwsgicd /appdata/uwsgi# 将项目代码放置此处 安装相关工具和依赖12[root@uwsgi ~]# yum -y install git wget httpd vim # 安装相关工具[root@uwsgi ~]# yum -y install gcc zlib* openssl-devel # 安装编译工具和依赖库 编译安装 Python 环境rhel系列无法通过yum直接安装python3，需要源码编译安装 123456789101112[root@uwsgi ~]# pwd # 查看当前目录/root[root@uwsgi ~]# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz # 下载python3.6.5[root@uwsgi ~]# tar -zxvf Python-3.6.5.tgz # 解压[root@uwsgi ~]# cd Python-3.6.5[root@uwsgi Python-3.6.5]# pwd # 查看当前目录/root/Python-3.6.5[root@uwsgi Python-3.6.5]# ./configure # 编译[root@uwsgi Python-3.6.5]# make &amp;&amp; make install # 安装[root@uwsgi Python-3.6.5]# which python3 # 查看python3的路径/usr/local/bin/python3 使用 epel 源 Python 环境1234[root@uwsgi ~]# yum -y install epel-release[root@uwsgi ~]# yum makecache[root@uwsgi ~]# yum -y install python3 python3-devel` 出现以下报错为缺少 python3-devel * uWSGI compiling embedded plugins * [gcc -pthread] plugins/python/python_plugin.o In file included from plugins/python/python_plugin.c:1:0: plugins/python/uwsgi_python.h:2:20: 致命错误：Python.h：没有那个文件或目录 #include &lt;Python.h&gt; 安装 uWSGI1[root@uwsgi ~]# python3 -m pip install uwsgi 安装配置虚拟环境1234567[root@uwsgi ~]# python3 -m pip install virtualenv # 安装虚拟环境[root@uwsgi ~]# python3 -m virtualenv /appdata/uwsgi/venv # 配置虚拟环境[root@uwsgi ~]# source /venv/bin/activate # 激活虚拟环境(venv) [root@uwsgi ~]# pip install -r /appdata/planner/requirements.txt # 安装项目依赖(venv) [root@uwsgi ~]# pip freeze # 查看依赖库是否安装(venv) [root@uwsgi ~]# deactivate # 取消激活虚拟环境[root@uwsgi ~]# 修改 ALLOW_HOSTS1[root@uwsgi ~]# vim /appdata/planner/planner/settings.py # 编辑项目中的 settings.py 1ALLOWED_HOSTS = [\"*\"] 配置 uWSGI12[root@uwsgi ~]# mkdir -p /applog/uwsgi/ # 创建 uwsgi 的日志目录[root@uwsgi ~]# vim /etc/uwsgi/planner.ini # 创建 uwsgi.ini 配置文件 123456789101112131415[uwsgi]# 项目目录chdir=/appdata/uwsgi/plannerhttp=192.168.33.11:8000# 虚拟环境目录home=/appdata/uwsgi/venvmodule=planner.wsgi:applicationmaster=Truepidfile=/applog/uwsgi/planner.piddaemonize=/applog/uwsgi/planner.logsocket=/applog/uwsgi/planner.sockmax-requests=5000env=LANG=en_US.UTF-8buffer-size=32768logformat=&#123;\"uri\": \"%(uri)\", \"method\": \"%(method)\", \"user\": \"%(user)\", \"addr\": \"%(addr)\", \"host\": \"%(host)\", \"proto\": \"%(proto)\", \"uagent\": \"%(uagent)\", \"referer\": \"%(referer)\", \"status\": \"%(status)\", \"micros\": \"%(micros)\", \"msecs\": \"%(msecs)\", \"time\": \"%(time)\", \"ctime\": \"%(ctime)\", \"epoch\": \"%(epoch)\", \"size\": \"%(size)\", \"ltime\": \"%(ltime)\", \"hsize\": \"%(hsize)\", \"rsize\": \"%(rsize)\", \"cl\": \"%(cl)\", \"pid\": \"%(pid)\", \"wid\": \"%(wid)\", \"switches\": \"%(switches)\", \"vars\": \"%(vars)\", \"headers\": \"%(headers)\", \"core\": \"%(core)\", \"vsz\": \"%(vsz)\", \"rss\": \"%(rss)\", \"vszM\": \"%(vszM)\", \"rssM\": \"%(rssM)\", \"pktsize\": \"%(pktsize)\", \"modifier1\": \"%(modifier1)\", \"modifier2\": \"%(modifier2)\", \"metric\": \"%(metric.XXX)\", \"rerr\": \"%(rerr)\", \"werr\": \"%(werr)\", \"ioerr\": \"%(ioerr)\", \"tmsecs\": \"%(tmsecs)\", \"tmicros\": \"%(tmicros)\"&#125; 启动 uWSGI123456# 以 /etc/uwsgi.ini 配置启动 uwsgi[root@uwsgi ~]# uwsgi --init /etc/uwsgi.ini# 查看端口是否监听[root@uwsgi ~]# netstat -ntlp | grep uwsgitcp 0 0 192.168.33.11:8000 0.0.0.0:* LISTEN 13162/uwsgi 配置 Nginx12345678910111213141516171819202122232425# 安装 nginx[root@uwsgi ~]# yum -y install epel-release[root@uwsgi ~]# yum -y install nginx# 创建配置文件[root@uwsgi ~]# cat &lt;&lt; EOF &gt; /etc/nginx/conf.d/planner.confserver &#123; listen 80; server_name 192.168.33.11; charset utf-8; location /static &#123; alias /appdata/uwsgi/planner/static/; &#125; location /media &#123; alias /appdata/uwsgi/planner/media/; &#125; location /&#123; include /etc/nginx/uwsgi_params; uwsgi_pass unix:/applog/uwsgi/planner.sock; &#125;&#125;EOF# 检查文件是否合法[root@uwsgi ~]# nginx -t# 刷新配置文件[root@uwsgi ~]# nginx -s reload 现在就可以使用 http:// 访问 Django 应用了 注意事项未安装zlib*： 1zipimport.ZipImportError: can&#39;t decompress data; zlib not available # 编译时报错 未安装openssl、openssl-devel： 1pip is configured with locations that require TLS&#x2F;SSL, however the ssl module in Python is not available # pip 安装 uwsgi 时报错 uwsgi 无法访问，日志报错： 1invalid request block size: 21573 (max 4096)...skip # 在 &#x2F;etc&#x2F;uwsgi.ini 中添加 buffer-size&#x3D;32768","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"使用 oh-my-posh 美化 PowerShell","slug":"oh-my-posh","date":"2019-01-04T16:00:00.000Z","updated":"2020-12-04T11:24:29.139Z","comments":true,"path":"2019/01/05/oh-my-posh/","link":"","permalink":"http://yoursite.com/2019/01/05/oh-my-posh/","excerpt":"使用 oh-my-posh 美化 PowerShell","text":"使用 oh-my-posh 美化 PowerShell 英文字体是支持PowerLine的DejaVuSansMono字体，中文字体是文泉驿等宽微米黑字体），并将终端字体设置为支持PowerLine的字体。然后开始安装oh-my-posh（该步骤可能需要某种“较为稳定”的网络环境）。在管理员权限的PowerShell下执行指令 1Set-ExecutionPolicy Bypass 该指令旨在允许加载并运行任意脚本。可能会造成安全问题，但是只要有杀毒软件在就无需担心，毕竟没有人会无聊到对一个普通的计算机用户进行针对性攻击。 然后安装oh-my-posh的依赖和oh-my-posh本身 12Install-Module posh-git -Scope CurrentUserInstall-Module oh-my-posh -Scope CurrentUser 安装完成之后，可以通过 1Import-Module oh-my-posh 来尝试启用这个模组。之后就可以使用 1Set-Theme主题名 这种格式的指令来切换不同的显示风格。示例图中的主题是基于Agnoster改造的，默认主题文件位于 IT之家学院：使用oh-my-posh美化Win10 PowerShell 接下来便是在PowerShell启动时加载这个模组了。类似于Linux Bash的.bashrc，PowerShell也提供类似的Profile文件用于在启动时执行指令。输入 1Test-Path $profile 并执行，以确定profile文件是否存在。如果返回False，则应该执行： 1New-Item -path $profile -type file–force 来新建一个文件。然后去往Profile的目录（通常是你的文档下的WindowsPowerShell目录下），修改那个后缀为ps1的Profile文件，加入一行Import-Module oh-my-posh即可。 一切完成之后，PowerShell应该比原先美观了不少，而且提示符的功能更强了。基于oh-my-posh框架，还能自己编写更多的主题。","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"windows","slug":"windows","permalink":"http://yoursite.com/tags/windows/"},{"name":"powershell","slug":"powershell","permalink":"http://yoursite.com/tags/powershell/"}]},{"title":"gitlab-ce 安装指南","slug":"gitlab","date":"2019-01-02T16:00:00.000Z","updated":"2020-12-04T11:24:29.129Z","comments":true,"path":"2019/01/03/gitlab/","link":"","permalink":"http://yoursite.com/2019/01/03/gitlab/","excerpt":"gitlab 安装使用指南","text":"gitlab 安装使用指南 更新软件包1yum update -y 配置防火墙1[root@gitlab ~]# vim /etc/sysctl.conf 1net.ipv4.ip_forward &#x3D; 1 启用并启动防火墙 12[root@gitlab ~]# systemctl enable firewalld[root@gitlab ~]# systemctl start firewalld 放通 HTTP、HTTPS 12[root@gitlab ~]# firewall-cmd --add-service=http --permanent[root@gitlab ~]# firewall-cmd --add-service=https --permanent 重载入防火墙 1[root@gitlab ~]# systemctl reload firewalld 安装 postfixGitLab 需要使用 postfix 来发送邮件。当然，也可以使用 SMTP 服务器 1[root@gitlab ~]# vim /etc/postfix/main.cf 12# inet_protocols &#x3D; allinet_protocols &#x3D; ipv4 启用并启动 postfix 1[root@gitlab ~]# systemctl restart postfix 配置 swap由于 GitLab 较为消耗资源，我们需要先创建交换分区，以降低物理内存的压力。在实际生产环境中，如果服务器配置够高，则不必配置交换分区。 新建 2 GB 大小的交换分区 1[root@gitlab ~]# dd if=/dev/zero of=/root/swapfile bs=1M count=2048 格式化为交换分区文件并启用 12[root@gitlab ~]# mkswap /root/swapfile[root@gitlab ~]# swapon /root/swapfile 添加自启用 1[root@gitlab ~]# vim /etc/fstab 1&#x2F;root&#x2F;swapfile swap swap defaults 0 0 安装 GitLab 将软件源修改为国内源 1[root@gitlab ~]# vim /etc/yum.repos.d/gitlab-ce.repo 12345[gitlab-ce]name&#x3D;Gitlab CE Repositorybaseurl&#x3D;https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;gitlab-ce&#x2F;yum&#x2F;el$releasever&#x2F;gpgcheck&#x3D;0enabled&#x3D;1 安装 GitLab 12[root@gitlab ~]# yum makecache[root@gitlab ~]# yum install -y gitlab-ce 12345678910111213141516171819202122 *. *. *** *** ***** ***** .****** ******* ******** ******** ,,,,,,,,,***********,,,,,,,,,,,,,,,,,,,,*********,,,,,,,,,,,.,,,,,,,,,,,*******,,,,,,,,,,,, ,,,,,,,,,*****,,,,,,,,,. ,,,,,,,****,,,,,, .,,,***,,,, ,*,. _______ __ __ __ &#x2F; ____(_) &#x2F;_&#x2F; &#x2F; ____ _&#x2F; &#x2F;_ &#x2F; &#x2F; __&#x2F; &#x2F; __&#x2F; &#x2F; &#x2F; __ &#96;&#x2F; __ \\&#x2F; &#x2F;_&#x2F; &#x2F; &#x2F; &#x2F;_&#x2F; &#x2F;___&#x2F; &#x2F;_&#x2F; &#x2F; &#x2F;_&#x2F; &#x2F;\\____&#x2F;_&#x2F;\\__&#x2F;_____&#x2F;\\__,_&#x2F;_.___&#x2F;Thank you for installing GitLab! 配置 HTTPS 证书 生成 key 文件 1[root@gitlab ~]# openssl genrsa -out \"/etc/gitlab/ssl/gitlab.example.com.key\" 输出： 1234Generating RSA private key, 2048 bit long modulus.........................................................................................................+++..............................................................+++e is 65537 (0x10001) 生成 csr 文件 1[root@gitlab ssl]# openssl req -new -key \"/etc/gitlab/ssl/gitlab.example.com.key\" -out \"/etc/gitlab/ssl/gitlab.example.com.csr\" 输出： 12345678910111213141516171819You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#39;.&#39;, the field will be left blank.-----Country Name (2 letter code) [XX]:cnState or Province Name (full name) []:szLocality Name (eg, city) [Default City]:szOrganization Name (eg, company) [Default Company Ltd]:exampleOrganizational Unit Name (eg, section) []:Common Name (eg, your name or your server&#39;s hostname) []:gitlab.example.comEmail Address []:admin@example.comPlease enter the following &#39;extra&#39; attributesto be sent with your certificate requestA challenge password []:passwordAn optional company name []: 生成 crt 文件 1[root@gitlab ~]# openssl x509 -req -days 365 -in \"/etc/gitlab/ssl/gitlab.example.com.csr\" -signkey \"/etc/gitlab/ssl/gitlab.example.com.key\" -out \"/etc/gitlab/ssl/gitlab.example.com.crt\" 输出： 123Signature oksubject&#x3D;&#x2F;C&#x3D;cn&#x2F;ST&#x3D;sz&#x2F;L&#x3D;sz&#x2F;O&#x3D;example&#x2F;CN&#x3D;gitlab.example.com&#x2F;emailAddress&#x3D;admin@example.comGetting Private key 生成 dhparams.pem 1[root@gitlab ssl]# openssl dhparam -out /etc/gitlab/ssl/dhparams.pem 2048 初始化 GitLab 配置 GitLab 1[root@gitlab ~]# vim /etc/gitlab/gitlab.rb 12345external_url &#39;http:&#x2F;&#x2F;gitlab.example.com&#39;nginx[&#39;redirect_http_to_https&#39;] &#x3D; truenginx[&#39;ssl_certificate&#39;] &#x3D; &quot;&#x2F;etc&#x2F;gitlab&#x2F;ssl&#x2F;gitlab.example.com.crt&quot;nginx[&#39;ssl_certificate_key&#39;] &#x3D; &quot;&#x2F;etc&#x2F;gitlab&#x2F;ssl&#x2F;gitlab.example.com.key&quot;nginx[&#39;ssl_dhparam&#39;] &#x3D; &quot;&#x2F;etc&#x2F;gitlab&#x2F;ssl&#x2F;dhparams.pem&quot; 初始化 GitLab 1[root@gitlab ~]# gitlab-ctl reconfigure 修改 nginx 配置 1[root@gitlab ~]# vim /var/opt/gitlab/nginx/conf/gitlab-http.conf 12345678910111213141516server &#123; listen *:80; rewrite ^(.*)$ https:&#x2F;&#x2F;$host$1 permanent; # 新增 server_name gitlab.example.com; server_tokens off; ## Don&#39;t show the nginx version number, a security best practice location &#x2F; &#123; return 301 https:&#x2F;&#x2F;gitlab.example.com:443$request_uri; &#125; access_log &#x2F;var&#x2F;log&#x2F;gitlab&#x2F;nginx&#x2F;gitlab_access.log gitlab_access; error_log &#x2F;var&#x2F;log&#x2F;gitlab&#x2F;nginx&#x2F;gitlab_error.log;&#125; 重启 gitlab 1[root@gitlab ~]# gitlab-ctl restart","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"}]},{"title":"使用 Ambari 部署 Hadoop 集群","slug":"ambari","date":"2018-12-17T16:00:00.000Z","updated":"2020-12-04T12:11:41.707Z","comments":true,"path":"2018/12/18/ambari/","link":"","permalink":"http://yoursite.com/2018/12/18/ambari/","excerpt":"使用 Ambari 部署 Hadoop 集群","text":"使用 Ambari 部署 Hadoop 集群 配置本地yum源安装httpd1yum install httpd -y 在官方下载镜像文件123456wget http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.1.0/ambari.repowget http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.4.0/hdp.repowget http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.1.0/ambari-2.6.1.0-centos7.tar.gzwget http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7/HDP-UTILS-1.1.0.22-centos7.tar.gzwget http://public-repo-1.hortonworks.com/HDP-GPL/centos7/2.x/updates/2.6.4.0/HDP-GPL-2.6.4.0-centos7-rpm.tar.gzwget http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.4.0/HDP-2.6.4.0-centos7-rpm.tar.gz 将对应的tar包解压到httpd的文件目录12345cd /var/www/htmltar -zxvf ambari-2.6.1.0-centos7.tar.gztar -zxvf HDP-2.6.4.0-centos7-rpm.tar.gz tar -zxvf HDP-GPL-2.6.4.0-centos7-rpm.tar.gz tar -zxvf HDP-UTILS-1.1.0.22-centos7.tar.gz 配置基础源，创建hadoop的repo文件12# ambari 源vim /etc/yum.repo.d/ambari.repo 1234567[ambari-2.6.1.0]name&#x3D;ambari Version - ambari-2.6.1.0baseurl&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;ambari&#x2F;centos7&#x2F;2.6.1.0-143gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;ambari&#x2F;centos7&#x2F;2.6.1.0-143&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1 12# hadoop源vim /etc/yum.repo.d/hdp.repo 123456789101112131415161718192021222324#VERSION_NUMBER&#x3D;2.6.4.0-91[HDP-2.6.4.0]name&#x3D;HDP Version - HDP-2.6.4.0baseurl&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;HDP&#x2F;centos7&#x2F;2.6.4.0-91gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;HDP&#x2F;centos7&#x2F;2.6.4.0-91&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1[HDP-UTILS-1.1.0.22]name&#x3D;HDP-UTILS Version - HDP-UTILS-1.1.0.22baseurl&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;HDP-UTILS&#x2F;centos7&#x2F;1.1.0.22&#x2F;gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;HDP-UTILS&#x2F;centos7&#x2F;1.1.0.22&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1[HDP-GPL-2.6.4.0]name&#x3D;HDP-GPL Version - HDP-GPL-2.6.4.0baseurl&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;HDP-GPL&#x2F;centos7&#x2F;2.6.4.0-91gpgcheck&#x3D;1gpgkey&#x3D;http:&#x2F;&#x2F;192.168.10.11&#x2F;HDP-GPL&#x2F;centos7&#x2F;2.6.4.0-91&#x2F;RPM-GPG-KEY&#x2F;RPM-GPG-KEY-Jenkinsenabled&#x3D;1priority&#x3D;1 启动httpd12systemctl enable httpdsystemctl start httpd 将本地源的repo配置拷贝到其它节点，并创建缓存123scp /etc/yum.repos.d/ambari.repo 192.168.135.4:/etc/yum.repos.d/scp /etc/yum.repos.d/ambari.repo 192.168.135.5:/etc/yum.repos.d/scp /etc/yum.repos.d/hdp.repo 192.168.135.6:/etc/yum.repos.d/ 在各个节点创建缓存： 12yum clean allyum makecache fast 初始化环境各个节点安装java-1.8.0-openjdk1yum install java-1.8.0-openjdk -y 解析主机名123echo \"192.168.135.4 node2\" &gt;&gt; /etc/hostsecho \"192.168.135.5 node3\" &gt;&gt; /etc/hostsecho \"192.168.135.6 node4\" &gt;&gt; /etc/hosts 创建主机信任关系1234ssh-keygenssh-copy-id node-1ssh-copy-id node-2ssh-copy-id node-3 安装配置数据库123yum install mariadb-server -ysystemctl enable mariadbsystemctl start mariadb 创建数据库1mysql 123456789set password=password('123456');grant all on *.* to root@localhost identified by '123456';grant all on *.* to root@'%' identified by '123456';create database ambari default character set utf8;grant all on ambari.* to ambari@localhost identified by 'bigdata';grant all on ambari.* to ambari@'%' identified by 'bigdata';create database hive default character set utf8;grant all on hive.* to hive@localhost identified by 'hive';grant all on hive.* to hive@'%' identified by 'hive'; 安装Amabri服务在node-1上安装ambari-server,并启动配置向导12yum install ambari-server -yambari-server setup 按照配置向导信息、配置用户、java_home123456789101112131415161718192021222324252627282930313233343536373839404142434445ambari-server setupUsing python /usr/bin/pythonSetup ambari-serverChecking SELinux...SELinux status is 'disabled'Customize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):ambari Adjusting ambari-server permissions and ownership...Checking firewall status...Checking JDK...[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7[3] Custom JDK==============================================================================Enter choice (1): 3WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.Path to JAVA_HOME: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-0.b14.el7_4.x86_64/jre # 填写java_homeValidating JDK on Ambari Server...done.Checking GPL software agreement...GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.htmlEnable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? nCompleting setup...Configuring database...Enter advanced database configuration [y/n] (n)? y Configuring database...==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle[3] - MySQL / MariaDB[4] - PostgreSQL[5] - Microsoft SQL Server (Tech Preview)[6] - SQL Anywhere[7] - BDB==============================================================================Enter choice (1): 3Hostname (localhost): Port (3306): Database name (ambari): Username (ambari): Enter Database Password (bigdata): Configuring ambari database...WARNING: Before starting Ambari Server, you must copy the MySQL JDBC driver JAR file to /usr/share/java and set property \"server.jdbc.driver.path=[path/to/custom_jdbc_driver]\" in ambari.properties.Press &lt;enter&gt; to continue. 到上面一步时，根据提示上传mysql的jdbc驱动，并修改配置文件，指定jdbc驱动文件位置：123456cd /usr/share/javalltar xf mysql-connector-java-5.1.45.tar.gz mv mysql-connector-java-5.1.45/mysql-connector-java-5.1.45-bin.jar ./# 修改配置文件：vim /etc/ambari-server/conf/ambari.properties 1server.jdbc.driver.path&#x3D;&#x2F;usr&#x2F;share&#x2F;java&#x2F;mysql-connector-java-5.1.45-bin.jar 配置完成后继续，会出现如下提示： Press to continue.Configuring remote database connection properties…WARNING: Before starting Ambari Server, you must run the following DDL against the database to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sqlProceed with configuring remote database connection properties [y/n] (y)? 出现上述提示时，根据信息导入数据库1mysql -uroot -p ambari &lt; &#x2F;var&#x2F;lib&#x2F;ambari-server&#x2F;resources&#x2F;Ambari-DDL-MySQL-CREATE.sql 启动服务1ambari-server start","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"}]},{"title":"Ansible 自动化运维实战","slug":"ansible","date":"2018-12-16T16:00:00.000Z","updated":"2020-12-04T12:25:54.242Z","comments":true,"path":"2018/12/17/ansible/","link":"","permalink":"http://yoursite.com/2018/12/17/ansible/","excerpt":"Ansible 自动化运维实战","text":"Ansible 自动化运维实战 Ad-Hoc命令简介并行和Shell命令让我们使用Ansible的命令行工具重启atlanta的所有Web服务器，一次10个。首先，让我们设置SSH代理，以便它能记住我们的凭据： 12ssh-agent bashssh-add ~/.ssh/id_rsa playbook 1234567[nginx]name&#x3D;nginx repobaseurl&#x3D;http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;OS&#x2F;OSRELEASE&#x2F;$basearch&#x2F;gpgcheck&#x3D;0enabled&#x3D;1","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Arch Linux 入坑指南","slug":"archlinux_install","date":"2018-12-15T16:00:00.000Z","updated":"2020-12-04T12:11:58.461Z","comments":true,"path":"2018/12/16/archlinux_install/","link":"","permalink":"http://yoursite.com/2018/12/16/archlinux_install/","excerpt":"Arch Linux 安装指南","text":"Arch Linux 安装指南 系统安装连接网络1wifi-menu 磁盘分区123456fdisk -lfdisk /dev/sda# 1. 先将硬盘格式转换为 GPT# 2. 创建 sda1 EFI 分区 200M# 3. 创建 ada2 boot 分区 1G# 4. 剩下的 sda3 Linux LVM 分区 1234# 格式化三个分区mkfs.vfat -F32 /dev/sda1mkfs.ext4 /dev/sda2mkfs.xfs /dev/sda3 查看硬盘的分区情况1lsblk -l 创建并挂载目录12345678# 一定要先挂载 /mntmount /dev/sda3 /mnt# 创建 boot 文件夹并挂载mkdir /mnt/bootmount /dev/sda2 /mnt/boot# 创建 efi 文件夹并挂载mkdir /mnt/boot/efimount /dev/sda1 /mnt/boot/efi 安装基本系统1pacstrap &#x2F;mnt base 生成 fstab1genfstab -U &#x2F;mnt &gt;&gt; &#x2F;mnt&#x2F;etc&#x2F;fstab Change root 到新安装的系统12arch-chroot &#x2F;mntpacman -S vim net-tools Locale12# 编辑地区信息生成文件vim /etc/locale.gen 1234# 生成地区信息locale-gen# 写进配置文件echo LANG=zh_CN.UTF-8 &gt; /etc/locale.conf 设置时区12ln -S &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtimehwclock --localtime 主机名12echo myhostname &gt; &#x2F;etc&#x2F;hostnamevim &#x2F;etc&#x2F;hosts Root 密码1passwd 安装 GRUB1234pacman -S grub-efi-x86_64pacman -S efibootmgrgrub-install --efi-directory=/boot/efi --bootloader-id=arch --recheckgrub-mkconfig -o /boot/grub/grub.cfg 重启12345exitumount &#x2F;mnt&#x2F;boot&#x2F;efiumount &#x2F;mnt&#x2F;bootumount &#x2F;mntreboot 安装图形化界面设置 archlinux 源1vim &#x2F;etc&#x2F;pacman.d&#x2F;mirrorlist 更新源并且安装yaourt:1pacman -Syu yaourt 安装驱动 触摸板驱动 1pacman -S xf86-input-libinput xf86-input-synaptics 显示驱动 123pacman -S xf86-video-intelpacman -S mesa-libgl libva-intel-driver libvdpau-va-glmesa-demospacman -S nvidia nvidia-settings 声音 1pacman -S alsa-utils 无线网卡安装BCM4322 123pacman -S linux-firmwarepacman -S linux-headersyaourt -S broadcom-wl-dkms 安装Deepin桌面环境 1.安装Xorg和其工具包 1pacman -S xorg-server xorg-xinit 2.DDE基本环境安装 123pacman -S deepin deepin-extra lightdmpacman -S file-roller evince gedit thunderbird gpicviewpacman -S unrar unzip p7zip 3.修改lightdm.conf使用登录管理器 123&#x2F;etc&#x2F;lightdm&#x2F;lightdm.confgreeter-session&#x3D;lightdm-deepin-greetersystemctl enable lightdm 4.配置网络连接 12pacman -S networkmanagersystemctl enable NetworkManager 安装常用软件 1.搜狗输入法安装 12pacman -S fcitx fcitx-configtoolpacman -S fcitx-sougoupinyin 在用户目录下添加个配置文件： 1234nano ~&#x2F;.xprofileexport GTK_IM_MODULE&#x3D;fcitxexport QT_IM_MODULE&#x3D;fcitxexport XMODIFIERS&#x3D;@im&#x3D;fcitx 1pacman -S opencc （简体和繁体互相转换的库） 2.浏览器 1234pacman -S chromiumpacman -S google-chromepacman -S firefoxpacman -S git","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"Linux 文本处理器之 awk","slug":"awk","date":"2018-12-14T16:00:00.000Z","updated":"2020-12-04T12:12:34.506Z","comments":true,"path":"2018/12/15/awk/","link":"","permalink":"http://yoursite.com/2018/12/15/awk/","excerpt":"","text":"12345678910111213awk 'BEGIN&#123;FS=\"[:]\"&#125; &#123;aa+=$3&#125; END&#123;print \"所用的UID的和是:\",aa&#125;' passwdFS awk 'BEGIN&#123;FS=\"[:]\"&#125; /root/&#123;print $1,$2&#125;' passwdOFS awk 'BEGIN&#123;FS=\"[:]\";OFS=\"---\"&#125; /root/&#123;print $1,$2&#125;' passwdNF awk -F: '&#123;print NF&#125;' passwdRS awk 'BEGIN&#123;FS=\"[,]\";RS=\" \"&#125;&#123;print $2&#125;' bb.txtORS awk 'BEGIN&#123;FS=\"[:]\";ORS=\"---\"&#125;&#123;print $0&#125;' passwdFILENAME awk -F\"[:]\" '&#123;print FILENAME&#125;' passwdNR awk '&#123;print NR&#125;' a.txt b.txtFNR awk '&#123;print NR&#125;' a.txt b.txt# NR==FNR 此时处理的是第一个文件# NR!=FNR 此时处理的是第二个文件awk 'NR==FNR&#123;print FILENAME&#125; NR!=FNR&#123;print FILENAME&#125;' a.txt b.txtif awk -F[:] '&#123;if($3&lt;=1000)&#123;print $1\"是root用户\"&#125;else&#123;print $1\"是普通用户\"&#125;&#125;' /etc/passwd 变量名 属性 $0 当前记录 $1~$n 当前记录的第n个字段 FS 输入字段分隔符，默认为空格 RS 输入记录分割符，默认为换行符 NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始 OFS 输出字符分隔符，默认也是空格 ORS 输出的记录分隔符，默认为换行符","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"CentOS Oracle 12c 安装指南","slug":"centos_install_oracle12c","date":"2018-12-13T16:00:00.000Z","updated":"2020-12-04T12:25:38.133Z","comments":true,"path":"2018/12/14/centos_install_oracle12c/","link":"","permalink":"http://yoursite.com/2018/12/14/centos_install_oracle12c/","excerpt":"","text":"1. 优化、安装必要的工具1234567[root@oracle12c ~]$ yum -y install unzip vim lrzsz[root@oracle12c ~]$ setenforce 0[root@oracle12c ~]$ sed -i &#39;s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;&#39; &#x2F;etc&#x2F;selinux&#x2F;config[root@oracle12c ~]$ reboot[root@oracle12c ~]$ sed -i &#39;s&#x2F;^GSSAPIAuthentication yes$&#x2F;GSSAPIAuthentication no&#x2F;&#39; &#x2F;etc&#x2F;ssh&#x2F;sshd_config[root@oracle12c ~]$ sed -i &#39;s&#x2F;#UseDNS yes&#x2F;UseDNS no&#x2F;&#39; &#x2F;etc&#x2F;ssh&#x2F;sshd_config[root@oracle12c ~]$ service sshd restart 2. 安装依赖1[root@oracle12c ~]$ yum -y install binutils compat-libcap1 compat-libstdc++-33 compat-libstdc++-33*.i686 elfutils-libelf-devel gcc gcc-c++ glibc*.i686 glibc glibc-devel glibc-devel*.i686 ksh libgcc*.i686 libgcc libstdc++ libstdc++*.i686 libstdc++-devel libstdc++-devel*.i686 libaio libaio*.i686 libaio-devel libaio-devel*.i686 make sysstat unixODBC unixODBC*.i686 unixODBC-devel unixODBC-devel*.i686 libXp 3. 建立用户和组12345[root@oracle12c ~]$ groupadd oinstall[root@oracle12c ~]$ groupadd dba[root@oracle12c ~]$ groupadd oper[root@oracle12c ~]$ useradd -g oinstall -G dba,oper oracle[root@oracle12c ~]$ echo oracle | passwd --stdin oracle 4. 创建安装、备份目录12[root@oracle12c ~]$ mkdir -p &#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;12.2.0[root@oracle12c ~]$ chown -R oracle:oinstall &#x2F;u01 5. 更改共享内存1[root@oracle12c ~]$ echo &quot;shmfs &#x2F;dev&#x2F;shm tmpfs size&#x3D;12g 0&quot; &gt;&gt; &#x2F;etc&#x2F;fstab 6. 修改内核参数1[root@oracle12c ~]$ vim &#x2F;etc&#x2F;sysctl.conf 1234567891011121314fs.file-max &#x3D; 6815744kernel.sem &#x3D; 250 32000 100 128kernel.shmmni &#x3D; 4096kernel.shmall &#x3D; 4294967296kernel.shmmax &#x3D; 4398046511104kernel.panic_on_oops &#x3D; 1net.core.rmem_default &#x3D; 262144net.core.rmem_max &#x3D; 4194304net.core.wmem_default &#x3D; 262144net.core.wmem_max &#x3D; 1048576net.ipv4.conf.all.rp_filter &#x3D; 2net.ipv4.conf.default.rp_filter &#x3D; 2fs.aio-max-nr &#x3D; 1048576net.ipv4.ip_local_port_range &#x3D; 9000 65500 1[root@oracle12c ~]$ sysctl -p 7. 改文件限制1[root@oracle12c ~]$ vim &#x2F;etc&#x2F;security&#x2F;limits.conf 12345oracle soft nproc 2047oracle hard nproc 16384oracle soft nofile 1024oracle hard nofile 65536oracle soft stack 10240 8. 修改登陆配置文件1[root@oracle12c ~]$ vim &#x2F;etc&#x2F;pam.d&#x2F;login 1session required pam_limits.so 9. 修改 ulimit1[root@oracle12c ~]$ vim &#x2F;etc&#x2F;profile 12345678if [ $USER &#x3D; &quot;oracle&quot; ]; then if [ $SHELL &#x3D; &quot;&#x2F;bin&#x2F;ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536a else ulimit -u 16384 -n 65536 fifi 10. 修改环境变量1[root@oracle12c ~]$ vim ~&#x2F;.bash_profile 1234567PATH&#x3D;$PATH:$HOME&#x2F;.local&#x2F;bin:$HOME&#x2F;bin:$ORACLE_HOME&#x2F;binORACLE_BASE&#x3D;&#x2F;u01&#x2F;app&#x2F;oracleORACLE_HOME&#x3D;$ORACLE_BASE&#x2F;product&#x2F;12.2.0ORACLE_SID&#x3D;orclexport ORACLE_BASE ORACLE_HOME ORACLE_SIDexport NLS_LANG&#x3D;&quot;AMERICAN_AMERICA.UTF8&quot;export PATH 11. 修改 hosts 文件1[root@oracle12c ~]$ vim &#x2F;etc&#x2F;hosts 1[ipaddr] oracle12c 12. 上传安装包 linuxx64_12201_database.zip1[oracle@oracle12c ~]$ rz 13. 静默安装数据库软件12[oracle@oracle12c ~]$ cd database[oracle@oracle12c database]$ .&#x2F;runInstaller -silent -ignoreSysPrereqs -ignorePrereq -responseFile &#x2F;home&#x2F;oracle&#x2F;database&#x2F;response&#x2F;db_install.rsp /home/oracle/database/response/db_install.rsp 1234567891011121314151617oracle.install.responseFileVersion&#x3D;&#x2F;oracle&#x2F;install&#x2F;rspfmt_dbinstall_response_schema_v12.2.0oracle.install.option&#x3D;INSTALL_DB_SWONLYUNIX_GROUP_NAME&#x3D;dbaINVENTORY_LOCATION&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;oraInventoryORACLE_HOME&#x3D;&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;12.2.0ORACLE_BASE&#x3D;&#x2F;u01&#x2F;app&#x2F;oracleoracle.install.db.InstallEdition&#x3D;EEoracle.install.db.OSDBA_GROUP&#x3D;dbaoracle.install.db.OSOPER_GROUP&#x3D;dbaoracle.install.db.OSBACKUPDBA_GROUP&#x3D;dbaoracle.install.db.OSDGDBA_GROUP&#x3D;dbaoracle.install.db.OSKMDBA_GROUP&#x3D;dbaoracle.install.db.OSRACDBA_GROUP&#x3D;dbaoracle.install.db.CLUSTER_NODES&#x3D;oracle.install.db.isRACOneInstall&#x3D;falseSECURITY_UPDATES_VIA_MYORACLESUPPORT&#x3D;falseDECLINE_SECURITY_UPDATES&#x3D;true 14. 建立数据库1[oracle@oracle12c ~]$ $ORACLE_HOME&#x2F;bin&#x2F;dbca -silent -createDatabase -templateName General_Purpose.dbc -gdbname orcl -sid orcl -responseFile NO_VALUE -characterSet AL32UTF8 -memoryPercentage 50 -emConfiguration LOCAL root 用户下执行以下命令 12[root@oracle12c ~]$ &#x2F;oracle&#x2F;oraInventory&#x2F;orainstRoot.sh[root@oracle12c ~]$ &#x2F;oracle&#x2F;product&#x2F;12.2.0&#x2F;root.sh 15. 修改参数1[oracle@oracle12c ~]$ sqlplus &#x2F; as sysdba 12345678910111213141516171819202122232425262728293031323334353637383940SQL&gt; alter system set sga_target=0 scope=spfile;SQL&gt; alter system set pga_aggregate_target=0 scope=spfile;SQL&gt; alter system set db_files=2000 scope=spfile;SQL&gt; alter system set memory_max_target=12g scope=spfile;SQL&gt; alter system set memory_target=8g scope=spfile;SQL&gt; alter system set LOG_ARCHIVE_DEST_1='LOCATION=/backup/arch' scope=spfile;SQL&gt; alter SYSTEM set db_recovery_file_dest_size=4096M scope=spfile;SQL&gt; alter system set undo_retention=3600 scope=spfile;SQL&gt; alter system set processes=6000 scope=spfile;SQL&gt; alter system set sessions=8000 scope=spfile;SQL&gt; alter system set open_cursors=2000 scope=both;SQL&gt; create pfile='/tmp/pfile01.ora' from spfile;SQL&gt; alter system set filesystemio_options='asynch' scope=spfile;SQL&gt; alter system set disk_asynch_io=true SCOPE=SPFILE;SQL&gt; create directory expdp_dir as '/backup/expdp';SQL&gt; grant write,read on directory expdp_dir to public;SQL&gt; alter database add logfile group 4 '/u01/app/oracle/oradata/orcl/redo04.log' size 1G;SQL&gt; alter database add logfile group 5 '/u01/app/oracle/oradata/orcl/redo05.log' size 1G;SQL&gt; alter database add logfile group 6 '/u01/app/oracle/oradata/orcl/redo06.log' size 1G;SQL&gt; alter system switch logfile;SQL&gt; alter system switch logfile;SQL&gt; alter system switch logfile;SQL&gt; alter system checkpoint;SQL&gt; alter database drop logfile group 1;SQL&gt; alter database drop logfile group 2;SQL&gt; alter database drop logfile group 3;SQL&gt; host rm -rf /u01/app/oracle/oradata/orcl/redo0[1-3].logSQL&gt; alter database add logfile group 1 '/u01/app/oracle/oradata/orcl/redo01.log' size 1G;SQL&gt; alter database add logfile group 2 '/u01/app/oracle/oradata/orcl/redo02.log' size 1G;SQL&gt; alter database add logfile group 3 '/u01/app/oracle/oradata/orcl/redo03.log' size 1G; SQL&gt; alter system switch logfile;SQL&gt; alter system switch logfile;SQL&gt; alter system switch logfile;SQL&gt; alter system checkpoint;SQL&gt; shutdown immediateSQL&gt; startup mountSQL&gt; alter database archivelog;SQL&gt; alter database open;SQL&gt; alter profile default limit FAILED_LOGIN_ATTEMPTS unlimited;SQL&gt; create pfile='/tmp/pfile02.ora' from spfile; 16. 修改 Oracle 服务启动配置1[root@oracle12c ~]$ vim &#x2F;etc&#x2F;oratab 1orcl:&#x2F;u01&#x2F;app&#x2F;oracle&#x2F;product&#x2F;12.2.0:Y","categories":[{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"http://yoursite.com/tags/oracle/"}]},{"title":"Docker 入坑指南","slug":"docker","date":"2018-12-11T16:00:00.000Z","updated":"2020-12-04T12:14:31.966Z","comments":true,"path":"2018/12/12/docker/","link":"","permalink":"http://yoursite.com/2018/12/12/docker/","excerpt":"","text":"1. Docker 安装 Ubuntu 123456789101112131415161718# step 1: 安装必要的一些系统工具sudo apt updatesudo apt -y install apt-transport-https ca-certificates curl software-properties-common# step 2: 安装GPG证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# Step 3: 写入软件源信息sudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"# Step 4: 更新并安装 Docker-CEsudo apt -y updatesudo apt -y install docker-ce# 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# apt-cache madison docker-ce# docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages# docker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages# Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial)# sudo apt-get -y install docker-ce=[VERSION] CentOS 1234567891011121314151617181920212223242526# step 1: 安装必要的一些系统工具yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Step 3: 更新并安装 Docker-CEyum makecache fastyum -y install docker-ce# Step 4: 开启Docker服务service docker start# 注意：# 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，你可以通过以下方式开启。同理可以开启各种测试版本等。# vim /etc/yum.repos.d/docker-ce.repo# 将 [docker-ce-test] 下方的 enabled=0 修改为 enabled=1## 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# yum list docker-ce.x86_64 --showduplicates | sort -r# Loading mirror speeds from cached hostfile# Loaded plugins: branch, fastestmirror, langpacks# docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable# docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable# docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# Available Packages# Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos)# sudo yum -y install docker-ce-[VERSION] 2. 非 root 用户使用 Docker12# 将用户加入 docker 组sudo usermod -aG docker &lt;your-user&gt; 3. 常见问题 防火墙的问题 123# CentOS 7 firewalld 设置，添加相应端口firewall-cmd --permanent --add-port 80/tcpfirewall-cmd --reload IPv4 forwarding is disabled. Networking will not work. 12# vim /usr/lib/sysctl.d/00-system.conf 在最后添加一行net.ipv4.ip_forward=1","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"搭建基于 HDFS 碎片文件存储服务","slug":"hdfs","date":"2018-12-09T16:00:00.000Z","updated":"2020-12-04T12:16:27.216Z","comments":true,"path":"2018/12/10/hdfs/","link":"","permalink":"http://yoursite.com/2018/12/10/hdfs/","excerpt":"","text":"准备 Java 环境123yum -y install java-1.8.0-openjdk*java -versionvim /etc/profile 123export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdkexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 1source /etc/profile 准备 HDFS 环境配置 SSH先后执行如下两行命令，配置 SSH 以无密码模式登陆： 12ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsacat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys 接着可以验证下，在不输入密码的情况下，应该能使用 ssh 命令成功连接本机： 安装 Hadoop123456# 创建 /data/hadoop 目录，然后进入该目录：mkdir -p /data/hadoop &amp;&amp; cd $_# 下载并解压 Hadoop：wget http://archive.apache.org/dist/hadoop/core/hadoop-2.7.1/hadoop-2.7.1.tar.gztar -zxvf hadoop-2.7.1.tar.gzmv hadoop-2.7.1 hadoop &amp;&amp; mv $_ /usr/local/ 修改 Hadoop 环境配置文件 1vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh 1export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jre-1.8.0-openjdk 查看下 Hadoop 的版本： 1/usr/local/hadoop/bin/hadoop version 修改 Hadoop 配置由于我们的实践环境是在单机下进行的，所以此处把 Hadoop 配置为伪分布式模式。新建若干临时文件夹，我们在后续的配置中以及 HDFS 和 Hadoop 的启动过程中会使用到这些文件夹： 1cd /usr/local/hadoop &amp;&amp; mkdir -p tmp dfs/name dfs/data 修改 HDFS 配置文件 core-site.xml 1vim /usr/local/hadoop/etc/hadoop/core-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改 HDFS 配置文件 hdfs-site.xml 1vim &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改 HDFS 配置文件 yarn-site.xml 1vim /usr/local/hadoop/etc/hadoop/yarn-site.xml 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 启动 Hadoop 12345678910cd /usr/local/hadoop/bin/# 对 HDFS 文件系统进行格式化：./hdfs namenode -format# 接着进入如下目录cd /usr/local/hadoop/sbin/# 先后执行如下两个脚本启动 Hadoop./start-dfs.sh./start-yarn.sh# 验证 Hadoop 是否启动成功：jps 在浏览器中访问如下链接，应该能正常访问： http://&lt;您的 IP 地址&gt;:50070/explorer.html#/接下来，我们实践下如何将碎片文件存储到 HDFS 中。 存储碎片文件准备碎片文件123456# 创建目录用于存放碎片文件，进入该目录：mkdir -p /data/file &amp;&amp; cd /data/file# 新建一批碎片文件到该目录下i=1; while [ $i -le 99 ]; do name=`printf \"test%02d.txt\" $i`; touch \"$name\"; i=$(($i+1)); donels 将碎片文件存储在 HDFS 中12# 在 HDFS 上新建目录/usr/local/hadoop/bin/hadoop fs -mkdir /dest 此时，在浏览器是访问如下链接，可以看到 /dest 目录已创建，但是暂时还没有内容： http://&lt;您的 IP 地址&gt;:50070/explorer.html#/dest 上传碎片文件123456groupadd supergroupusermod -a -G supergroup root# 将之前创建的碎片文件上传到 HDFS 中：cd /data/file &amp;&amp; /usr/local/hadoop/bin/hadoop fs -put *.txt /dest/usr/local/hadoop/bin/hadoop fs -ls /dest# 在上传之前，我们需先创建 HDFS 用户组 supergroup，然后将 root 用户添加到该组中，否则会因权限问题页报告异常。 访问服务在浏览器是访问如下链接，可以看到 /dest 目录的文件内容： 1http:&#x2F;&#x2F;&lt;您的 IP 地址&gt;:50070&#x2F;explorer.html#&#x2F;dest","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"}]},{"title":"Hexo 打造静态博客","slug":"hexo","date":"2018-12-08T16:00:00.000Z","updated":"2020-12-04T12:16:42.651Z","comments":true,"path":"2018/12/09/hexo/","link":"","permalink":"http://yoursite.com/2018/12/09/hexo/","excerpt":"使用 Hexo 打造静态博客","text":"使用 Hexo 打造静态博客 1npm install hexo-deployer-git --save 修改主页配置文件 _config.yml1post_asset_folder : true 安装本地图片插件1npm install hexo-asset-image --save 生成新的博文1hexo n &quot;xxx&quot; 此时 /source/_posts/ 下会生成同名文件夹 博文引入图片1![](xxx&#x2F;xxx.jpg)","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://yoursite.com/tags/nodejs/"}]},{"title":"给 history 添加时间戳","slug":"bash_history","date":"2018-12-07T16:00:00.000Z","updated":"2020-12-04T12:12:39.601Z","comments":true,"path":"2018/12/08/bash_history/","link":"","permalink":"http://yoursite.com/2018/12/08/bash_history/","excerpt":"","text":"添加环境变量1[root@client ~]# vim &#x2F;etc&#x2F;profile 12HISTTIMEFORMAT=\"%Y-%m-%d %H:%M:%S\"export HISTTIMEFORMAT","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"jekyll 打造静态博客","slug":"jekyll","date":"2018-12-06T16:00:00.000Z","updated":"2020-12-04T12:17:57.651Z","comments":true,"path":"2018/12/07/jekyll/","link":"","permalink":"http://yoursite.com/2018/12/07/jekyll/","excerpt":"","text":"1. 安装之前先安装依赖包1sudo apt-get install ruby ruby-dev build-essential 2. 添加环境变量1234echo '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrcecho 'export GEM_HOME=$HOME/gems' &gt;&gt; ~/.bashrcecho 'export PATH=$HOME/gems/bin:$PATH' &gt;&gt; ~/.bashrcsource ~/.bashrc 3. 安装 Jekyll1gem install jekyll bundler 4. 使用 bundle 更新 Jekyll123jekyll --versiongem list jekyllbundle update jekyll 5. 使用 gem 更新 Jekyll1gem update jekyll 6. 更新 Rubygems1gem update --system 7. 安装预览版1234## 安装最新预览版gem install jekyll --pre## 安装特定版本的 Jekyllgem install jekyll -v '2.0.0.alpha.1' 8. 源码安装12345git clone git://github.com/jekyll/jekyll.gitcd jekyllscript/bootstrapbundle exec rake buildls pkg/*.gem | head -n 1 | xargs gem install -l","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"ruby","slug":"ruby","permalink":"http://yoursite.com/tags/ruby/"},{"name":"jekyll","slug":"jekyll","permalink":"http://yoursite.com/tags/jekyll/"}]},{"title":"Keepalive 安装与配置","slug":"keepalive","date":"2018-12-05T16:00:00.000Z","updated":"2020-12-04T11:24:29.134Z","comments":true,"path":"2018/12/06/keepalive/","link":"","permalink":"http://yoursite.com/2018/12/06/keepalive/","excerpt":"Keepalive 安装与配置","text":"Keepalive 安装与配置 1. 安装 keepalive1[root@centos ~]# yum -y install keepalived","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"keepalive","slug":"keepalive","permalink":"http://yoursite.com/tags/keepalive/"}]},{"title":"Linux 网络管理","slug":"managenetwork","date":"2018-12-04T16:00:00.000Z","updated":"2020-12-04T12:20:09.677Z","comments":true,"path":"2018/12/05/managenetwork/","link":"","permalink":"http://yoursite.com/2018/12/05/managenetwork/","excerpt":"Linux 网络管理","text":"Linux 网络管理 1. arp：管理系统中的 ARP 高速缓存12345678910111213141516171819202122232425Usage: arp [-vn] [&lt;HW&gt;] [-i &lt;if&gt;] [-a] [&lt;hostname&gt;] &lt;-Display ARP cache arp [-v] [-i &lt;if&gt;] -d &lt;host&gt; [pub] &lt;-Delete ARP entry arp [-vnD] [&lt;HW&gt;] [-i &lt;if&gt;] -f [&lt;filename&gt;] &lt;-Add entry from file arp [-v] [&lt;HW&gt;] [-i &lt;if&gt;] -s &lt;host&gt; &lt;hwaddr&gt; [temp] &lt;-Add entry arp [-v] [&lt;HW&gt;] [-i &lt;if&gt;] -Ds &lt;host&gt; &lt;if&gt; [netmask &lt;nm&gt;] pub &lt;-&#39;&#39;- -a display (all) hosts in alternative (BSD) style -e display (all) hosts in default (Linux) style -s, --set set a new ARP entry -d, --delete delete a specified entry -v, --verbose be verbose -n, --numeric don&#39;t resolve names -i, --device specify network interface (e.g. eth0) -D, --use-device read &lt;hwaddr&gt; from given device -A, -p, --protocol specify protocol family -f, --file read new entries from file or from &#x2F;etc&#x2F;ethers &lt;HW&gt;&#x3D;Use &#39;-H &lt;hw&gt;&#39; to specify hardware address type. Default: ether List of possible hardware types (which support ARP): ash (Ash) ether (Ethernet) ax25 (AMPR AX.25) netrom (AMPR NET&#x2F;ROM) rose (AMPR ROSE) arcnet (ARCnet) dlci (Frame Relay DLCI) fddi (Fiber Distributed Data Interface) hippi (HIPPI) irda (IrLAP) x25 (generic X.25) infiniband (InfiniBand) eui64 (Generic EUI-64) 2. arpwatch：监听 ARP 记录3. arping：发送 ARP 请求到一个相邻主机4. finger：查找并显示用户信息5. ifconfig：设置网络接口6. iwconfig：设置无线网卡7. hostname：显示主机名8. ifup：激活设备9. ifdown：禁用网络设备10. mii-tool：调整网卡模式11. route：设置路由表12. netstat：查看网络连接13. ping：检测主机的连通性14. traceroute：检查数据包所经过的路由器15. wget：下载文件16. telnet：远程登陆17. ethtool：查询及设置网卡参数18. tc：显示和维护流量控制设置","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"Linux 时区设置","slug":"timezone","date":"2018-12-03T16:00:00.000Z","updated":"2020-12-04T11:24:29.143Z","comments":true,"path":"2018/12/04/timezone/","link":"","permalink":"http://yoursite.com/2018/12/04/timezone/","excerpt":"Linux 时区设置","text":"Linux 时区设置 1. 时间设置查看、设置硬件时间12345hwclock --showclock --show## 月/日/年时:分:秒hwclock --set --date=\"06/18/14 14:55\"clock --set --date=\"06/18/14 14:55\" 硬件时钟与系统时钟同步1234567## hc代表硬件时间，sys代表系统时间## 硬件时钟同步系统时钟hwclock --hctosysclock --hctosys## 系统时钟同步硬件时钟hwclock --systohcclock --systohc 同步 ntp 服务器123456## 安装 ntp、ntpdateyum -y install ntpntpdate &lt;IP&gt;## 添加定时任务crontab -e0 0 * * * /usr/sbin/ntpdate &lt;IP&gt; 2. 时区设置tzselect1TZ='Asia/Shanghai'; export TZ 修改配置文件1234vim etc&#x2F;sysconfig&#x2F;clockZONE&#x3D;Asia&#x2F;Shanghairm &#x2F;etc&#x2F;localtimeln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime 12345timedatectltimedatectl list-timezonestimedatectl set-timezone Asia/Shanghaiyum -y install ntpvim /etc/ntp.conf","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"Tomcat 配置与优化","slug":"tomcat","date":"2018-11-30T16:00:00.000Z","updated":"2020-12-04T11:24:29.144Z","comments":true,"path":"2018/12/01/tomcat/","link":"","permalink":"http://yoursite.com/2018/12/01/tomcat/","excerpt":"Tomcat 配置与优化","text":"Tomcat 配置与优化 1. JVM 配置添加 tomcat 管理员1[root@server ~]# vim &#x2F;tomcat&#x2F;conf&#x2F;tomcat-users.xml 123&lt;role rolename=\"manager-gui\"/&gt;&lt;role rolename=\"admin-gui\"/&gt;&lt;user username=\"manager\" password=\"manager\" roles=\"admin-gui,manager-gui\"/&gt; 修改 JVM 虚拟内存 1JAVA_OPTS=\"-server -Xms1024m -Xmx1024m -Xmn256m -XX:PermSize=512m -XX:MaxPermSize=1024m -XX:ReservedCodeCacheSize=256M -Djava.awt.headless=true -Dfile.encoding=utf-8\" 堆设置： -Xms=n 初始堆大小-Xmx=n 最大堆大小-XX:NewSize=n 设置年轻代大小-XX:NewRatio=n 设置年轻代和年老代的比值.如:为3,表示年轻代与年老代比值为1:3,年轻代占整个年轻代年老代和的1/4-XX:SurvivorRatio=n 年轻代中Eden区与两个Survivor区的比值.注意Survivor区有两个.如:3,表示Eden:Survivor=3:2,一个Survivor区占整个年轻代的1/5-XX:MaxPermSize=n 设置持久代大小 收集器设置： -XX:+UseSerialGC 设置串行收集器-XX:+UseParallelGC 设置并行收集器-XX:+UseParalledlOldGC 设置并行年老代收集器-XX:+UseConcMarkSweepGC 设置并发收集器 垃圾回收统计信息： -XX:+PrintGC-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-Xloggc:filename 并行收集器设置： -XX:ParallelGCThreads=n 设置并行收集器收集时使用的CPU数.并行收集线程数.-XX:MaxGCPauseMillis=n 设置并行收集最大暂停时间-XX:GCTimeRatio=n 设置垃圾回收时间占程序运行时间的百分比.公式为1/(1+n)并发收集器设置-XX:+CMSIncrementalMode 设置为增量模式.适用于单CPU情况.-XX:ParallelGCThreads=n 设置并发收集器年轻代收集方式为并行收集时,使用的CPU数.并行收集线程数 2. apr 安装安装依赖1[root@server ~]# yum -y install gcc expat-devel 安装 apr123[root@server ~]# mkdir &#x2F;usr&#x2F;local&#x2F;apr[root@server apr-1.6.3]# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr[root@server apr-1.6.3]# make &amp;&amp; make install 安装 apr-util12[root@server apr-util-1.6.1]# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr --with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr[root@server apr-util-1.6.1]# make &amp;&amp; make install 安装 tomcat-native123[root@server ~]# cd tomcat-native-1.2.17-src&#x2F;native&#x2F;[root@server native]# .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;apr --with-apr&#x3D;&#x2F;usr&#x2F;local&#x2F;apr --with-java-home&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.7.0_80&#x2F;[root@server native]# make &amp;&amp; make install 修改 tomcat 配置1[root@server ~]# vim &#x2F;tomcat&#x2F;bin&#x2F;catalina.sh 12# 添加 CATALINA_OPTSCATALINA_OPTS=\"-Djava.library.path=/usr/local/apr/lib\" 1[root@server ~]# vim &#x2F;tomcat&#x2F;conf&#x2F;server.xml 123456789101112&lt;Connector port=\"8001\" protocol=\"org.apache.coyote.http11.Http11AprProtocol\" executor=\"tomcatThreadPool\" maxThreads=\"1000\" enableLookups=\"false\" acceptCount=\"1000\" connectionTimeout=\"30000\" redirectPort=\"9100\" maxPostSize=\"8388608\" maxParameterCount=\"40000\" disableUploadTimeout=\"true\" URIEncoding=\"UTF-8\"/&gt; 3. SSLEngine Error查看 tomcat 日志，出现 SSLEngine Errororg.apache.catalina.core.AprLifecycleListener.lifecycleEvent Failed to initialize the SSLEngine.{:.error} 解决办法1[root@server ~]# vim &#x2F;tomcat&#x2F;conf&#x2F;server.xml 1&lt;Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"off\" /&gt;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"}]},{"title":"LVS","slug":"lvs","date":"2018-11-29T16:00:00.000Z","updated":"2020-12-04T12:19:49.796Z","comments":true,"path":"2018/11/30/lvs/","link":"","permalink":"http://yoursite.com/2018/11/30/lvs/","excerpt":"LVS","text":"LVS 1. 安装 ipvsadm1[root@centos ~]# yum -y install ipvsadm 2. ipvsadm 用法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768[root@centos ~]# ipvsadm --helpipvsadm v1.27 2008&#x2F;5&#x2F;15 (compiled with popt and IPVS v1.2.1)Usage: ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [--pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address ipvsadm -C ipvsadm -R ipvsadm -S [-n] ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|u|f service-address] ipvsadm --set tcp tcpfin udp ipvsadm --start-daemon state [--mcast-interface interface] [--syncid sid] ipvsadm --stop-daemon state ipvsadm -hCommands:Either long or short options are allowed. --add-service -A add virtual service with options --edit-service -E edit virtual service with options --delete-service -D delete virtual service --clear -C clear the whole table --restore -R restore rules from stdin --save -S save rules to stdout --add-server -a add real server with options --edit-server -e edit real server with options --delete-server -d delete real server --list -L|-l list the table --zero -Z zero counters in a service or all services --set tcp tcpfin udp set connection timeout values --start-daemon start connection sync daemon --stop-daemon stop connection sync daemon --help -h display this help messageOptions: --tcp-service -t service-address service-address is host[:port] --udp-service -u service-address service-address is host[:port] --fwmark-service -f fwmark fwmark is an integer greater than zero --ipv6 -6 fwmark entry uses IPv6 --scheduler -s scheduler one of rr|wrr|lc|wlc|lblc|lblcr|dh|sh|sed|nq, the default scheduler is wlc. --pe engine alternate persistence engine may be sip, not set by default. --persistent -p [timeout] persistent service --netmask -M netmask persistent granularity mask --real-server -r server-address server-address is host (and port) --gatewaying -g gatewaying (direct routing) (default) --ipip -i ipip encapsulation (tunneling) --masquerading -m masquerading (NAT) --weight -w weight capacity of real server --u-threshold -x uthreshold upper threshold of connections --l-threshold -y lthreshold lower threshold of connections --mcast-interface interface multicast interface for connection sync --syncid sid syncid for connection sync (default&#x3D;255) --connection -c output of current IPVS connections --timeout output of timeout (tcp tcpfin udp) --daemon output of daemon information --stats output of statistics information --rate output of rate information --exact expand numbers (display exact values) --thresholds output of thresholds information --persistent-conn output of persistent connection info --nosort disable sorting output of service&#x2F;server entries --sort does nothing, for backwards compatibility --ops -o one-packet scheduling --numeric -n numeric output of addresses and ports --sched-flags -b flags scheduler flags (comma-separated) 3.","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"lvs","slug":"lvs","permalink":"http://yoursite.com/tags/lvs/"}]},{"title":"Node.js 安装指南","slug":"nodejs","date":"2018-11-26T16:00:00.000Z","updated":"2020-12-04T12:21:33.395Z","comments":true,"path":"2018/11/27/nodejs/","link":"","permalink":"http://yoursite.com/2018/11/27/nodejs/","excerpt":"Node.js 安装（NVM 包管理器）","text":"Node.js 安装（NVM 包管理器） Install &amp; Update script12# curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.2/install.sh | bashwget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.2/install.sh | bash 12export NVM_DIR=\"$([ -z \"$&#123;XDG_CONFIG_HOME-&#125;\" ] &amp;&amp; printf %s \"$&#123;HOME&#125;/.nvm\" || printf %s \"$&#123;XDG_CONFIG_HOME&#125;/nvm\")\"[ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" # This loads nvm Git install1git clone https://github.com/nvm-sh/nvm.git $HOME/.nvm 12cd .nvmgit checkout v0.35.2 123export NVM_DIR=\"$HOME/.nvm\"[ -s \"$NVM_DIR/nvm.sh\" ] &amp;&amp; \\. \"$NVM_DIR/nvm.sh\" # This loads nvm[ -s \"$NVM_DIR/bash_completion\" ] &amp;&amp; \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://yoursite.com/tags/nodejs/"}]},{"title":"树莓派安装教程","slug":"raspberrypi","date":"2018-11-25T16:00:00.000Z","updated":"2020-12-04T11:24:29.142Z","comments":true,"path":"2018/11/26/raspberrypi/","link":"","permalink":"http://yoursite.com/2018/11/26/raspberrypi/","excerpt":"树莓派安装教程","text":"树莓派安装教程 rasbian 网络配置1234567891011auto loiface lo inet loopbackauto eth0iface eth0 inet dhcpauto wlan0allow-hotplug wlan0iface wlan0 inet dhcpwpa-ssid &quot;360WiFi&quot;wpa-psk &quot;hellworld&quot; 树莓派安装 docker-ce1234567curl -fsSL https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;debian&#x2F;gpg | sudo apt-key add -echo &quot;deb [arch&#x3D;armhf] https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;docker-ce&#x2F;linux&#x2F;debian $(lsb_release -cs) stable&quot; | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;docker.listapt updateapt install docker-ce","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"http://yoursite.com/tags/raspberrypi/"}]},{"title":"SELinux","slug":"selinux","date":"2018-11-24T16:00:00.000Z","updated":"2020-12-04T11:24:29.142Z","comments":true,"path":"2018/11/25/selinux/","link":"","permalink":"http://yoursite.com/2018/11/25/selinux/","excerpt":"SELinux","text":"SELinux 1. 上下文（以 apache 为例）1）服务器端安装 httpd123[root@server ~]# yum -y install httpd[root@server ~]# systemctl start httpd[root@server ~]# systemctl enable httpd 2）查看 httpd 默认目录的上下文12[root@server ~]# ls -ldZ &#x2F;var&#x2F;www&#x2F;drwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 &#x2F;var&#x2F;www&#x2F; 3）设置临时上下文1234567891011121314151617[root@server ~]# mkdir &#x2F;html[root@server ~]# ls -ldZ &#x2F;html&#x2F;drwxr-xr-x. root root unconfined_u:object_r:default_t:s0 &#x2F;html&#x2F;[root@server ~]# chcon -R -t httpd_sys_content_t &#x2F;html&#x2F;[root@server ~]# ls -ldZ &#x2F;html&#x2F;drwxr-xr-x. root root unconfined_u:object_r:httpd_sys_content_t:s0 &#x2F;html&#x2F;[root@server ~]# restorecon -R &#x2F;html&#x2F;[root@server ~]# ls -ldZ &#x2F;html&#x2F;drwxr-xr-x. root root unconfined_u:object_r:default_t:s0 &#x2F;html&#x2F;[root@server ~]# # --reference 设置和目录相同的上下文[root@server ~]# chcon -R --reference&#x3D;&#x2F;var&#x2F;www&#x2F;html &#x2F;www 4）设置永久上下文123456789[root@server ~]# semanage fcontext -a -t httpd_sys_content_t &#39;&#x2F;html(&#x2F;.*)?&#39;[root@server ~]# ls -ldZ &#x2F;htmldrwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 &#x2F;html[root@server ~]# restorecon -R &#x2F;html&#x2F;[root@server ~]# ls -ldZ &#x2F;htmldrwxr-xr-x. root root system_u:object_r:httpd_sys_content_t:s0 &#x2F;html 2. 布尔值（以 vsftpd 为例） 如果搭建了一个服务，需要在客户端往服务里写东西，但是无法写入，按照以下不走排查 1）检查配置文件是否允许写2）检查文件系统是否允许写3）检查 selinux （上下文|布尔值） 1)服务端安装 vsftpd123[root@server ~]# yum -y install vsftpd[root@server ~]# systemctl start vsftpd[root@server ~]# systemctl enable vsftpd 2）检查配置文件是否允许写1[root@server ~]# vim &#x2F;etc&#x2F;vsftpd&#x2F;vsftpd.conf 123# 允许匿名上传anon_upload_enable&#x3D;YESanon_mkdir_write_enable&#x3D;YES 3）检查文件系统是否允许写1234567891011[root@server ~]# ls -ld &#x2F;var&#x2F;ftp&#x2F;drwxr-xr-x. 4 root root 27 8月 17 14:29 &#x2F;var&#x2F;ftp&#x2F;[root@server ~]# cd &#x2F;var&#x2F;ftp&#x2F;[root@server ftp]# mkdir test[root@server ftp]# chown -R ftp.ftp test[root@server ftp]# ls -ld testdrwxr-xr-x. 2 ftp ftp 6 8月 17 14:48 test 4）检查 selinux （上下文|布尔值）12345678910111213141516171819202122232425262728293031[root@server ~]# getsebool -a | grep ftpftpd_anon_write --&gt; offftpd_connect_all_unreserved --&gt; offftpd_connect_db --&gt; offftpd_full_access --&gt; offftpd_use_cifs --&gt; offftpd_use_fusefs --&gt; offftpd_use_nfs --&gt; offftpd_use_passive_mode --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_enable_ftp_server --&gt; offtftp_anon_write --&gt; offtftp_home_dir --&gt; off[root@server ftp]# setsebool -P ftpd_anon_write on[root@server ftp]# setsebool -P ftpd_full_access on[root@server ~]# getsebool -a | grep ftpftpd_anon_write --&gt; onftpd_connect_all_unreserved --&gt; offftpd_connect_db --&gt; offftpd_full_access --&gt; onftpd_use_cifs --&gt; offftpd_use_fusefs --&gt; offftpd_use_nfs --&gt; offftpd_use_passive_mode --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_enable_ftp_server --&gt; offtftp_anon_write --&gt; offtftp_home_dir --&gt; off","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"selinux","slug":"selinux","permalink":"http://yoursite.com/tags/selinux/"}]},{"title":"Subversion 安装与配置","slug":"svn","date":"2018-11-23T16:00:00.000Z","updated":"2020-12-04T11:24:29.142Z","comments":true,"path":"2018/11/24/svn/","link":"","permalink":"http://yoursite.com/2018/11/24/svn/","excerpt":"Subversion 安装与配置","text":"Subversion 安装与配置 1. 安装 Subversion1yum install -y subversion 2. 创建 SVN 版本库12mkdir -p &#x2F;data&#x2F;svn&#x2F;myprojectsvnadmin create &#x2F;data&#x2F;svn&#x2F;myproject 3. 配置 SVN 信息配置文件简介版本库中的配置目录 conf 有三个文件: authz 是权限控制文件 passwd 是帐号密码文件 svnserve.conf 是SVN服务综合配置文件 配置权限配置文件 authz示例代码：/data/svn/myproject/conf/authz 12345678910[groups] #用户组admin &#x3D; admin,root,test #用户组所对应的用户[&#x2F;] #库目录权限@admin &#x3D; rw #用户组权限*&#x3D;r #非用户组权限 配置账号密码文件 passwd示例代码：/data/svn/myproject/conf/passwd 123456[users]# harry &#x3D; harryssecret# sally &#x3D; sallyssecretadmin &#x3D; 123456root &#x3D; 123456test &#x3D; 123456 配置 SVN 服务综合配置文件 svnserve.conf示例代码：/data/svn/myproject/conf/svnserve.conf 1234567891011121314[general]# force-username-case &#x3D; none# 匿名访问的权限 可以是read、write，none，默认为readanon-access &#x3D; none#使授权用户有写权限auth-access &#x3D; write#密码数据库的路径password-db &#x3D; passwd#访问控制文件authz-db &#x3D; authz#认证命名空间，SVN会在认证提示里显示，并且作为凭证缓存的关键字realm &#x3D; &#x2F;data&#x2F;svn&#x2F;myproject[sasl] 4. 启动 SVN 服务启动 SVN1svnserve -d -r &#x2F;data&#x2F;svn checkout SVN项目12mkdir -p &#x2F;data&#x2F;workspace&#x2F;myprojectsvn co svn:&#x2F;&#x2F;127.0.0.1&#x2F;myproject &#x2F;data&#x2F;workspace&#x2F;myproject --username root --password 123456 --force --no-auth-cache 提交文件到 SVN 服务器从本地提交文件到 SVN 服务器，其中 root 密码为 /data/svn/myproject/conf/passwd 文件存储的密码 1234cd &#x2F;data&#x2F;workspace&#x2F;myprojectecho test &gt;&gt; test.txtsvn add test.txtsvn commit test.txt -m &#39;test&#39; 提交成功后可以通过如下命令从本地项目删除文件 12cd &#x2F;data&#x2F;workspace&#x2F;myprojectrm -rf test.txt 删除后可以通过 SVN 服务器恢复 12cd &#x2F;data&#x2F;workspace&#x2F;myprojectsvn update 清除SVN客户端密码方法：邮件选择TortoiseSVN中的settings选项—Saved Data—右边会发现有个Authentication data,点击clear，即完成清空账号密码操作，确认即可。下次就会自动弹出登录框。 在eclipse的svn插件中，我们也会保存密码，那么要清除时，换账号登录，就稍微麻烦点： 查看你的Eclipse中使用的是什么SVN 接口windows &gt; preference &gt; Team &gt; SVN 如果是用的JavaHL, 找到以下目录并删除auth目录.C:\\Documents and Settings\\User\\Application Data\\Subversion\\ 如果你用的SVNKit, 找到以下目录并删除.keyring文件.eclipse\\configuration\\org.eclipse.core.runtime\\","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"svn","slug":"svn","permalink":"http://yoursite.com/tags/svn/"}]},{"title":"Ubuntu 网络配置","slug":"ubuntuserver","date":"2018-11-22T16:00:00.000Z","updated":"2020-12-04T11:24:29.144Z","comments":true,"path":"2018/11/23/ubuntuserver/","link":"","permalink":"http://yoursite.com/2018/11/23/ubuntuserver/","excerpt":"Ubuntu Server 网络配置","text":"Ubuntu Server 网络配置 1. 查看所有网卡信息1ifconfig -a 2. 修改网卡配置文件1vim &#x2F;etc&#x2F;network&#x2F;interfaces DHCP 1234567source /etc/network/interfaces.d/*auto loiface lo inet loopbackauto ens33iface ens33 inet dhcp STATIC 123456789101112131415source /etc/network/interfaces.d/*auto loiface lo inet loopbackauto ens33iface ens33 inet static# 克隆 mac 地址# pre-up ifconfig ens33 hw ether &lt;MACADDR&gt; address &lt;IPADDR&gt;gateway &lt;GATEWAY&gt;netmask &lt;NETMASK&gt;# network &lt;NETWORK&gt;# broadcast &lt;BROADCAST&gt;dns-nameservers &lt;DNS&gt;","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://yoursite.com/tags/ubuntu/"}]},{"title":"VVirtualBox EFI 引导问题","slug":"virtualbox","date":"2018-11-20T16:00:00.000Z","updated":"2020-12-04T11:24:29.145Z","comments":true,"path":"2018/11/21/virtualbox/","link":"","permalink":"http://yoursite.com/2018/11/21/virtualbox/","excerpt":"VirtualBox EFI 引导问题","text":"VirtualBox EFI 引导问题 1、引导界面修改123Shell&gt; FS0:FS0:\\&gt; cd EFIFS0:\\EFI&gt; cp centos\\grubx64.efi BOOT\\grubx64.efi 2、系统界面修改1cp &#x2F;boot&#x2F;efi&#x2F;EFI&#x2F;centos&#x2F;grubx64.efi &#x2F;boot&#x2F;efi&#x2F;EFI&#x2F;BOOT&#x2F;grubx64.efi","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"virtualbox","slug":"virtualbox","permalink":"http://yoursite.com/tags/virtualbox/"}]},{"title":"FTP 教程","slug":"vsftpd","date":"2018-11-19T16:00:00.000Z","updated":"2020-12-04T11:24:29.146Z","comments":true,"path":"2018/11/20/vsftpd/","link":"","permalink":"http://yoursite.com/2018/11/20/vsftpd/","excerpt":"一份简易的 ftp 安装使用教程","text":"一份简易的 ftp 安装使用教程 1. 安装 vsftpd123456789101112131415# 查看 selinux 状态getenforce# 查看防火墙状态service firewalld status# 安装 vsftpdyum -y install vsftpd# 设置开机启动systemctl enable vsftpd# 启动 vsftpd 服务systemctl start vsftpd# 防火墙开放 ftp 服务firewall-cmd --add-service=ftp --permanent# 查看和更改 ftp 的 sebool 值getsebool -a | grep ftpsetsebool ftpd_full_access on 2. 配置 vsftpd1vim /etc/vsftpd/vsftpd.conf vsftpd.conf 1234567# 不允许匿名访问 ftpanonymous_enable&#x3D;NO# 用户不允许切换上级目录chroot_local_user&#x3D;YESallow_writeable_chroot&#x3D;YES# 设置时区use_localtime&#x3D;YES 12# 修改配置后重启 vsftpdsystemctl restart vsftpd 3. 创建用户1234# 创建用户 [username]，不允许登陆，家目录为 [directory]useradd -s /sbin/nologin -m -d [directory] [username]# 设置密码echo \"[password]\" | passwd --stdin [username] 4. 验证1234# 安装 ftp 客户端yum -y install ftp# 连接 ftp 服务器ftp [ip]","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"ftp","slug":"ftp","permalink":"http://yoursite.com/tags/ftp/"}]},{"title":"Windows LinuxSubSystem","slug":"wsl","date":"2018-11-18T16:00:00.000Z","updated":"2020-12-04T11:24:29.146Z","comments":true,"path":"2018/11/19/wsl/","link":"","permalink":"http://yoursite.com/2018/11/19/wsl/","excerpt":"Windows Linux 子系统安装指南","text":"Windows Linux 子系统安装指南 安装 oh-my-zsh curl 1sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" wget 1sh -c \"$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" 更改默认 shell1chsh -s $(which zsh) 更改主题1vim ~/.zshrc 12ZSH_THEME&#x3D;&quot;agnoster&quot;DEFAULT_USER&#x3D;&quot;jeremy&quot; 问题 字体问题导致显示异常 解决办法：Windows 环境安装 powerline-fonts 并设置控制台字体https://github.com/powerline/fonts.git 启动vim的时候会出现字体变回原来的新宋体的情况： win + R -&gt; 运行 -&gt; regedit 1HKEY_CURRENT_USER\\Console\\C:_Program Files_WindowsApps_CanonicalGroupLimited.Ubuntu18.04onWindows_1804.2018.817.0_x64__79rhkp1fndgsc_ubuntu1804.exe 添加：CodePage (DWORD (32) 类型、值 0x01b5)","categories":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"}],"tags":[{"name":"windows","slug":"windows","permalink":"http://yoursite.com/tags/windows/"},{"name":"wsl","slug":"wsl","permalink":"http://yoursite.com/tags/wsl/"}]},{"title":"Zabbix Proxy 分布式监控","slug":"zabbix_proxy","date":"2018-11-17T16:00:00.000Z","updated":"2020-12-04T11:24:29.147Z","comments":true,"path":"2018/11/18/zabbix_proxy/","link":"","permalink":"http://yoursite.com/2018/11/18/zabbix_proxy/","excerpt":"使用 Zabbix Proxy 搭建分布式监控","text":"使用 Zabbix Proxy 搭建分布式监控 1. 安装 MySQL、Zabbix Prorxy1234567# 安装 MySQLapt install mysql-server# 安装 zabbix proxywget https://repo.zabbix.com/zabbix/3.4/ubuntu/pool/main/z/zabbix-release/zabbix-release_3.4-1+xenial_all.debdpkg -i zabbix-release_3.4-1+xenial_all.debapt updateapt install zabbix-server-mysql zabbix-agent zabbix-proxy-mysql zabbix-get zabbix-sender 2. 导入数据1mysql -uroot -p 1234--创建 zabbix_proxy 数据库create database zabbix_proxy character set utf8 collate utf8_bin;--授权grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'password'; 1zcat /usr/share/doc/zabbix-proxy-mysql/schema.sql.gz | mysql -uzabbix -pzabbix zabbix 3. 更改配置1vim /etc/zabbix/zabbix_proxy.conf 1234567891011121314151617Server&#x3D;192.168.6.30Hostname&#x3D;Zabbix proxyLogFile&#x3D;&#x2F;var&#x2F;log&#x2F;zabbix&#x2F;zabbix_proxy.logLogFileSize&#x3D;0PidFile&#x3D;&#x2F;var&#x2F;run&#x2F;zabbix&#x2F;zabbix_proxy.pidSocketDir&#x3D;&#x2F;var&#x2F;run&#x2F;zabbixDBName&#x3D;zabbixDBUser&#x3D;zabbixDBPassword&#x3D;zabbixConfigFrequency&#x3D;120DataSenderFrequency&#x3D;1SNMPTrapperFile&#x3D;&#x2F;var&#x2F;log&#x2F;snmptrap&#x2F;snmptrap.logTimeout&#x3D;30ExternalScripts&#x3D;&#x2F;usr&#x2F;lib&#x2F;zabbix&#x2F;externalscriptsFpingLocation&#x3D;&#x2F;usr&#x2F;bin&#x2F;fpingFping6Location&#x3D;&#x2F;usr&#x2F;bin&#x2F;fping6LogSlowQueries&#x3D;3000 4. 启动服务并设置开机启动1systemctl enable zabbix-proxy zabbix-agent mysql","categories":[{"name":"monitor","slug":"monitor","permalink":"http://yoursite.com/categories/monitor/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"Zabbix 安装指南","slug":"zabbix_installation","date":"2018-11-16T16:00:00.000Z","updated":"2020-12-04T11:24:29.146Z","comments":true,"path":"2018/11/17/zabbix_installation/","link":"","permalink":"http://yoursite.com/2018/11/17/zabbix_installation/","excerpt":"Zabbix 3.4 安装指南","text":"Zabbix 3.4 安装指南 CentOS 安装 zabbix3.41. 准备123rpm -i http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpmyum install zabbix-server-mysql zabbix-web-mysql zabbix-agentyum -y install php-fpm php php-mysql php-gd php-bcmath php-mbstring php-xml php-ldap 2. 设置数据库123456&#x2F;usr&#x2F;bin&#x2F;mysqladmin -u root password 123456mysql -uroot -ppasswordmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by &#39;zabbix&#39;;mysql&gt; quit; 3. 数据库导入数据1zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 4. 修改 zabbix 配置文件增加 DBPassword=zabbix1vim /etc/zabbix/zabbix_server.conf 1DBPassword&#x3D;zabbix 5. 将时区设置为：亚洲/上海12vim /etc/httpd/conf.d/zabbix.confphp_value date.timezone Asia/Shanghai 6. 启动服务，将服务设为开机启动12systemctl restart zabbix-server zabbix-agent httpdsystemctl enable zabbix-server zabbix-agent httpd 7. 修改默认语言，文字配置123vim &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;include&#x2F;locales.inc.phpcp simkai.ttf &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;fonts&#x2F;vim &#x2F;usr&#x2F;share&#x2F;zabbix&#x2F;include&#x2F;defines.inc.php","categories":[{"name":"monitor","slug":"monitor","permalink":"http://yoursite.com/categories/monitor/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"Zabbix 通过 jmx 监控 Tomcat","slug":"zabbix_jmx","date":"2018-11-15T16:00:00.000Z","updated":"2020-12-04T11:24:29.147Z","comments":true,"path":"2018/11/16/zabbix_jmx/","link":"","permalink":"http://yoursite.com/2018/11/16/zabbix_jmx/","excerpt":"Zabbix 通过 jmx 监控 Tomcat","text":"Zabbix 通过 jmx 监控 Tomcat 1. 安装 jdk 和 zabbix-java-gateway1234# 安装 openjdk 或者下载 tar.gzapt install openjdk-8-jdk# 安装 zabbix-java-gatewayapt install zabbix-java-gateway 2. 修改服务器端配置1vim &#x2F;etc&#x2F;zabbix&#x2F;zabbix_server.conf 123JavaGateway&#x3D;192.168.6.30JavaGatewayPort&#x3D;10052StartJavaPollers&#x3D;50 123systemctl restart zabbix-serversystemctl start zabbix-java-gatewaysystemctl enable zabbix-java-gateway 3. 配置被监控 tomcat1vim /tomcat/bin/catalina.sh 1CATALINA_OPTS=\"-Djava.rmi.server.hostname=&lt; 被监控 tomcat 主机 IP 地址 &gt; -Djavax.management.builder.initial= -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\" 更改完成之后重启 tomcat 应用 4. zabbix web 配置 添加被监控 tomcat","categories":[{"name":"monitor","slug":"monitor","permalink":"http://yoursite.com/categories/monitor/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"Zabbix 通过 SNMP 进行监控","slug":"zabbix_snmp","date":"2018-11-14T16:00:00.000Z","updated":"2020-12-04T11:24:29.147Z","comments":true,"path":"2018/11/15/zabbix_snmp/","link":"","permalink":"http://yoursite.com/2018/11/15/zabbix_snmp/","excerpt":"Zabbix 通过 SNMP 进行监控","text":"Zabbix 通过 SNMP 进行监控 SNMP 监控 Linux1. 被监控主机安装 net-snmp1[root@client ~]# yum install -y net-snmp 2. 修改配置文件1[root@client ~]# vim &#x2F;etc&#x2F;snmp&#x2F;snmpd.conf 123456# sec.name source communitycom2sec notConfigUser default publicview systemview included .1view systemview included .1.3.6.1.2.1.1view systemview included .1.3.6.1.2.1.25.1.1 3. 启动12[root@client ~]# systemctl start snmpd.service[root@client ~]# netstat -nlp | grep 161 4. 在 zabbix server 上测试12[root@zabbix ~]# yum install -y net-snmp[root@zabbix ~]# snmpwalk -v 2c -c zabbix 192.168.1.51 | wc -l 5. zabbix的web界面添加主机 添加模板 设置 communities SNMP 监控 ESXI1. 开启 ESXI 的 SNMP 服务（允许所有主机访问） 设置 communities 1[root@esxi:~] esxcli system snmp set --communities public 开启 SNMP 服务 1[root@esxi:~] esxcli system snmp set --enable true 允许所有主机访问 SNMP 12[root@esxi:~] esxcli network firewall ruleset set --ruleset-id snmp --allowed-all trueAlready allowed all ip 设置防火墙 1[root@esxi:~] esxcli network firewall ruleset set --ruleset-id snmp --enabled true 重启 SNMP 服务 12345[root@esxi:~] &#x2F;etc&#x2F;init.d&#x2F;snmpd restartroot: snmpd Running from interactive shell, running command: esxcli system snmp set -e false.root: snmpd setting up resource reservations.root: snmpd opening firewall port(s) for notifications.root: snmpd watchdog for snmpd started. 2. 开启 ESXI 主机的 SNMP 服务（允许特定主机访问） 禁止所有主机访问 SNMP 1[root@esxi:~] esxcli network firewall ruleset set --ruleset-id snmp --allowed-all false 设置防火墙 12[root@esxi:~] esxcli network firewall ruleset allowedip add --ruleset-id snmp --ip-address 10.0.101.0&#x2F;24[root@esxi:~] esxcli network firewall ruleset set --ruleset-id snmp --enabled true 重启 SNMP 服务 1[root@esxi:~] &#x2F;etc&#x2F;init.d&#x2F;snmpd restart 3. 测试是否能获取 SNMP 数据 在其他服务器上安装 SNMP 1[root@zabbix ~]# yum -y install net-snmp net-snmp-utils net-snmp-devel 测试获取信息 12[root@zabbix ~]# snmpwalk -v 2c -c sunwoda 192.168.9.24:161 | wc -l4594 4. Zabbix 添加主机 添加模板 设置 communities","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"Zabbix 企业微信告警","slug":"zabbix_wechat_alert","date":"2018-11-13T16:00:00.000Z","updated":"2020-12-04T12:27:37.336Z","comments":true,"path":"2018/11/14/zabbix_wechat_alert/","link":"","permalink":"http://yoursite.com/2018/11/14/zabbix_wechat_alert/","excerpt":"使用 python 编写 Zabbix 企业微信告警脚本","text":"使用 python 编写 Zabbix 企业微信告警脚本 1. 编辑 zabbix_server.conf 配置 zabbix 告警脚本路径1AlertScriptsPath&#x3D;&#x2F;usr&#x2F;local&#x2F;share&#x2F;zabbix&#x2F;alertscripts&#x2F; 2. 创建发送消息脚本 编写脚本 vim wechat.py 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python#coding=utf-8import requestsimport jsonimport osimport sys# 基本信息CropID = 'xxxxxxxxxx'Secret = 'xxxxxxxxxx'agentid = 'xxxxxxxxx'touser = 'xxxxxxxxxx' # 获取TokenGetToken =\"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=\"+ CropID + \"&amp;corpsecret=\" + Secretheaders = &#123;'Content-Type': 'application/json'&#125;json_data = json.loads(requests.get(GetToken).content.decode())token = json_data[\"access_token\"]# 消息发送接口Purl = \"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=\" + token# 消息发送函数def sendmsg(message): weixin_msg = &#123; \"touser\" : \"TangYingJie\", \"msgtype\" : \"text\", \"agentid\" : 1000002, \"text\" : &#123; \"content\" : message &#125;, &#125; print requests.post(Purl,json.dumps(weixin_msg),headers=headers) if __name__ == '__main__': message = sys.argv[1] #获取第二个参数 sendmsg(message) 测试脚本发送消息 1.&#x2F;wechat.py 测试消息 3. 进入 zabbix 主界面配置报警媒介类型 用户 -&gt; 报警媒介 动作 -&gt; 操作 默认接收人 1&#123;TRIGGER.STATUS&#125; : &#123;TRIGGER.NAME&#125; 默认信息 12345678910当前状态 : &#123;TRIGGER.STATUS&#125;告警主机 : &#123;HOST.NAME&#125;告警地址 : &#123;HOST.IP&#125;告警时间 : &#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级 : &#123;TRIGGER.SEVERITY&#125;告警信息 : &#123;TRIGGER.NAME&#125;监控取值 : &#123;ITEM.VALUE&#125;监控项目 : &#123;ITEM.NAME&#125;持续时间 : &#123;EVENT.AGE&#125;事件ID : &#123;ITEM.ID&#125; 动作 -&gt; 恢复操作","categories":[{"name":"monitor","slug":"monitor","permalink":"http://yoursite.com/categories/monitor/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]}],"categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"},{"name":"tools","slug":"tools","permalink":"http://yoursite.com/categories/tools/"},{"name":"golang","slug":"golang","permalink":"http://yoursite.com/categories/golang/"},{"name":"database","slug":"database","permalink":"http://yoursite.com/categories/database/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"},{"name":"monitor","slug":"monitor","permalink":"http://yoursite.com/categories/monitor/"},{"name":"Kubernetes","slug":"linux/Kubernetes","permalink":"http://yoursite.com/categories/linux/Kubernetes/"}],"tags":[{"name":"nmcli","slug":"nmcli","permalink":"http://yoursite.com/tags/nmcli/"},{"name":"systemd","slug":"systemd","permalink":"http://yoursite.com/tags/systemd/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"ldap","slug":"ldap","permalink":"http://yoursite.com/tags/ldap/"},{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://yoursite.com/tags/CI-CD/"},{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://yoursite.com/tags/elasticsearch/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"http://yoursite.com/tags/Kubernetes/"},{"name":"mac","slug":"mac","permalink":"http://yoursite.com/tags/mac/"},{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"vagrant","slug":"vagrant","permalink":"http://yoursite.com/tags/vagrant/"},{"name":"virtualbox","slug":"virtualbox","permalink":"http://yoursite.com/tags/virtualbox/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"},{"name":"prometheus","slug":"prometheus","permalink":"http://yoursite.com/tags/prometheus/"},{"name":"windows","slug":"windows","permalink":"http://yoursite.com/tags/windows/"},{"name":"powershell","slug":"powershell","permalink":"http://yoursite.com/tags/powershell/"},{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"},{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"},{"name":"oracle","slug":"oracle","permalink":"http://yoursite.com/tags/oracle/"},{"name":"nodejs","slug":"nodejs","permalink":"http://yoursite.com/tags/nodejs/"},{"name":"ruby","slug":"ruby","permalink":"http://yoursite.com/tags/ruby/"},{"name":"jekyll","slug":"jekyll","permalink":"http://yoursite.com/tags/jekyll/"},{"name":"keepalive","slug":"keepalive","permalink":"http://yoursite.com/tags/keepalive/"},{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"},{"name":"lvs","slug":"lvs","permalink":"http://yoursite.com/tags/lvs/"},{"name":"raspberrypi","slug":"raspberrypi","permalink":"http://yoursite.com/tags/raspberrypi/"},{"name":"selinux","slug":"selinux","permalink":"http://yoursite.com/tags/selinux/"},{"name":"svn","slug":"svn","permalink":"http://yoursite.com/tags/svn/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://yoursite.com/tags/ubuntu/"},{"name":"ftp","slug":"ftp","permalink":"http://yoursite.com/tags/ftp/"},{"name":"wsl","slug":"wsl","permalink":"http://yoursite.com/tags/wsl/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]}